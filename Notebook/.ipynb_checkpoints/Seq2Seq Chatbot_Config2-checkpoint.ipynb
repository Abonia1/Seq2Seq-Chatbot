{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IbG4IPd46Vy2"
   },
   "source": [
    "# <center> AI Chatbot Tensorflow Seq2seq Model</center>\n",
    "### <center> Deep Learning Project_Global IA</center> \n",
    "<b>Presented by</b>\t\t\t\t\t\t\t\t\n",
    "Abonia Sojasingarayar\t\t\t\t\t\t\n",
    "M2-Artificial Intelligence-IA school\t\t\n",
    "<b>Guided  by</b>\t\t\t\t\t\t\t\t\n",
    "Yacine Aslima\n",
    "Prof. AI-IA School\n",
    "\n",
    "## Credits and Motivation\n",
    "\n",
    "Siraj Raval - Founder of School of AI \n",
    "\n",
    "Andrew NG - Founder and CEO of Landing AI & Founder of deeplearning.ai\n",
    "\n",
    "Tensorflow Community\n",
    "\n",
    "Cornell University - For dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_DmmuBJY6Vy4"
   },
   "source": [
    "# Fundamentals:\n",
    "A <b>sequence</b> is an ordered list of symbols. For Ex:\n",
    "A sequence of webpages visited by a user, ordered by the time of access.\n",
    "A sequence of words or characters typed on a cellphone by a user, or in a text such as a book.\n",
    "A sequence of products bought by a customer in a retail store\n",
    "A sequence of proteins in bioinformatics\n",
    "A sequence of symptoms observed on a patient at a hospital\n",
    "\n",
    "Note : we consider that a sequence is a list of symbols and do not contain numeric values.  A sequence of numeric values is usually called a time-series rather than a sequence, and the task of predicting a time-series is called time-series forecasting. \n",
    "\n",
    "The task of <b>sequence prediction</b> consists of predicting the next symbol of a sequence based on the previously observed symbols. For example, if a user has visited some webpages A, B, C, in that order, one may want to predict what is the next webpage that will be visited by that user to prefetch the webpage.\n",
    "![title](DocImg/prediction.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "20-3Q5pG6Vy4"
   },
   "source": [
    "## RNN:\n",
    "\n",
    "Recurrent Neural Networks, or RNNs, were designed to work with sequence prediction problems. \n",
    "\n",
    "\n",
    "Recurrent means the output at the current time step becomes the input to the next time step. At each element of the sequence, the model considers not just the current input, but what it remembers about the preceding elements.\n",
    "![title](DocImg/rnn.png)\n",
    "\n",
    "![title](DocImg/rnns.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yIjuZGY66Vy5"
   },
   "source": [
    "\n",
    "## Types of RNN:\n",
    "\n",
    "One-to-Many: An observation as input mapped to a sequence with multiple steps as an output.\n",
    "Many-to-One: A sequence of multiple steps as input mapped to class or quantity prediction.\n",
    "Many-to-Many: A sequence of multiple steps as input mapped to a sequence with multiple steps as output.\n",
    "\n",
    "![title](DocImg/rnntype.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kRD_owAH6Vy6"
   },
   "source": [
    "### LSTM:\n",
    "Long Short-Term Memory (LSTM) networks are a type of recurrent neural network capable of learning order dependence(long-term dependencies) in sequence prediction problems.\n",
    "This is a behavior required in complex problem domains like machine translation, speech recognition, and more.\n",
    "\n",
    "\n",
    "![title](DocImg/lstm.png)\n",
    "\n",
    "<i>Image Source: https://colah.github.io</i>\n",
    "\n",
    "\n",
    "## Seq2Seq LSTMs or RNN Encoder-Decoders:\n",
    "\n",
    "An “encoder” RNN reads the source sentence and transforms it into a rich fixed-length vector representation, which in turn in used as the initial hidden state of a “decoder” RNN that generates the target sentence. Here, we propose to follow this elegant recipe, replacing the encoder RNN by a deep convolution neural network (CNN). … it is natural to use a CNN as an image “encoder”, by first pre-training it for an image classification task and using the last hidden layer as an input to the RNN decoder that generates sentences!\n",
    "\n",
    "<i>Source: — Oriol Vinyals, et al., Show and Tell: A Neural Image Caption Generator, 2014</i>\n",
    "\n",
    "… an RNN Encoder–Decoder, consists of two recurrent neural networks (RNN) that act as an encoder and a decoder pair. The encoder maps a variable-length source sequence to a fixed-length vector, and the decoder maps the vector representation back to a variable-length target sequence.\n",
    "\n",
    "<i>Source: — Kyunghyun Cho, et al., Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation, 2014</i>\n",
    "\n",
    "![title](DocImg/encoderdecoder.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 646
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 57887,
     "status": "ok",
     "timestamp": 1589884274617,
     "user": {
      "displayName": "Abonia Sojasingarayar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiGI2S6plDhEjXinzvOnzVjhgSjbT_2_mUe0Ud1xA=s64",
      "userId": "02695506849043029320"
     },
     "user_tz": -120
    },
    "id": "ekrhgi2g9E_X",
    "outputId": "50db2bfd-082d-424c-fe7b-3e9d586dae2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==1.14.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/f0/96fb2e0412ae9692dbf400e5b04432885f677ad6241c088ccc5fe7724d69/tensorflow-1.14.0-cp36-cp36m-manylinux1_x86_64.whl (109.2MB)\n",
      "\u001b[K     |████████████████████████████████| 109.2MB 28kB/s \n",
      "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.34.2)\n",
      "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.18.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.2.0)\n",
      "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.8.1)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.12.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.1.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.9.0)\n",
      "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488kB)\n",
      "\u001b[K     |████████████████████████████████| 491kB 40.8MB/s \n",
      "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.28.1)\n",
      "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.3.3)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (3.10.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.1.0)\n",
      "Collecting tensorboard<1.15.0,>=1.14.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl (3.1MB)\n",
      "\u001b[K     |████████████████████████████████| 3.2MB 54.6MB/s \n",
      "\u001b[?25hRequirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.0.8)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.12.1)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.14.0) (46.3.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.2.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (1.0.1)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14.0) (2.10.0)\n",
      "Installing collected packages: tensorflow-estimator, tensorboard, tensorflow\n",
      "  Found existing installation: tensorflow-estimator 2.2.0\n",
      "    Uninstalling tensorflow-estimator-2.2.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.2.0\n",
      "  Found existing installation: tensorboard 2.2.1\n",
      "    Uninstalling tensorboard-2.2.1:\n",
      "      Successfully uninstalled tensorboard-2.2.1\n",
      "  Found existing installation: tensorflow 2.2.0\n",
      "    Uninstalling tensorflow-2.2.0:\n",
      "      Successfully uninstalled tensorflow-2.2.0\n",
      "Successfully installed tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==1.14.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 462
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 59523,
     "status": "ok",
     "timestamp": 1589884276265,
     "user": {
      "displayName": "Abonia Sojasingarayar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiGI2S6plDhEjXinzvOnzVjhgSjbT_2_mUe0Ud1xA=s64",
      "userId": "02695506849043029320"
     },
     "user_tz": -120
    },
    "id": "jZldWIkOQ4Fw",
    "outputId": "0114d781-cd08-43a3-d1be-fb02166648fe"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 59515,
     "status": "ok",
     "timestamp": 1589884276266,
     "user": {
      "displayName": "Abonia Sojasingarayar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiGI2S6plDhEjXinzvOnzVjhgSjbT_2_mUe0Ud1xA=s64",
      "userId": "02695506849043029320"
     },
     "user_tz": -120
    },
    "id": "gHC1tmDnQzdD",
    "outputId": "193b5e81-39e4-417c-efe8-097f9e3a205c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 10083818335540186466, name: \"/device:XLA_CPU:0\"\n",
       " device_type: \"XLA_CPU\"\n",
       " memory_limit: 17179869184\n",
       " locality {\n",
       " }\n",
       " incarnation: 13287795928092318117\n",
       " physical_device_desc: \"device: XLA_CPU device\"]"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 816
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 61946,
     "status": "ok",
     "timestamp": 1589884278707,
     "user": {
      "displayName": "Abonia Sojasingarayar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiGI2S6plDhEjXinzvOnzVjhgSjbT_2_mUe0Ud1xA=s64",
      "userId": "02695506849043029320"
     },
     "user_tz": -120
    },
    "id": "atJTCMdKRB_A",
    "outputId": "287d30ff-103c-4b88-8fbc-1035138404db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MemTotal:       13333540 kB\n",
      "MemFree:         5264452 kB\n",
      "MemAvailable:   12350868 kB\n",
      "Buffers:          129288 kB\n",
      "Cached:          6960360 kB\n",
      "SwapCached:            0 kB\n",
      "Active:           996008 kB\n",
      "Inactive:        6620480 kB\n",
      "Active(anon):     484172 kB\n",
      "Inactive(anon):      332 kB\n",
      "Active(file):     511836 kB\n",
      "Inactive(file):  6620148 kB\n",
      "Unevictable:           0 kB\n",
      "Mlocked:               0 kB\n",
      "SwapTotal:             0 kB\n",
      "SwapFree:              0 kB\n",
      "Dirty:             18396 kB\n",
      "Writeback:             0 kB\n",
      "AnonPages:        526840 kB\n",
      "Mapped:           302848 kB\n",
      "Shmem:               948 kB\n",
      "Slab:             321712 kB\n",
      "SReclaimable:     279756 kB\n",
      "SUnreclaim:        41956 kB\n",
      "KernelStack:        3712 kB\n",
      "PageTables:         6084 kB\n",
      "NFS_Unstable:          0 kB\n",
      "Bounce:                0 kB\n",
      "WritebackTmp:          0 kB\n",
      "CommitLimit:     6666768 kB\n",
      "Committed_AS:    2661032 kB\n",
      "VmallocTotal:   34359738367 kB\n",
      "VmallocUsed:           0 kB\n",
      "VmallocChunk:          0 kB\n",
      "Percpu:              912 kB\n",
      "AnonHugePages:         0 kB\n",
      "ShmemHugePages:        0 kB\n",
      "ShmemPmdMapped:        0 kB\n",
      "HugePages_Total:       0\n",
      "HugePages_Free:        0\n",
      "HugePages_Rsvd:        0\n",
      "HugePages_Surp:        0\n",
      "Hugepagesize:       2048 kB\n",
      "Hugetlb:               0 kB\n",
      "DirectMap4k:      103612 kB\n",
      "DirectMap2M:     5138432 kB\n",
      "DirectMap1G:    10485760 kB\n"
     ]
    }
   ],
   "source": [
    "!cat /proc/meminfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 955
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 63600,
     "status": "ok",
     "timestamp": 1589884280371,
     "user": {
      "displayName": "Abonia Sojasingarayar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiGI2S6plDhEjXinzvOnzVjhgSjbT_2_mUe0Ud1xA=s64",
      "userId": "02695506849043029320"
     },
     "user_tz": -120
    },
    "id": "ByIE0eNJRM9y",
    "outputId": "c019478e-7639-4caf-fb4f-9e4a094a5154"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processor\t: 0\n",
      "vendor_id\t: GenuineIntel\n",
      "cpu family\t: 6\n",
      "model\t\t: 85\n",
      "model name\t: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
      "stepping\t: 3\n",
      "microcode\t: 0x1\n",
      "cpu MHz\t\t: 2000.178\n",
      "cache size\t: 39424 KB\n",
      "physical id\t: 0\n",
      "siblings\t: 2\n",
      "core id\t\t: 0\n",
      "cpu cores\t: 1\n",
      "apicid\t\t: 0\n",
      "initial apicid\t: 0\n",
      "fpu\t\t: yes\n",
      "fpu_exception\t: yes\n",
      "cpuid level\t: 13\n",
      "wp\t\t: yes\n",
      "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx avx512f avx512dq rdseed adx smap clflushopt clwb avx512cd avx512bw avx512vl xsaveopt xsavec xgetbv1 xsaves arat md_clear arch_capabilities\n",
      "bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs taa itlb_multihit\n",
      "bogomips\t: 4000.35\n",
      "clflush size\t: 64\n",
      "cache_alignment\t: 64\n",
      "address sizes\t: 46 bits physical, 48 bits virtual\n",
      "power management:\n",
      "\n",
      "processor\t: 1\n",
      "vendor_id\t: GenuineIntel\n",
      "cpu family\t: 6\n",
      "model\t\t: 85\n",
      "model name\t: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
      "stepping\t: 3\n",
      "microcode\t: 0x1\n",
      "cpu MHz\t\t: 2000.178\n",
      "cache size\t: 39424 KB\n",
      "physical id\t: 0\n",
      "siblings\t: 2\n",
      "core id\t\t: 0\n",
      "cpu cores\t: 1\n",
      "apicid\t\t: 1\n",
      "initial apicid\t: 1\n",
      "fpu\t\t: yes\n",
      "fpu_exception\t: yes\n",
      "cpuid level\t: 13\n",
      "wp\t\t: yes\n",
      "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx avx512f avx512dq rdseed adx smap clflushopt clwb avx512cd avx512bw avx512vl xsaveopt xsavec xgetbv1 xsaves arat md_clear arch_capabilities\n",
      "bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs taa itlb_multihit\n",
      "bogomips\t: 4000.35\n",
      "clflush size\t: 64\n",
      "cache_alignment\t: 64\n",
      "address sizes\t: 46 bits physical, 48 bits virtual\n",
      "power management:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!cat /proc/cpuinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UBK-yfZdwsN5",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Import packages\n",
    "import warnings  \n",
    "with warnings.catch_warnings():  \n",
    "    warnings.filterwarnings(\"ignore\",category=FutureWarning)\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import re\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iABePnXb6VzB"
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "juqgahmc6VzF"
   },
   "source": [
    "## Dataset : Cornell Movie Dialogs Corpus\n",
    "Description:\u000b",
    "\n",
    "This corpus contains a large metadata-rich collection of fictional conversations extracted from raw movie scripts.\n",
    "\n",
    "Link to download dataset : https://www.cs.cornell.edu/~cristian/Cornell_Movie-Dialogs_Corpus.html \t\t\t\t\t\n",
    "                            https://www.kaggle.com/rajathmc/cornell-moviedialog-corpus \u000b",
    "\u000b",
    "\n",
    "\n",
    "220,579 conversational exchanges between 10,292 pairs of movie characters\u000b",
    "\n",
    "\n",
    "Involves 9,035 characters from 617 movies\u000b",
    "\n",
    "\n",
    "In total 304,713 utterances\u000b",
    "\n",
    "\n",
    "Movie metadata included:\u000b",
    "\n",
    "    \n",
    "    Genres\u000b",
    "\n",
    "    Release year\u000b",
    "\n",
    "    IMDB rating\u000b",
    "\n",
    "    Number of IMDB votes\u000b",
    "\u000b",
    "\n",
    "\n",
    "Character metadata included:\u000b",
    "\n",
    "    \n",
    "    Gender (for 3,774 characters)\u000b",
    "\n",
    "    Position on movie credits (3,321 characters)\u000b",
    "\n",
    "\n",
    "README.txt (included) for details\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9UNOGC0Mwwlk"
   },
   "outputs": [],
   "source": [
    "#!wget http://www.cs.cornell.edu/~cristian/data/cornell_movie_dialogs_corpus.zip\n",
    "#!unzip cornell_movie_dialogs_corpus.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DO9voLO_6VzL"
   },
   "source": [
    "# Preprocessing or Data_Utils\n",
    "<b>Step 1:</b>\n",
    "Read from 'movie_conversations.txt'\n",
    "Create a list of [list of line_id's]\n",
    "\n",
    "Output Ex:['L194', 'L195', 'L196', 'L197']\n",
    "\n",
    "<b>Step 2:</b>\n",
    "Read from 'movie-lines.txt'\n",
    "Create a dictionary with ( key = line_id, value = text )\n",
    "\n",
    "Ex:\n",
    "They do not!\n",
    "\n",
    "They do to!\n",
    "\n",
    "I hope so.\n",
    "\n",
    "She okay?\n",
    "\n",
    "Let's go.\n",
    "\n",
    "Wow\n",
    "\n",
    "Okay -- you're gonna need to learn how to lie.\n",
    "\n",
    "No\n",
    "\n",
    "I'm kidding.  You know how sometimes you just become this \"persona\"?  And you don't know how to quit?\n",
    "\n",
    "Like my fear of wearing pastels?\n",
    "\n",
    "<b>Step 3:</b>\n",
    "Get lists of all conversations as Questions and Answers\n",
    " [questions]\n",
    " [answers]   \n",
    "\n",
    "Question and answers are come from same conversation.As because there will be a question with the response.\n",
    "\n",
    "Ex: For our first conversation\n",
    "\n",
    "Q Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again.\n",
    "\n",
    "A Well, I thought we'd start with pronunciation, if that's okay with you.\n",
    "\n",
    "Q Well, I thought we'd start with pronunciation, if that's okay with you.\n",
    "\n",
    "A Not the hacking and gagging and spitting part.  Please.\n",
    "\n",
    "Q Not the hacking and gagging and spitting part.  Please.\n",
    "\n",
    "A Okay... then how 'bout we try out some French cuisine.  Saturday?  Night?\n",
    "\n",
    "\n",
    "<b>Step 4:</b>\n",
    "Clean Text:\n",
    "Text to lowercase \n",
    "Replacing certain words as follow:\n",
    "\n",
    "Ex:   \n",
    "    \n",
    "    text = re.sub(r\"i'm\", \"i am\", text)\n",
    "    \n",
    "    text = re.sub(r\"he's\", \"he is\", text)\n",
    "    \n",
    "    text = re.sub(r\"she's\", \"she is\", text)\n",
    "    \n",
    "    text = re.sub(r\"it's\", \"it is\", text)\n",
    "    \n",
    "    text = re.sub(r\"that's\", \"that is\", text)\n",
    "    \n",
    "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
    "    \n",
    "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
    "    \n",
    "    text = re.sub(r\"\\'re\", \" are\", text)\n",
    "    \n",
    "    text = re.sub(r\"\\'re\", \" are\", text)\n",
    "    \n",
    "    text = re.sub(r\"can't\", \"cannot\", text)\n",
    "\n",
    "<b>Step 5:</b>\n",
    "\n",
    "Filter out the Questions  and Answers that are too short/long\n",
    "\n",
    "Minimum&Maximum  length are 2&5\n",
    "\n",
    "<b>Step 6:</b>\n",
    "\n",
    "Get each word and its count  from filtered questions and answers in vocab dictionary\n",
    "\n",
    "Get each word and its count  from filtered questions and answers in Question and Answer vocab dictionary \n",
    "\n",
    "<b>Step 7:</b>\n",
    "\n",
    "Create vocabulary index with total number of words appear more than 2 times in vocab dictionary\n",
    "\t\n",
    "    6281 words which appear more appear more than 2 times \n",
    "\n",
    "<b>Step 8:</b>\n",
    "\n",
    "For each codes(<EOS>,<PAD>,<UNK><GO>) ,increment vocabulary index to 1 for each existing code \n",
    "Same for question and answer vocab.\n",
    "\t\n",
    "    Now vocab index will be 6285\n",
    "\n",
    "<b>Step 9:</b>\n",
    "\n",
    "Create index vocabulary from vocabulary index dictionary \n",
    "\t\n",
    "    index vocabulary dict_items([(0, 'what'), (1, 'good'), (2, 'stuff'), (3, 'she'), (4, 'okay'), (5, 'they'),......\n",
    "\t......., (6283, '<PAD>'), (6284, '<EOS>'), (6285, '<UNK>'), (6286, '<GO>')])\n",
    "\n",
    "<b>Step 10:</b>\n",
    "\n",
    "Add EOS tag at the end of each answer \t\n",
    "\tEx: the real you   -->   the real you <EOS>\n",
    "\n",
    "<b>Step 11:</b>\n",
    "\n",
    "Again filter out words in by comparing words in filtered question  and words in vocabulary index\n",
    "Do the same for filtered answer \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 87268,
     "status": "ok",
     "timestamp": 1589884304058,
     "user": {
      "displayName": "Abonia Sojasingarayar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiGI2S6plDhEjXinzvOnzVjhgSjbT_2_mUe0Ud1xA=s64",
      "userId": "02695506849043029320"
     },
     "user_tz": -120
    },
    "id": "XnNTNnpf6hkr",
    "outputId": "923fffbc-b0c1-4f41-ba99-36216b003e1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HrQk0g1kwsOE"
   },
   "outputs": [],
   "source": [
    "#get the conversation and movie data\n",
    "movie_line = \"/content/drive/My Drive/ML Projects/Global IA/Seq2Seq-Chatbot/Datasets/cornell movie-dialogs corpus/movie_lines.txt\"\n",
    "movie_convo = \"/content/drive/My Drive/ML Projects/Global IA/Seq2Seq-Chatbot/Datasets/cornell movie-dialogs corpus/movie_conversations.txt\"\n",
    "\n",
    "m_lines = open(movie_line , encoding='utf-8',errors='ignore').read().split('\\n')\n",
    "c_lines = open(movie_convo , encoding='utf-8',errors='ignore').read().split('\\n')\n",
    "\n",
    "#get converastion lines\n",
    "convo_line = []\n",
    "for lines in c_lines:\n",
    "    _lines = lines.split(\" +++$+++ \")[-1][1:-1].replace(\"'\",\"\").replace(\" \",\"\")\n",
    "    convo_line.append(_lines.split(\",\"))\n",
    "\n",
    "#get movie lines\n",
    "id_line = {}\n",
    "for lines in m_lines:\n",
    "    _lines = lines.split(\" +++$+++ \")\n",
    "    if len(_lines) == 5:\n",
    "        id_line[_lines[0]] = _lines[4]\n",
    "        \n",
    "#Form questions and answers \n",
    "questions = []\n",
    "answers = []\n",
    "\n",
    "for line in convo_line:\n",
    "    for i in range(len(line) -1):\n",
    "        questions.append(id_line[line[i]])\n",
    "        answers.append(id_line[line[i+1]])\n",
    "        \n",
    "#Clean and replace improper words using regular expression\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    \n",
    "    text = re.sub(r\"i'm\", \"i am\", text)\n",
    "    text = re.sub(r\"he's\", \"he is\", text)\n",
    "    text = re.sub(r\"she's\", \"she is\", text)\n",
    "    text = re.sub(r\"it's\", \"it is\", text)\n",
    "    text = re.sub(r\"that's\", \"that is\", text)\n",
    "    text = re.sub(r\"what's\", \"that is\", text)\n",
    "    text = re.sub(r\"where's\", \"where is\", text)\n",
    "    text = re.sub(r\"how's\", \"how is\", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
    "    text = re.sub(r\"\\'re\", \" are\", text)\n",
    "    text = re.sub(r\"\\'d\", \" would\", text)\n",
    "    text = re.sub(r\"\\'re\", \" are\", text)\n",
    "    text = re.sub(r\"won't\", \"will not\", text)\n",
    "    text = re.sub(r\"can't\", \"cannot\", text)\n",
    "    text = re.sub(r\"n't\", \" not\", text)\n",
    "    text = re.sub(r\"n'\", \"ng\", text)\n",
    "    text = re.sub(r\"'bout\", \"about\", text)\n",
    "    text = re.sub(r\"'til\", \"until\", text)\n",
    "    text = re.sub(r\"  \",\"\",text)\n",
    "    text = re.sub(r\"[-()\\\"#/@;:<>{}`+=~|.!?,]\", \"\", text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "clean_questions = []\n",
    "clean_answers = []\n",
    "\n",
    "for q in questions:\n",
    "    clean_questions.append(clean_text(q))\n",
    "for a in answers:\n",
    "    clean_answers.append(clean_text(a))\n",
    "    \n",
    "#get the min and max length of sentence need to be used\n",
    "max_length = 5\n",
    "min_length = 2\n",
    "\n",
    "codes = ['<PAD>','<EOS>','<UNK>','<GO>']\n",
    "\n",
    "\n",
    "\n",
    "short_questions_temp = []\n",
    "short_answers_temp = []\n",
    "\n",
    "i = 0\n",
    "for question in clean_questions:\n",
    "    if len(question.split()) >= min_length and len(question.split()) <= max_length:\n",
    "        short_questions_temp.append(question)\n",
    "        short_answers_temp.append(clean_answers[i])\n",
    "    i += 1\n",
    "\n",
    "# Filter out the answers that are too short/long\n",
    "shorted_q = []\n",
    "shorted_a = []\n",
    "\n",
    "i = 0\n",
    "for answer in short_answers_temp:\n",
    "    if len(answer.split()) >= min_length and len(answer.split()) <= max_length:\n",
    "        shorted_a.append(answer)\n",
    "        shorted_q.append(short_questions_temp[i])\n",
    "    i += 1\n",
    "   \n",
    "  \n",
    "\n",
    "#Get the count of words from filtered questions and answers  \n",
    "vocab = {}\n",
    "\n",
    "for question in shorted_q:\n",
    "    for words in question.split():\n",
    "        if words not in vocab:\n",
    "            vocab[words] = 1\n",
    "        else:\n",
    "            vocab[words] +=1\n",
    "for answer in shorted_a:\n",
    "    for words in answer.split():\n",
    "        if words not in vocab:\n",
    "            vocab[words] = 1\n",
    "        else:\n",
    "            vocab[words] +=1\n",
    "            \n",
    "questions_vocabs = {}\n",
    "for answer in shorted_q:\n",
    "    for words in answer.split():\n",
    "        if words not in questions_vocabs:\n",
    "            questions_vocabs[words] = 1\n",
    "        else:\n",
    "            questions_vocabs[words] +=1\n",
    "            \n",
    "answers_vocabs = {}\n",
    "for answer in shorted_a:\n",
    "    for words in answer.split():\n",
    "        if words not in answers_vocabs:\n",
    "            answers_vocabs[words] = 1\n",
    "        else:\n",
    "            answers_vocabs[words] +=1\n",
    "            \n",
    "#total number of words appear more than 2 times\n",
    "vocabs_to_index = {}\n",
    "threshold = 2\n",
    "word_num = 0\n",
    "for word, count in vocab.items():\n",
    "    if count >= threshold:\n",
    "        vocabs_to_index[word] = word_num\n",
    "        word_num += 1\n",
    "\n",
    "#add words in codes in the text and  increment vocab index to 1 for each existing code \n",
    "#same for question and answer vocab.6281 in vocab dict and now 6286        \n",
    "for code in codes:\n",
    "    vocabs_to_index[code] = len(vocabs_to_index)+1\n",
    "    \n",
    "for code in codes:\n",
    "    questions_vocabs[code] = len(questions_vocabs)+1\n",
    "\n",
    "for code in codes:\n",
    "    answers_vocabs[code] = len(answers_vocabs)+1\n",
    "\n",
    "#Convert index vocab to vocab index   \n",
    "index_to_vocabs = {v_i: v for v, v_i in vocabs_to_index.items()}\n",
    "\n",
    "#Add <EOS> to the end of all the answer in such a way model can learn the the sentence comes to the end \n",
    "for i in range(len(shorted_a)):\n",
    "  shorted_a[i] += ' <EOS>'\n",
    "  \n",
    "#Get the question and with code <UNK> for the words which are not in vocab to index\n",
    "#ex:'nowhere hi daddy <EOS> ' to '[6285, 179, 22, 6284]' as it doesnt find the word 'nowhere' in the vocabulary index dictionary\n",
    "\n",
    "questions_int = []\n",
    "for question in shorted_q:\n",
    "    ints = []\n",
    "    for word in question.split():\n",
    "        if word not in vocabs_to_index:\n",
    "            ints.append(vocabs_to_index['<UNK>'])\n",
    "        else:\n",
    "            ints.append(vocabs_to_index[word])\n",
    "    questions_int.append(ints)\n",
    "    \n",
    "answers_int = []\n",
    "for answer in shorted_a:\n",
    "    ints = []\n",
    "    for word in answer.split():\n",
    "        if word not in vocabs_to_index:\n",
    "            ints.append(vocabs_to_index['<UNK>'])\n",
    "        else:\n",
    "            ints.append(vocabs_to_index[word])\n",
    "    answers_int.append(ints)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 99259,
     "status": "ok",
     "timestamp": 1589884316062,
     "user": {
      "displayName": "Abonia Sojasingarayar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiGI2S6plDhEjXinzvOnzVjhgSjbT_2_mUe0Ud1xA=s64",
      "userId": "02695506849043029320"
     },
     "user_tz": -120
    },
    "id": "X0o_V2ofuDrk",
    "outputId": "cb70dfd8-e55b-48e0-e83b-d5f84f13517c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6283\n",
      "6284\n",
      "6285\n",
      "6286\n"
     ]
    }
   ],
   "source": [
    "for code in codes:\n",
    "  print(vocabs_to_index[code])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cgYZIx1h6VzU"
   },
   "source": [
    "## Configuration:\n",
    "<b>source_vocab_size</b> is the size of questions vocabulary dictionary.In our case:9611\n",
    "\n",
    "<b>target_vocab_size</b> is the size of answers vocabulary dictionary.In our case:9636\n",
    "\n",
    "<b>vocab size</b> is the length of vocabulary index dictionary in our case its 6286\n",
    "\n",
    "The <b>learning rate</b> is a hyperparameter that controls how much to change the model in response to the estimated error each time the model weights are updated. Choosing the learning rate is challenging as a value too small may result in a long training process that could get stuck, whereas a value too large may result in learning a sub-optimal set of weights too fast or an unstable training process.\n",
    "\n",
    "<b>learning Rate decay:</b>An alternative to using a fixed learning rate is to instead vary the learning rate over the training process.\n",
    "The way in which the learning rate changes over time (training epochs) is referred to as the learning rate schedule or learning rate decay.\n",
    "\n",
    "The <b>keep_prob</b> value is used to control the dropout rate used when training the network. Essentially, it means that each connection between layers (in this case between the last densely connected layer and the readout layer) will only be used with probability 0.5 when training. This reduces overfitting.\n",
    "\n",
    "The <b>batch size</b> is a hyperparameter that defines the number of samples to work through before updating the internal model parameters.\n",
    "\n",
    "The number of <b>epochs</b> is a hyperparameter that defines the number times that the learning algorithm will work through the entire training dataset.\n",
    "\n",
    "<b>Working Example:</b> Assume you have a dataset with 200 samples (rows of data) and you choose a batch size of 5 and 1,000 epochs.\n",
    "\n",
    "This means that the dataset will be divided into 40 batches, each with five samples. The model weights will be updated after each batch of five samples.\n",
    "\n",
    "This also means that one epoch will involve 40 batches or 40 updates to the model.\n",
    "\n",
    "With 1,000 epochs, the model will be exposed to or pass through the whole dataset 1,000 times. That is a total of 40,000 batches during the entire training process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lHBhX_UMwsOH"
   },
   "outputs": [],
   "source": [
    "target_vocab_size = len(answers_vocabs)\n",
    "source_vocab_size = len(questions_vocabs)\n",
    "vocab_size = len(index_to_vocabs)+1\n",
    "embed_size = 512\n",
    "rnn_size = 512\n",
    "batch_size = 512\n",
    "#num_layers =  3\n",
    "learning_rate = 0.001\n",
    "learning_rate_decay = 0.99\n",
    "min_lr = 0.0001\n",
    "#keep_prob = 0.5\n",
    "epochs=80\n",
    "DISPLAY_STEP=30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WwvxhPNN6VzZ"
   },
   "source": [
    "### LSTM and DropoutWrapper\n",
    "\n",
    "<b>class LSTMCell:</b> Long short-term memory unit (LSTM) recurrent network cell.\n",
    "\n",
    "rnn_size: int, The number of units in the LSTM cell.\n",
    "\n",
    "reuse:Python boolean describing whether to reuse variables in an existing scope. If not True, and the existing scope already has the given variables, an error is raised.\n",
    "\n",
    "\n",
    "<b>class DropoutWrapper</b>:Operator adding dropout to inputs and outputs of the given cell.\n",
    "\n",
    "cell: an RNNCell, a projection to output_size is added to it.\n",
    "input_keep_prob: unit Tensor or float between 0 and 1, input keep probability; if it is constant and 1, no input dropout will be added.\n",
    "\n",
    "output_keep_prob: unit Tensor or float between 0 and 1, output keep probability; if it is constant and 1, no output dropout will be added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e2Dg_dItwsOJ"
   },
   "outputs": [],
   "source": [
    "def lstm(rnn_size, keep_prob,reuse=False):\n",
    "    lstm =tf.nn.rnn_cell.LSTMCell(rnn_size,reuse=reuse)\n",
    "    drop =tf.nn.rnn_cell.DropoutWrapper(lstm, output_keep_prob=keep_prob)\n",
    "    return drop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fL_eAfzY6Vzc"
   },
   "source": [
    "# Attention Mechanism:\n",
    "A neural network is considered to be an effort to mimic human brain actions in a simplified manner. Attention Mechanism is also an attempt to implement the same action of selectively concentrating on a few relevant things in input, while ignoring others in deep neural networks when producing output\n",
    "\n",
    "### Bahdanau Attention\n",
    "\n",
    "Bahdanau et al (2015) came up with a simple but elegant idea where they suggested that not only can all the input words be taken into account in the context vector, but relative importance should also be given to each one of them.\n",
    "\n",
    "![title](DocImg/Battention.jpg)\n",
    "\n",
    "<center>Overall process for Bahdanau Attention seq2seq model</center>\n",
    "\n",
    "\n",
    "The first type of Attention, commonly referred to as Additive Attention, came from a paper by Dzmitry Bahdanau, which explains the less-descriptive original name. The paper aimed to improve the sequence-to-sequence model in machine translation by aligning the decoder with the relevant input sentences and implementing Attention. The entire step-by-step process of applying Attention in Bahdanau’s paper is as follows:\n",
    "\n",
    "1;Producing the Encoder Hidden States - Encoder produces hidden states of each element in the input sequence\n",
    "\n",
    "2.Calculating Alignment Scores between the previous decoder hidden state and each of the encoder’s hidden states are calculated (Note: The last encoder hidden state can be used as the first hidden state in the decoder)\n",
    "\n",
    "3.Softmaxing the Alignment Scores - the alignment scores for each encoder hidden state are combined and represented in a single vector and subsequently softmaxed\n",
    "\n",
    "4.Calculating the Context Vector - the encoder hidden states and their respective alignment scores are multiplied to form the context vector\n",
    "\n",
    "5.Decoding the Output - the context vector is concatenated with the previous decoder output and fed into the Decoder RNN for that time step along with the previous decoder hidden state to produce a new output\n",
    "\n",
    "6.The process (steps 2-5) repeats itself for each time step of the decoder until an token is produced or output is past the specified maximum length\n",
    "\n",
    "Dzmitry Bahdanau, Kyunghyun Cho, Yoshua Bengio. \"Neural Machine Translation by Jointly Learning to Align and Translate.\" ICLR 2015. https://arxiv.org/abs/1409.0473\n",
    "\n",
    "The second is the normalized form. This form is inspired by the weight normalization article:\n",
    "\n",
    "Tim Salimans, Diederik P. Kingma. \"Weight Normalization: A Simple Reparameterization to Accelerate Training of Deep Neural Networks.\" https://arxiv.org/abs/1602.07868\n",
    "\n",
    "<b>Class BahdanauAttention</b>\n",
    "\n",
    "Args:\n",
    "\n",
    "num_units: The depth of the query mechanism.\n",
    "\n",
    "memory: The memory to query; usually the output of an RNN encoder. This tensor should be shaped [batch_size, max_time, ...]. \n",
    "\n",
    "memory_sequence_length (optional): Sequence lengths for the batch entries in memory. If provided, the memory tensor rows are masked with zeros for values past the respective sequence lengths.\n",
    "\n",
    "normalize: Python boolean. Whether to normalize the energy term.\n",
    "\n",
    "probability_fn: (optional) A callable. Converts the score to probabilities. The default is tf.nn.softmax. Other options include tf.contrib.seq2seq.hardmax and tf.contrib.sparsemax.sparsemax. Its signature should be: probabilities = \n",
    "\n",
    "probability_fn(score).\n",
    "score_mask_value: (optional): The mask value for score before passing into probability_fn. The default is -inf. Only used if \n",
    "\n",
    "memory_sequence_length is not None.\n",
    "\n",
    "<b>class AttentionWrapper:</b>Wraps another RNNCell with attention.\n",
    "\n",
    "dec_cell: An instance of RNNCell.\n",
    "\n",
    "attention_mechanism: A list of AttentionMechanism instances or a single instance.\n",
    "\n",
    "attention_layer_size: A list of Python integers or a single Python integer, the depth of the attention (output) layer(s). If None (default), use the context as attention at each time step. Otherwise, feed the context and cell output into the attention layer to generate attention at each time step. If attention_mechanism is a list, attention_layer_size must be a list of the same length. If attention_layer is set, this must be None. If attention_fn is set, it must guaranteed that the outputs of attention_fn also meet the above requirements.\n",
    "\n",
    "source: 1. https://www.analyticsvidhya.com/blog/2019/11/comprehensive-guide-attention-mechanism-deep-learning/\n",
    "   2. https://blog.floydhub.com/attention-mechanism/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zTsNF75pwsOL"
   },
   "outputs": [],
   "source": [
    "def attention(rnn_size,encoder_outputs,target_sequence_length,dec_cell):\n",
    "    attention_mechanism = tf.contrib.seq2seq.BahdanauAttention(rnn_size*2,encoder_outputs,\n",
    "                                                                   memory_sequence_length=target_sequence_length)\n",
    "    attention_cell = tf.contrib.seq2seq.AttentionWrapper(dec_cell, attention_mechanism,\n",
    "                                                             attention_layer_size=rnn_size/2)\n",
    "    return attention_cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Tmj6SJB_6Vzf"
   },
   "source": [
    "A <b>placeholder</b> is used for feeding external data into a Tensorflow computation (stuff outside the graph). Here's some documentation: https://www.tensorflow.org/versions/r0.10/how_tos/reading_data/#feeding\n",
    "\n",
    "TensorFlow's feed mechanism lets you inject data into any Tensor in a computation graph. A python computation can thus feed data directly into the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wY9S276eYdQq"
   },
   "outputs": [],
   "source": [
    "#import tensorflow.compat.v1 as tf\n",
    "#tf.disable_v2_behavior()\n",
    "#tf.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BcGIjHaBwsON"
   },
   "outputs": [],
   "source": [
    "input_data = tf.placeholder(tf.int32, [None, None],name='input')\n",
    "target_data = tf.placeholder(tf.int32, [None, None],name='target')\n",
    "input_data_len = tf.placeholder(tf.int32,[None],name='input_len')\n",
    "target_data_len = tf.placeholder(tf.int32,[None],name='target_len')\n",
    "lr_rate = tf.placeholder(tf.float32,name='lr')\n",
    "keep_prob = tf.placeholder(tf.float32,name='keep_prob')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fx4CshXy6Vzi"
   },
   "source": [
    "# <center> Encoder</center>\n",
    "The LSTM network can be organized into an architecture called the Encoder-Decoder LSTM that allows the model to be used to both support variable length input sequences and to predict or output variable length output sequences.\n",
    "\n",
    "This architecture is the basis for many advances in complex sequence prediction problems such as speech recognition and text translation.\n",
    "\n",
    "In this architecture, an <b>encoder</b> LSTM model reads the input sequence step-by-step. After reading in the entire input sequence, the hidden state or output of this model represents an internal learned representation of the entire input sequence as a fixed-length vector. This vector is then provided as an input to the <b>decoder</b> model that interprets it as each step in the output sequence is generated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_wZ1Odh76Vzi"
   },
   "source": [
    "A <b> tf.variable</b> is used to store state in graph. It requires an initial value. One use case could be representing weights of a neural network or something similar. Here's documentation: (https://www.tensorflow.org/api_docs/python/tf/Variable)\n",
    "\n",
    "A variable maintains state in the graph across calls to run(). You add a variable to the graph by constructing an instance of the class Variable.\n",
    "\n",
    "The Variable() constructor requires an initial value for the variable, which can be a Tensor of any type and shape. The initial value defines the type and shape of the variable. After construction, the type and shape of the variable are fixed. The value can be changed using one of the assign methods.\n",
    "\n",
    "<b>random_uniform</b>:Outputs random values from a uniform distribution. Generate a random tensor in TensorFlow so that you can use it and maintain it for further use even if you call session run multiple times\n",
    "\n",
    "<b>encoder_embeddings:</b> holds the random value of tensors with shape of [source_vocab_size, embed_size]\n",
    "\n",
    "it output : <tf.Variable 'Variable:0' shape=(9611, 128) dtype=float32_ref>\n",
    "\n",
    "So [9611, 128] this is the shape of embedding matrix which xill be used for embedding lookup\n",
    "\n",
    "### Word Embedding \n",
    "\n",
    "Word embedding is one of the most popular representation of document vocabulary. It is capable of capturing context of a word in a document, semantic and syntactic similarity, relation with other words, etc.\n",
    "\n",
    "Word Embeddings are the texts converted into numbers and there may be different numerical representations of the same text.\n",
    "\n",
    "Take a look at this example – sentence=” Word Embeddings are Word converted into numbers ”\n",
    "\n",
    "A word in this sentence may be “Embeddings” or “numbers ” etc.\n",
    "\n",
    "A dictionary may be the list of all unique words in the sentence. So, a dictionary may look like – [‘Word’,’Embeddings’,’are’,’Converted’,’into’,’numbers’]\n",
    "\n",
    "A vector representation of a word may be a one-hot encoded vector where 1 stands for the position where the word exists and 0 everywhere else. The vector representation of “numbers” in this format according to the above dictionary is [0,0,0,0,0,1] and of converted is[0,0,0,1,0,0].\n",
    "![title](DocImg/one-hot.jpg)            ![title](DocImg/wordembed.jpg)\n",
    "\n",
    "![title](DocImg/one-hot to wordembed.jpg)\n",
    "\n",
    "<center><i>Source:https://confengine.com/odsc-india-2019/proposal/10176/sequence-to-sequence-learning-with-encoder-decoder-neural-network-models</i></center>\n",
    "\n",
    "### Word2Vec\n",
    "\n",
    "Word2Vec is one of the most popular technique to learn word embeddings using shallow neural network.\n",
    "\n",
    "Mitolov introduced word2vec to the NLP community. These methods were prediction based in the sense that they provided probabilities to the words and proved to be state of the art for tasks like word analogies and word similarities. They were also able to achieve tasks like King -man +woman = Queen, which was considered a result almost magical. So let us look at the word2vec model used as of today to generate word vectors.\n",
    "\n",
    "Word2vec is not a single algorithm but a combination of two techniques – CBOW(Continuous bag of words) and Skip-gram model. Both of these are shallow neural networks which map word(s) to the target variable which is also a word(s). \n",
    "\n",
    "<i>source:https://www.analyticsvidhya.com/blog/2017/06/word-embeddings-count-word2veec/</i>\n",
    "\n",
    "### <b>Class embedding_lookup:</b>\n",
    "embedding_lookup function retrieves rows of the params tensor. The behavior is similar to using indexing with arrays in numpy.\n",
    "\n",
    "![title](DocImg/embed_lookup2.jpg)\n",
    "\n",
    "![title](DocImg/embed_lookup.jpg)\n",
    "\n",
    "<i>Note:In above diagram 100 is the row size of embedding matrix but in our case its 9611 i.e our vocabulary size of questions</i>\n",
    "\n",
    "source:Stackoverflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z7TNblfPwsOQ"
   },
   "outputs": [],
   "source": [
    "encoder_embeddings = tf.Variable(tf.random_uniform([source_vocab_size, embed_size], -1, 1))\n",
    "encoder_embedded = tf.nn.embedding_lookup(encoder_embeddings, input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1FBuBDxu6Vzl"
   },
   "source": [
    "## Bidirectional_dynamic_rnn\n",
    "\n",
    "If you want to have have multiple layers that pass the information backward or forward in time, there are two ways how to design this. Assume the forward layer consists of two layers F1, F2 and the backword layer consists of two layers B1, B2.\n",
    "\n",
    "If you use tf.nn.bidirectional_dynamic_rnn the model will look like this (time flows from left to right):\n",
    "\n",
    "![title](DocImg/bidir_rnn.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 99768,
     "status": "ok",
     "timestamp": 1589884316599,
     "user": {
      "displayName": "Abonia Sojasingarayar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiGI2S6plDhEjXinzvOnzVjhgSjbT_2_mUe0Ud1xA=s64",
      "userId": "02695506849043029320"
     },
     "user_tz": -120
    },
    "id": "Gag764m8wsOa",
    "outputId": "18ef675a-d4f3-4c3e-970a-85315e071ab1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-13-477ce5ee2f51>:2: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n"
     ]
    }
   ],
   "source": [
    "stacked_cells = lstm(rnn_size, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 360
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 99755,
     "status": "ok",
     "timestamp": 1589884316600,
     "user": {
      "displayName": "Abonia Sojasingarayar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiGI2S6plDhEjXinzvOnzVjhgSjbT_2_mUe0Ud1xA=s64",
      "userId": "02695506849043029320"
     },
     "user_tz": -120
    },
    "id": "LVt0hjBzwsOg",
    "outputId": "d90d9a43-211e-4040-cf3e-e4e8f4e23673",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-19-575f162a5a91>:6: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn.py:464: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn_cell_impl.py:961: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f92538ddf60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f92538ddf60>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f92538ddf60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f92538ddf60>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn.py:244: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f92538ddf60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f92538ddf60>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f92538ddf60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f92538ddf60>>: AttributeError: module 'gast' has no attribute 'Num'\n"
     ]
    }
   ],
   "source": [
    "((encoder_fw_outputs,encoder_bw_outputs),\n",
    " (encoder_fw_final_state,encoder_bw_final_state)) = tf.nn.bidirectional_dynamic_rnn(cell_fw=stacked_cells, \n",
    "                                                                 cell_bw=stacked_cells, \n",
    "                                                                 inputs=encoder_embedded, \n",
    "                                                                 sequence_length=input_data_len, \n",
    "                                                                 dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QVKq1wurwsOm"
   },
   "outputs": [],
   "source": [
    "encoder_outputs = tf.concat((encoder_fw_outputs,encoder_bw_outputs),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 99743,
     "status": "ok",
     "timestamp": 1589884316601,
     "user": {
      "displayName": "Abonia Sojasingarayar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiGI2S6plDhEjXinzvOnzVjhgSjbT_2_mUe0Ud1xA=s64",
      "userId": "02695506849043029320"
     },
     "user_tz": -120
    },
    "id": "XvdjQBE6wsOp",
    "outputId": "50f3bc6f-2bb3-43cd-a90a-0e9c81b5e8a0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'concat:0' shape=(?, ?, 1024) dtype=float32>"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qDzVB8xN6Vzz"
   },
   "source": [
    "### <b>class LSTMStateTuple</b>\n",
    "Tuple used by LSTM Cells for state_size, zero_state, and output state.\n",
    "\n",
    "Stores two elements: (c, h), in that order. Where c is the hidden state and h is the output.\n",
    "\n",
    "Only used when state_is_tuple=True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QsFapqt-wsOt"
   },
   "outputs": [],
   "source": [
    "encoder_state_c = tf.concat((encoder_fw_final_state.c,encoder_bw_final_state.c),1)\n",
    "encoder_state_h = tf.concat((encoder_fw_final_state.h,encoder_bw_final_state.h),1)\n",
    "encoder_states = tf.nn.rnn_cell.LSTMStateTuple(c=encoder_state_c,h=encoder_state_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 99728,
     "status": "ok",
     "timestamp": 1589884316602,
     "user": {
      "displayName": "Abonia Sojasingarayar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiGI2S6plDhEjXinzvOnzVjhgSjbT_2_mUe0Ud1xA=s64",
      "userId": "02695506849043029320"
     },
     "user_tz": -120
    },
    "id": "8qEgz1PdwsOv",
    "outputId": "7450b61c-5381-4e5b-d223-11ddef805cf5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMStateTuple(c=<tf.Tensor 'concat_1:0' shape=(?, 1024) dtype=float32>, h=<tf.Tensor 'concat_2:0' shape=(?, 1024) dtype=float32>)"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4L92BBY-6Vz5"
   },
   "source": [
    "# <center> Decoder</center>\n",
    "### <b>strided_slice</b>\n",
    "To a first order, this operation extracts a slice of size <b>end - begin</b> from a tensor input starting at the location specified by begin. The slice continues by adding stride to the begin index until all dimensions are not less than end. Note that components of stride can be negative, which causes a reverse slice.\n",
    "\n",
    "<b>ex:</b>\n",
    "\n",
    "begin = [1, 0, 0] and end = [2, 1, 3]. Also, all the strides are 1. Work your way backwards, from the last dimension.\n",
    "\n",
    "Start with element [1,0,0]. Now increase the last dimension only by its stride amount, giving you [1,0,1]. Keep doing this until you reach the limit. Something like [1,0,2], [1,0,3] (end of the loop). Now in your next iteration, start by incrementing the second to last dimension and resetting the last dimension, [1,1,0]. Here the second to last dimension is equal to end[1], so move to the first dimension (third to last) and reset the rest, giving you [2,0,0]. Again you are at the first dimension’s limit, so quit the loop.\n",
    "\n",
    "In our case: input=target_data,begin=[0,0],end=[batchsize,-1], stride[1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ecXG9168wsOz"
   },
   "outputs": [],
   "source": [
    "main = tf.strided_slice(target_data, [0, 0], [batch_size, -1], [1, 1])\n",
    "decoder_input = tf.concat([tf.fill([batch_size, 1],vocabs_to_index['<GO>']), main], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UAvG9wW1wsO3"
   },
   "outputs": [],
   "source": [
    "#sam process as followed in encoder embedding and lookups\n",
    "decoder_embeddings = tf.Variable(tf.random_uniform([target_vocab_size, embed_size], -1, 1))\n",
    "dec_cell_inputs = tf.nn.embedding_lookup(decoder_embeddings, decoder_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B3N5JtvZwsO8"
   },
   "outputs": [],
   "source": [
    "dec_cell = lstm(rnn_size*2,keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 99707,
     "status": "ok",
     "timestamp": 1589884316604,
     "user": {
      "displayName": "Abonia Sojasingarayar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiGI2S6plDhEjXinzvOnzVjhgSjbT_2_mUe0Ud1xA=s64",
      "userId": "02695506849043029320"
     },
     "user_tz": -120
    },
    "id": "nfmoMirUwsO_",
    "outputId": "f2a1be47-75fc-4d47-d77d-984bf67a771c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.ops.rnn_cell_impl.DropoutWrapper at 0x7f9253219908>"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hspUwnXs6V0D"
   },
   "source": [
    "### Dense layer\n",
    "\n",
    "Single output layer\n",
    "\n",
    "target_vocab_size=dimensionality of the output space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZyZQ2NR6wsPC"
   },
   "outputs": [],
   "source": [
    "#output layer for decoder\n",
    "dense_layer = tf.layers.Dense(target_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4ODIItjHaSpM"
   },
   "outputs": [],
   "source": [
    "#!pip install tensorflow_addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6s46aM_yaWx9"
   },
   "outputs": [],
   "source": [
    "#import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bQjDwxGa6V0G"
   },
   "source": [
    "### Class TrainingHelper\n",
    "\n",
    "A helper for use during training. Only reads inputs.\n",
    "\n",
    "Returned sample_ids are the argmax of the RNN output logits\n",
    "\n",
    "dec_cell_inputs=>inputs: A (structure of) input tensors.\n",
    "\n",
    "target_data_len=>sequence_length: An int32 vector tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 100589,
     "status": "ok",
     "timestamp": 1589884317508,
     "user": {
      "displayName": "Abonia Sojasingarayar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiGI2S6plDhEjXinzvOnzVjhgSjbT_2_mUe0Ud1xA=s64",
      "userId": "02695506849043029320"
     },
     "user_tz": -120
    },
    "id": "TR4iLAuDwsPJ",
    "outputId": "2b6e2414-f722-400a-eac7-f54255c2c37b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_helper = tf.contrib.seq2seq.TrainingHelper(dec_cell_inputs, target_data_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pha09cxC6V0J"
   },
   "source": [
    "### Cell state initializer\n",
    "<b>attention_cell.zero_state</b>\n",
    "\n",
    "The two are different things. state_is_tuple is used on LSTM cells because the state of LSTM cells is a tuple. cell.zero_state is the initializer of the state for all RNN cells.\n",
    "\n",
    "You will generally prefer cell.zero_state function as it will initialize the required state class depending on whether state_is_tuple is true or not.\n",
    "\n",
    "See this GitHub issue where you can see the cell.zero_state recommended - \"use the zero_state function on the cell object\".\n",
    "\n",
    "Another reason why you may want cell.zero_state is because it is agnostic of the type of the cell (LSTM, GRU, RNN) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 100579,
     "status": "ok",
     "timestamp": 1589884317509,
     "user": {
      "displayName": "Abonia Sojasingarayar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiGI2S6plDhEjXinzvOnzVjhgSjbT_2_mUe0Ud1xA=s64",
      "userId": "02695506849043029320"
     },
     "user_tz": -120
    },
    "id": "5FJBKKGywsPN",
    "outputId": "937d5b87-c740-47c0-9600-43baab9ab8e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9246e19198>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9246e19198>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9246e19198>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9246e19198>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    }
   ],
   "source": [
    "attention_cell = attention(rnn_size,encoder_outputs,target_data_len,dec_cell)\n",
    "state = attention_cell.zero_state(dtype=tf.float32, batch_size=batch_size)\n",
    "state = state.clone(cell_state=encoder_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HReziUbn6V0M"
   },
   "source": [
    "### Class BasicDecoder\n",
    "Basic sampling decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BMXJ5P_9wsPP"
   },
   "outputs": [],
   "source": [
    "decoder_train = tf.contrib.seq2seq.BasicDecoder(cell=attention_cell, helper=train_helper, \n",
    "                                                  initial_state=state,\n",
    "                                                  output_layer=dense_layer) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mtFRUCp-6V0O"
   },
   "source": [
    "\n",
    "### Class dynamic_decode\n",
    "Perform dynamic decoding with decoder.\n",
    "\n",
    "Calls initialize() once and step() repeatedly on the Decoder object.\n",
    "\n",
    "impute_finished: Python boolean. If True, then states for batch entries which are marked as finished get copied through and the corresponding outputs get zeroed out. This causes some slowdown at each time step, but ensures that the final state and outputs have the correct values and that backprop ignores time steps that were marked as finished.\n",
    "\n",
    "maximum_iterations: maximum allowed number of decoding steps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 101531,
     "status": "ok",
     "timestamp": 1589884318477,
     "user": {
      "displayName": "Abonia Sojasingarayar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiGI2S6plDhEjXinzvOnzVjhgSjbT_2_mUe0Ud1xA=s64",
      "userId": "02695506849043029320"
     },
     "user_tz": -120
    },
    "id": "8Vcsu2S0wsPR",
    "outputId": "bfcf5ff1-4068-4e34-f6f0-1f365752ef40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method AttentionWrapper.call of <tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper object at 0x7f9252638588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method AttentionWrapper.call of <tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper object at 0x7f9252638588>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method AttentionWrapper.call of <tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper object at 0x7f9252638588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method AttentionWrapper.call of <tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper object at 0x7f9252638588>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f92532196d8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f92532196d8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f92532196d8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f92532196d8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9246e190f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9246e190f0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9246e190f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9246e190f0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9246e19240>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9246e19240>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9246e19240>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9246e19240>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f925efd47b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f925efd47b8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f925efd47b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f925efd47b8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    }
   ],
   "source": [
    "outputs_train, _, _ = tf.contrib.seq2seq.dynamic_decode(decoder_train, \n",
    "                                                  impute_finished=True, \n",
    "                                                  maximum_iterations=tf.reduce_max(target_data_len))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7M5KHcEE6V0Q"
   },
   "source": [
    "# Greedy Search\n",
    "A simple approximation is to use a greedy search that selects the most likely word at each step in the output sequence.\n",
    "\n",
    "This approach has the benefit that it is very fast, but the quality of the final output sequences may be far from optimal.\n",
    "\n",
    "ex:define a sequence of 10 words over a vocab of 5 words\n",
    "\n",
    "\n",
    "        data = [[0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "               [0.5, 0.4, 0.3, 0.2, 0.1],\n",
    "               [0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "               [0.5, 0.4, 0.3, 0.2, 0.1],\n",
    "               [0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "               [0.5, 0.4, 0.3, 0.2, 0.1],\n",
    "               [0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "               [0.5, 0.4, 0.3, 0.2, 0.1],\n",
    "               [0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "               [0.5, 0.4, 0.3, 0.2, 0.1]]\n",
    "     \n",
    "After applying greedy decoder that mapped back to words in the vocabulary. \n",
    "\n",
    "Return the words which have maximum probability at athose time \n",
    "\n",
    "               [4, 0, 4, 0, 4, 0, 4, 0, 4, 0]\n",
    "\n",
    "        \n",
    "### Class GreedyEmbeddingHelper\n",
    "\n",
    "A helper for use during inference.\n",
    "\n",
    "Uses the argmax of the output (treated as logits) and passes the result through an embedding layer to get the next input.\n",
    "\n",
    "embedding: A callable that takes a vector tensor of ids (argmax ids), or the params argument for embedding_lookup. The returned tensor will be passed to the decoder input.\n",
    "\n",
    "start_tokens: int32 vector shaped [batch_size], the start tokens.\n",
    "\n",
    "end_token: int32 scalar, the token that marks end of decoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jf02Hu8ewsPV"
   },
   "outputs": [],
   "source": [
    "infer_helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(decoder_embeddings, \n",
    "                                                          tf.fill([batch_size], vocabs_to_index['<GO>']), \n",
    "                                                          vocabs_to_index['<EOS>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KUcM6qQOwsPX"
   },
   "outputs": [],
   "source": [
    "decoder_infer = tf.contrib.seq2seq.BasicDecoder(cell=attention_cell, helper=infer_helper, \n",
    "                                                  initial_state=state,\n",
    "                                                  output_layer=dense_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 101510,
     "status": "ok",
     "timestamp": 1589884318480,
     "user": {
      "displayName": "Abonia Sojasingarayar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiGI2S6plDhEjXinzvOnzVjhgSjbT_2_mUe0Ud1xA=s64",
      "userId": "02695506849043029320"
     },
     "user_tz": -120
    },
    "id": "pq0kpF-BwsPY",
    "outputId": "5a1fdb5a-7809-4c5a-c02e-b88deb183c26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method AttentionWrapper.call of <tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper object at 0x7f9252638588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method AttentionWrapper.call of <tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper object at 0x7f9252638588>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method AttentionWrapper.call of <tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper object at 0x7f9252638588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method AttentionWrapper.call of <tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper object at 0x7f9252638588>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f92532196d8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f92532196d8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f92532196d8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f92532196d8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9246e190f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9246e190f0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9246e190f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9246e190f0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9246e19240>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9246e19240>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9246e19240>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9246e19240>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f925efd47b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f925efd47b8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f925efd47b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f925efd47b8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    }
   ],
   "source": [
    "outputs_infer, _, _ = tf.contrib.seq2seq.dynamic_decode(decoder_infer, impute_finished=True,\n",
    "                                                          maximum_iterations=tf.reduce_max(target_data_len))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xxwJpviT6V0X"
   },
   "source": [
    "### Class identity\n",
    "Return a tensor with the same shape and contents as input.\n",
    "\n",
    "input=outputs_train.rnn_output for logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D7e00xllwsPb"
   },
   "outputs": [],
   "source": [
    "training_logits = tf.identity(outputs_train.rnn_output, name='logits')\n",
    "inference_logits = tf.identity(outputs_infer.sample_id, name='predictions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w8DEzPWj6V0b"
   },
   "source": [
    "### Padding and Masking\n",
    "Now that all samples have a uniform length, the model must be informed that some part of the data is actually padding and should be ignored. That mechanism is <b>masking</b>.\n",
    "ex:\n",
    "\n",
    "    [\n",
    "      [\"The\", \"weather\", \"will\", \"be\", \"nice\", \"tomorrow\"],\n",
    "      [\"How\", \"are\", \"you\", \"doing\", \"today\"],\n",
    "      [\"Hello\", \"world\", \"!\"]\n",
    "    ]\n",
    "can also be \n",
    "\n",
    "    [\n",
    "      [83, 91, 1, 645, 1253, 927],\n",
    "      [73, 8, 3215, 55, 927],\n",
    "      [71, 1331, 4231]\n",
    "    ]\n",
    "Afetr padding\n",
    "\n",
    "    [[  83   91    1  645 1253  927]\n",
    "     [  73    8 3215   55  927    0]\n",
    "     [ 711  632   71    0    0    0]]\n",
    "     \n",
    "After masking\n",
    "\n",
    "    tf.Tensor(\n",
    "    [[ True  True  True  True  True  True]\n",
    "     [ True  True  True  True  True False]\n",
    "     [ True  True  True False False False]], shape=(3, 6), dtype=bool)\n",
    "### Class sequence_mask\n",
    "When using the Functional API or the Sequential API, a mask generated by an Embedding or Masking layer will be propagated through the network for any layer that is capable of using them (for example, RNN layers). \n",
    "\n",
    "Note that in the call method of a subclassed model or layer, masks aren't automatically propagated, so you will need to manually pass a mask argument to any layer that needs one. \n",
    "\n",
    "Returns a mask tensor representing the first N positions of each cell.\n",
    "\n",
    "\n",
    "If lengths has shape [d_1, d_2, ..., d_n] the resulting tensor mask has dtype and \n",
    "\n",
    "shape [d_1, d_2, ..., d_n, maxlen], with\n",
    "\n",
    "mask[i_1, i_2, ..., i_n, j] = (j < lengths[i_1, i_2, ..., i_n])\n",
    "\n",
    "Examples:\n",
    "tf.sequence_mask([1, 3, 2], 5)  \n",
    "                                # [[True, False, False, False, False],\n",
    "                                #  [True, True, True, False, False],\n",
    "                                #  [True, True, False, False, False]]\n",
    "\n",
    "tf.sequence_mask([[1, 3],[2,0]])  \n",
    "                                  # [[[True, False, False],\n",
    "                                  #   [True, True, True]],\n",
    "                                  #  [[True, True, False],\n",
    "                                  #   [False, False, False]]]\n",
    "                                  \n",
    "length=target_data_len\n",
    "\n",
    "max_len=tf.reduce_max(target_data_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pCczbxr-wsPd"
   },
   "outputs": [],
   "source": [
    "masks = tf.sequence_mask(target_data_len, tf.reduce_max(target_data_len), dtype=tf.float32, name='masks')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L3f8LEFS6V0d"
   },
   "source": [
    "### Class sequence_loss\n",
    "Weighted cross-entropy loss for a sequence of logits.\n",
    "\n",
    "logits: A Tensor of shape [batch_size, sequence_length, num_decoder_symbols] and dtype float. The logits correspond to the prediction across all classes at each timestep.\n",
    "\n",
    "targets: A Tensor of shape [batch_size, sequence_length] and dtype int. The target represents the true class at each timestep.\n",
    "\n",
    "weights: A Tensor of shape [batch_size, sequence_length] and dtype float. weights constitutes the weighting of each prediction in the sequence. When using weights as masking, set all valid timesteps to 1 and all padded timesteps to 0, e.g. a mask returned by tf.sequence_mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "txKobnLEwsPf"
   },
   "outputs": [],
   "source": [
    "cost = tf.contrib.seq2seq.sequence_loss(training_logits,target_data,masks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oLYjX5Sd6V0h"
   },
   "source": [
    "## <center> Adam Optimizer</center>\n",
    "\n",
    "Adam is different to classical stochastic gradient descent.\n",
    "\n",
    "Stochastic gradient descent maintains a single learning rate (termed alpha) for all weight updates and the learning rate does not change during training.\n",
    "\n",
    "A learning rate is maintained for each network weight (parameter) and separately adapted as learning unfolds.\n",
    "\n",
    "The method computes individual adaptive learning rates for different parameters from estimates of first and second moments of the gradients.\n",
    "\n",
    "The authors describe Adam as combining the advantages of two other extensions of stochastic gradient descent. Specifically:\n",
    "\n",
    "<b>Adaptive Gradient Algorithm (AdaGrad)</b> that maintains a per-parameter learning rate that improves performance on problems with sparse gradients (e.g. natural language and computer vision problems).\n",
    "\n",
    "<b>Root Mean Square Propagation (RMSProp)</b> that also maintains per-parameter learning rates that are adapted based on the average of recent magnitudes of the gradients for the weight (e.g. how quickly it is changing). This means the algorithm does well on online and non-stationary problems (e.g. noisy).\n",
    "Adam realizes the benefits of both AdaGrad and RMSProp.\n",
    "\n",
    "Instead of adapting the parameter learning rates based on the average first moment (the mean) as in RMSProp, Adam also makes use of the average of the second moments of the gradients (the uncentered variance).\n",
    "\n",
    "Adam is a replacement optimization algorithm for stochastic gradient descent for training deep learning models.\n",
    "Adam combines the best properties of the AdaGrad and RMSProp algorithms to provide an optimization algorithm that can handle sparse gradients on noisy problems.\n",
    "Adam is relatively easy to configure where the default configuration parameters do well on most problems.\n",
    "\n",
    "alpha (in our case lr_rate): Also referred to as the learning rate or step size. The amount that the weights are updated during training is referred to as the step size or the “learning rate.”\n",
    "\n",
    "\n",
    "The proportion that weights are updated (e.g. 0.001). Larger values (e.g. 0.3) results in faster initial learning before the rate is updated. Smaller values (e.g. 1.0E-5) slow learning right down during training\n",
    "\n",
    "source:https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wsg4xpVIwsPi"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(lr_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mAC-_2bS6V0k"
   },
   "source": [
    "#  Gradient Clipping\n",
    "Gradient clipping is a technique to prevent exploding gradients in very deep networks, usually in recurrent neural networks. A neural network is a learning algorithm, also called neural network or neural net, that uses a network of functions to understand and translate data input into a specific output. This type of learning algorithm is designed based on the way neurons function in the human brain. There are many ways to compute gradient clipping, but a common one is to rescale gradients so that their norm is at most a particular value. With gradient clipping, pre-determined gradient threshold be introduced, and  then gradients norms that exceed this threshold are scaled down to match the norm.  This prevents any gradient to have norm greater than the threshold and thus the gradients are clipped.  There is an introduced bias in the resulting values from the gradient, but gradient clipping can keep things stable. \n",
    "\n",
    "<b>Why is this Useful?</b>\n",
    "Training recurrent neural networks can be very difficult. Two common issues with training recurrent neural networks are vanishing gradients and exploding gradients. Exploding gradients can occur when the gradient becomes too large and error gradients accumulate, resulting in an unstable network. Vanishing gradients can happen when optimization gets stuck at a certain point because the gradient is too small to progress. Gradient clipping can prevent these issues in the gradients that mess up the parameters during training.\n",
    "\n",
    "![title](DocImg/gradclip.png)\n",
    "\n",
    "<center><i>Source:https://deepai.org/</i></center>\n",
    "### clip_by_value\n",
    "Clips tensor values to a specified min and max.\n",
    "\n",
    "Compute gradients of loss for the variables in var_list.\n",
    "\n",
    "This is the first part of minimize(). It returns a list of (gradient, variable) pairs where \"gradient\" is the gradient for \"variable\". Note that \"gradient\" can be a Tensor, an IndexedSlices, or None if there is no gradient for the given variable.\n",
    "\n",
    "loss: A Tensor containing the value to minimize or a callable taking no arguments which returns the value to minimize. When eager execution is enabled it must be a callable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jcrBNbOFwsPk"
   },
   "outputs": [],
   "source": [
    "gradients = optimizer.compute_gradients(cost)\n",
    "capped_gradients = [(tf.clip_by_value(grad, -1., 1.), var) for grad, var in gradients if grad is not None]\n",
    "train_op = optimizer.apply_gradients(capped_gradients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P-rCNHEf6V0n"
   },
   "source": [
    "# Padding\n",
    "Before training, we work on the dataset to convert the variable length sequences into fixed length sequences, by padding. We use a few special symbols to fill in the sequence.\n",
    "\n",
    "\n",
    "PAD : Filler\n",
    "\n",
    "GO : Start decoding\n",
    "\n",
    "UNK : Unknown; word not in vocabulary\n",
    "\n",
    "Consider the following query-response pair.\n",
    "\n",
    "Q : How are you?\n",
    "A : I am fine.\n",
    "\n",
    "Assuming that we would like our sentences (queries and responses) to be of fixed length, 10, this pair will be converted to:\n",
    "\n",
    "Q : [ PAD, PAD, PAD, PAD, PAD, PAD, “?”, “you”, “are”, “How” ]\n",
    "\n",
    "A : [ GO, “I”, “am”, “fine”, “.”, EOS, PAD, PAD, PAD, PAD ]\n",
    "\n",
    "EOS : End of sentence\n",
    "\n",
    "The result of the padding sequences is pretty straight forward. You can now observe that the list of sentences that have been padded out into a matrix where each row in the matrix has an encoded sentence with the same length.Its computationaly expensive as we work with large dataset there we have bucketing techinique but its not applied for the moment.\n",
    "\n",
    "\n",
    "# Bucketing\n",
    "Introduction of padding did solve the problem of variable length sequences, but consider the case of large sentences. If the largest sentence in our dataset is of length 100, we need to encode all our sentences to be of length 100, in order to not lose any words. Now, what happens to “How are you?” ? There will be 97 PAD symbols in the encoded version of the sentence. This will overshadow the actual information in the sentence.\n",
    "\n",
    "Bucketing kind of solves this problem, by putting sentences into buckets of different sizes. Consider this list of buckets : [ (5,10), (10,15), (20,25), (40,50) ]. If the length of a query is 4 and the length of its response is 4 (as in our previous example), we put this sentence in the bucket (5,10). The query will be padded to length 5 and the response will be padded to length 10. While running the model (training or predicting), we use a different model for each bucket, compatible with the lengths of query and response. All these models, share the same parameters and hence function exactly the same way.\n",
    "\n",
    "If we are using the bucket (5,10), our sentences will be encoded to :\n",
    "\n",
    "Q : [ PAD, “?”, “you”, “are”, “How” ]\n",
    "\n",
    "A : [ GO, “I”, “am”, “fine”, “.”, EOS, PAD, PAD, PAD, PAD ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hy8u3-bjwsPo"
   },
   "outputs": [],
   "source": [
    "def pad_sentence(sentence_batch, pad_int):\n",
    "    padded_seqs = []\n",
    "    seq_lens = []\n",
    "    max_sentence_len = max([len(sentence) for sentence in sentence_batch])\n",
    "    for sentence in sentence_batch:\n",
    "        padded_seqs.append(sentence + [pad_int] * (max_sentence_len - len(sentence)))\n",
    "        seq_lens.append(len(sentence))\n",
    "    return padded_seqs, seq_lens\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jdAd3e5o6V0q"
   },
   "source": [
    "# Accuracy computation\n",
    "<b>np.pad</b> will  take the input array and add the padding based on the shape \n",
    "\n",
    "<b>np.equal</b>compare the target and prediction elementwise\n",
    "\n",
    "<b>np.mean</b>Average of the inputs given\n",
    "\n",
    "    target = [1, 2, 3, 4, 5]\n",
    "    print(np.pad(target, (2, 3), 'constant', constant_values=(4, 6)))\n",
    "    output: [4 4 1 2 3 4 5 6 6 6]\n",
    "    target='Iam good'=[1 5]___length=2,  logits='Iam doing good'=[1 7 5]___length=3\n",
    "    if max_seq=3  then target=[1 5 0]   (After np.pad-Pad an array.)\n",
    "                       logits=[1 7 5]\n",
    "    take mean to get average accuracy of all batch:\n",
    "        compare sentence using   np.equal([1, 5, 0], [1, 7 ,5])           output:[ True False False]\n",
    "        mean of the result using np.mean(np.equal([1, 5, 0], [1, 7 ,5]))) output:0.3333333333\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SgVkMCsmwsPq"
   },
   "outputs": [],
   "source": [
    "def get_accuracy(target, logits):\n",
    "    max_seq = max(len(target[1]), logits.shape[1])\n",
    "    if max_seq - len(target[1]):\n",
    "        target = np.pad(\n",
    "            target,\n",
    "            [(0,0),(0,max_seq - len(target[1]))],\n",
    "            'constant')\n",
    "    if max_seq - logits.shape[1]:\n",
    "        logits = np.pad(\n",
    "            logits,\n",
    "            [(0,0),(0,max_seq - logits.shape[1])],\n",
    "            'constant')\n",
    "\n",
    "    return np.mean(np.equal(target, logits))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nkW6N-cs6V0t"
   },
   "source": [
    "# Train and Test data split\n",
    "As we know input and output will be our questions and answers.Here we are splliting our dataset wrt batch size(128)\n",
    "\n",
    "ex:Questions from 1 to 128  index in questions_int list will be our validation traing set and 128 to the end of list will be our train data its because as we need less data for validation than training\n",
    "\n",
    "Same goes for test data from answers_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V8oeeDm-wsPr"
   },
   "outputs": [],
   "source": [
    "train_data = questions_int[batch_size:]\n",
    "test_data = answers_int[batch_size:]\n",
    "val_train_data = questions_int[:batch_size]\n",
    "val_test_data = answers_int[:batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 103344,
     "status": "ok",
     "timestamp": 1589884320357,
     "user": {
      "displayName": "Abonia Sojasingarayar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiGI2S6plDhEjXinzvOnzVjhgSjbT_2_mUe0Ud1xA=s64",
      "userId": "02695506849043029320"
     },
     "user_tz": -120
    },
    "id": "MQ-XF1liwsPu",
    "outputId": "77f84a56-17e2-42eb-d4ee-ae8410deb298"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22608"
      ]
     },
     "execution_count": 46,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UMUSXQHC6V0z"
   },
   "source": [
    "# Prepare train test validation set\n",
    "\n",
    "we need to pad the sentence before use it to validate our model as we seen in padding section.\n",
    "As our vocabulary index already has the word 'PAD' it.checking it us:\n",
    "\n",
    "vocabs_to_index['<PAD>']--->6283(index where its located)\n",
    "    \n",
    "So padding the sentence if max length of sentence in vocab index is 4 as ex:\n",
    "\n",
    "    ['how','are','you']=[0, 1, 2]                 -Before padding\n",
    "    ['how','are','you','']=[0, 1, 2,6283]         -After padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tsSesPuRwsPw"
   },
   "outputs": [],
   "source": [
    "pad_int = vocabs_to_index['<PAD>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9-KGHuRrwsPz"
   },
   "outputs": [],
   "source": [
    "val_batch_x,val_batch_len = pad_sentence(val_train_data,pad_int)\n",
    "val_batch_y,val_batch_len_y = pad_sentence(val_test_data,pad_int)\n",
    "val_batch_x = np.array(val_batch_x)\n",
    "val_batch_y = np.array(val_batch_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S4CmZo3G6V05"
   },
   "source": [
    "# Round the length of train data \n",
    "we need to round the length of train data wrt batch size in order to have equal number of sentence in each batch \n",
    "\n",
    "For ex: \n",
    "        \n",
    "     we have length of train data=103 and our bacth size=10\n",
    "        103/10=10.3 \n",
    "     we cant have 10.3 data so we need to round sentence in batch to 10 so now we must get the rounded train data to obtain the same for whole training set .its done as follow:\n",
    "        10*10=100\n",
    "     So our round length of train data is 100 we dont care about the the 3 sentence which is left \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CzX0zA7zwsP2"
   },
   "outputs": [],
   "source": [
    "no_of_batches = math.floor(len(train_data)//batch_size)\n",
    "round_no = no_of_batches*batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SaEhvQ_A6V08"
   },
   "source": [
    "### Sentence to sequence\n",
    "So as given below if we have a question sentence 'how are you' it must not be given as it is in our rnn it must be converted into vector\n",
    "\n",
    "Ex:\n",
    "    \n",
    "    'how are you' to  [0, 1, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qHWZdMUc6V08"
   },
   "outputs": [],
   "source": [
    "def sentence_to_seq(sentence, vocabs_to_index):\n",
    "    results = []\n",
    "    for word in sentence.split(\" \"):\n",
    "        if word in vocabs_to_index:\n",
    "            results.append(vocabs_to_index[word])\n",
    "        else:\n",
    "            results.append(vocabs_to_index['<UNK>'])        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 103322,
     "status": "ok",
     "timestamp": 1589884320360,
     "user": {
      "displayName": "Abonia Sojasingarayar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiGI2S6plDhEjXinzvOnzVjhgSjbT_2_mUe0Ud1xA=s64",
      "userId": "02695506849043029320"
     },
     "user_tz": -120
    },
    "id": "UM46TrAk6V0-",
    "outputId": "802ac815-20f4-44f6-a084-c6da8c1eec73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 14, 12]\n"
     ]
    }
   ],
   "source": [
    "question_sentence = 'where are you'\n",
    "question_sentence = sentence_to_seq(question_sentence, vocabs_to_index)\n",
    "print(question_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8-hc3PL96V1A"
   },
   "source": [
    "# Tf Session Run/Train Model\n",
    "Only after running <b>tf.global_variables_initializer()</b> in a session our variables hold the values we told them to hold when we declare them (tf.Variable(tf.zeros(...)), tf.Variable(tf.random_normal(...)),...).\n",
    "\n",
    "From the TF doc :\n",
    "    \n",
    "    \n",
    "    Calling tf.Variable() adds several ops to the graph:\n",
    "    A variable op that holds the variable value.An initializer op that sets the variable to its initial value. This is actually a tf.assign op.The ops for the initial value, such as the zeros op for the biases variable in the example are also added to the graph.\n",
    "\n",
    "    And also:Variable initializers must be run explicitly before other ops in your model can be run. The easiest way to do that is to add an op that runs all the variable initializers, and run that op before using the model.\n",
    "    \n",
    "### tqdm:\n",
    "\n",
    "    for bs in tqdm(range(0,round_no  ,batch_size)):\n",
    "    tqdm() takes bs(batch) and iterates over it, but each time it yields a new bs (between each iteration of the loop), it also updates a progress bar in out output cell. \n",
    "    \n",
    "### Session\n",
    "we need to run the session by providing the optimize which compute gradient wrt cost in each step and all input and target data  with its length.\n",
    "It can return <b>prediction</b> of input data and it must be compared with the original target data to get the accuracy of our model.and which will be cumulated further to get total accuracy for all the batches in a single epochs.\n",
    "Also return the <b>loss</b> for each batch which will be cumulated further to get total loss for all the batches in a single epochs\n",
    "\n",
    "<b>optional:</b>Also in each epoch the current tf session  takes the input_sentence(question) we assigned before such as 'how are you' as input and gives the prediction (answers).It can help us to review how much the predicted answers are releent to the reponse of human reply."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J-8YS5-v6V1A"
   },
   "outputs": [],
   "source": [
    "#file_writer = tf.summary.FileWriter('/content/drive/My Drive/ML Projects/Global IA/Seq2Seq-Chatbot/Notebook/model_weights/log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5L8a03YH6V1C"
   },
   "outputs": [],
   "source": [
    "#summaries_op = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11860376,
     "status": "ok",
     "timestamp": 1589904161071,
     "user": {
      "displayName": "Abonia Sojasingarayar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiGI2S6plDhEjXinzvOnzVjhgSjbT_2_mUe0Ud1xA=s64",
      "userId": "02695506849043029320"
     },
     "user_tz": -120
    },
    "id": "3T3wGVUEwsP5",
    "outputId": "68ba69e7-c12b-4f2b-9360-0fc3f3826326",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [03:44<00:00,  5.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1,Average_loss 5.519613, Average Accucracy 0.032996\n",
      "  Inputs Words: ['where', 'are', 'you']\n",
      "  Replied Words: i am <EOS>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [03:51<00:00,  5.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2,Average_loss 4.643066, Average Accucracy 0.076483\n",
      "  Inputs Words: ['where', 'are', 'you']\n",
      "  Replied Words: i am <EOS>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [04:01<00:00,  5.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3,Average_loss 4.314536, Average Accucracy 0.114628\n",
      "  Inputs Words: ['where', 'are', 'you']\n",
      "  Replied Words: i am <EOS>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [04:04<00:00,  5.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4,Average_loss 4.072271, Average Accucracy 0.130423\n",
      "  Inputs Words: ['where', 'are', 'you']\n",
      "  Replied Words: <UNK> <UNK> <EOS>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [04:05<00:00,  5.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5,Average_loss 3.872264, Average Accucracy 0.137644\n",
      "  Inputs Words: ['where', 'are', 'you']\n",
      "  Replied Words: <UNK> <UNK> <EOS>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [04:06<00:00,  5.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6,Average_loss 3.695115, Average Accucracy 0.142393\n",
      "  Inputs Words: ['where', 'are', 'you']\n",
      "  Replied Words: <UNK> <UNK> <EOS>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [04:06<00:00,  5.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7,Average_loss 3.500958, Average Accucracy 0.150294\n",
      "  Inputs Words: ['where', 'are', 'you']\n",
      "  Replied Words: <UNK> <UNK> <EOS>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [04:04<00:00,  5.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8,Average_loss 3.281604, Average Accucracy 0.161170\n",
      "  Inputs Words: ['where', 'are', 'you']\n",
      "  Replied Words: <UNK> <UNK> <EOS>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [04:02<00:00,  5.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9,Average_loss 3.061717, Average Accucracy 0.175315\n",
      "  Inputs Words: ['where', 'are', 'you']\n",
      "  Replied Words: right here <EOS>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [04:00<00:00,  5.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10,Average_loss 2.854275, Average Accucracy 0.185732\n",
      "  Inputs Words: ['where', 'are', 'you']\n",
      "  Replied Words: in here <EOS>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [03:59<00:00,  5.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11,Average_loss 2.656442, Average Accucracy 0.196467\n",
      "  Inputs Words: ['where', 'are', 'you']\n",
      "  Replied Words: right here <EOS>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [03:58<00:00,  5.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12,Average_loss 2.505334, Average Accucracy 0.200188\n",
      "  Inputs Words: ['where', 'are', 'you']\n",
      "  Replied Words: i am <EOS>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [03:54<00:00,  5.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13,Average_loss 2.296961, Average Accucracy 0.218432\n",
      "  Inputs Words: ['where', 'are', 'you']\n",
      "  Replied Words: i am here\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [03:57<00:00,  5.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14,Average_loss 2.075931, Average Accucracy 0.243430\n",
      "  Inputs Words: ['where', 'are', 'you']\n",
      "  Replied Words: <UNK> holiness <EOS>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [04:10<00:00,  5.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15,Average_loss 1.870057, Average Accucracy 0.268163\n",
      "  Inputs Words: ['where', 'are', 'you']\n",
      "  Replied Words: foodstorage room <EOS>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [04:06<00:00,  5.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16,Average_loss 1.697123, Average Accucracy 0.290113\n",
      "  Inputs Words: ['where', 'are', 'you']\n",
      "  Replied Words: foodstorage room <EOS>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [04:03<00:00,  5.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17,Average_loss 1.552821, Average Accucracy 0.310051\n",
      "  Inputs Words: ['where', 'are', 'you']\n",
      "  Replied Words: foodstorage room <EOS>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [04:02<00:00,  5.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18,Average_loss 1.427310, Average Accucracy 0.331558\n",
      "  Inputs Words: ['where', 'are', 'you']\n",
      "  Replied Words: foodstorage room <EOS>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [04:00<00:00,  5.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19,Average_loss 1.290676, Average Accucracy 0.354241\n",
      "  Inputs Words: ['where', 'are', 'you']\n",
      "  Replied Words: foodstorage room <EOS>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [04:02<00:00,  5.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20,Average_loss 1.105122, Average Accucracy 0.392504\n",
      "  Inputs Words: ['where', 'are', 'you']\n",
      "  Replied Words: foodstorage bed <EOS>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [04:03<00:00,  5.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21,Average_loss 0.964319, Average Accucracy 0.425167\n",
      "  Inputs Words: ['where', 'are', 'you']\n",
      "  Replied Words: foodstorage room <EOS>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [04:05<00:00,  5.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22,Average_loss 0.860011, Average Accucracy 0.451838\n",
      "  Inputs Words: ['where', 'are', 'you']\n",
      "  Replied Words: <UNK> holiness <EOS>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [04:06<00:00,  5.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23,Average_loss 0.780794, Average Accucracy 0.466464\n",
      "  Inputs Words: ['where', 'are', 'you']\n",
      "  Replied Words: foodstorage foodstorage <EOS>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [04:05<00:00,  5.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24,Average_loss 0.718443, Average Accucracy 0.480210\n",
      "  Inputs Words: ['where', 'are', 'you']\n",
      "  Replied Words: foodstorage here <EOS>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [04:06<00:00,  5.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25,Average_loss 0.656882, Average Accucracy 0.497773\n",
      "  Inputs Words: ['where', 'are', 'you']\n",
      "  Replied Words: foodstorage room <EOS>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [04:07<00:00,  5.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26,Average_loss 0.606963, Average Accucracy 0.508249\n",
      "  Inputs Words: ['where', 'are', 'you']\n",
      "  Replied Words: foodstorage room <EOS>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [04:07<00:00,  5.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27,Average_loss 0.552893, Average Accucracy 0.524673\n",
      "  Inputs Words: ['where', 'are', 'you']\n",
      "  Replied Words: i am <EOS>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [04:11<00:00,  5.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28,Average_loss 0.483380, Average Accucracy 0.544589\n",
      "  Inputs Words: ['where', 'are', 'you']\n",
      "  Replied Words: foodstorage room <EOS>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [04:11<00:00,  5.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29,Average_loss 0.418582, Average Accucracy 0.567116\n",
      "  Inputs Words: ['where', 'are', 'you']\n",
      "  Replied Words: foodstorage room <EOS>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [04:07<00:00,  5.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30,Average_loss 0.379460, Average Accucracy 0.576793\n",
      "  Inputs Words: ['where', 'are', 'you']\n",
      "  Replied Words: foodstorage room <EOS>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [04:00<00:00,  5.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31,Average_loss 0.356477, Average Accucracy 0.586737\n",
      "  Inputs Words: ['where', 'are', 'you']\n",
      "  Replied Words: foodstorage room <EOS>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [03:58<00:00,  5.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32,Average_loss 0.330986, Average Accucracy 0.594675\n",
      "  Inputs Words: ['where', 'are', 'you']\n",
      "  Replied Words: foodstorage room <EOS>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [03:58<00:00,  5.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33,Average_loss 0.305983, Average Accucracy 0.602406\n",
      "  Inputs Words: ['where', 'are', 'you']\n",
      "  Replied Words: foodstorage room <EOS>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [03:58<00:00,  5.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34,Average_loss 0.283745, Average Accucracy 0.608924\n",
      "  Inputs Words: ['where', 'are', 'you']\n",
      "  Replied Words: foodstorage room <EOS>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [04:12<00:00,  5.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35,Average_loss 0.262216, Average Accucracy 0.613548\n",
      "  Inputs Words: ['where', 'are', 'you']\n",
      "  Replied Words: foodstorage room <EOS>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [04:06<00:00,  5.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36,Average_loss 0.251971, Average Accucracy 0.618312\n",
      "  Inputs Words: ['where', 'are', 'you']\n",
      "  Replied Words: foodstorage room <EOS>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [04:11<00:00,  5.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37,Average_loss 0.239477, Average Accucracy 0.622559\n",
      "  Inputs Words: ['where', 'are', 'you']\n",
      "  Replied Words: foodstorage room <EOS>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [04:12<00:00,  5.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38,Average_loss 0.229772, Average Accucracy 0.623069\n",
      "  Inputs Words: ['where', 'are', 'you']\n",
      "  Replied Words: <UNK> am <EOS>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [04:11<00:00,  5.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39,Average_loss 0.220710, Average Accucracy 0.626901\n",
      "  Inputs Words: ['where', 'are', 'you']\n",
      "  Replied Words: foodstorage room <EOS>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [04:09<00:00,  5.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40,Average_loss 0.216487, Average Accucracy 0.627108\n",
      "  Inputs Words: ['where', 'are', 'you']\n",
      "  Replied Words: foodstorage room <EOS>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [04:10<00:00,  5.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41,Average_loss 0.213335, Average Accucracy 0.628085\n",
      "  Inputs Words: ['where', 'are', 'you']\n",
      "  Replied Words: foodstorage room <EOS>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [04:11<00:00,  5.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42,Average_loss 0.207484, Average Accucracy 0.628706\n",
      "  Inputs Words: ['where', 'are', 'you']\n",
      "  Replied Words: foodstorage room <EOS>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [04:12<00:00,  5.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43,Average_loss 0.202952, Average Accucracy 0.631170\n",
      "  Inputs Words: ['where', 'are', 'you']\n",
      "  Replied Words: <UNK> everywhere <EOS>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [04:10<00:00,  5.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44,Average_loss 0.198835, Average Accucracy 0.630963\n",
      "  Inputs Words: ['where', 'are', 'you']\n",
      "  Replied Words: foodstorage room <EOS>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [04:09<00:00,  5.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45,Average_loss 0.196496, Average Accucracy 0.632065\n",
      "  Inputs Words: ['where', 'are', 'you']\n",
      "  Replied Words: foodstorage room <EOS>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [04:09<00:00,  5.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46,Average_loss 0.196854, Average Accucracy 0.631370\n",
      "  Inputs Words: ['where', 'are', 'you']\n",
      "  Replied Words: foodstorage room <EOS>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [04:10<00:00,  5.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47,Average_loss 0.191218, Average Accucracy 0.631688\n",
      "  Inputs Words: ['where', 'are', 'you']\n",
      "  Replied Words: <UNK> am <EOS>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [04:10<00:00,  5.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48,Average_loss 0.186428, Average Accucracy 0.634233\n",
      "  Inputs Words: ['where', 'are', 'you']\n",
      "  Replied Words: foodstorage room <EOS>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [04:11<00:00,  5.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49,Average_loss 0.185115, Average Accucracy 0.634795\n",
      "  Inputs Words: ['where', 'are', 'you']\n",
      "  Replied Words: foodstorage room <EOS>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [04:09<00:00,  5.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50,Average_loss 0.182829, Average Accucracy 0.634936\n",
      "  Inputs Words: ['where', 'are', 'you']\n",
      "  Replied Words: foodstorage room <EOS>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [04:09<00:00,  5.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51,Average_loss 0.180024, Average Accucracy 0.634973\n",
      "  Inputs Words: ['where', 'are', 'you']\n",
      "  Replied Words: in here <EOS>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [04:09<00:00,  5.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52,Average_loss 0.178280, Average Accucracy 0.635809\n",
      "  Inputs Words: ['where', 'are', 'you']\n",
      "  Replied Words: foodstorage room <EOS>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [04:09<00:00,  5.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53,Average_loss 0.176270, Average Accucracy 0.634270\n",
      "  Inputs Words: ['where', 'are', 'you']\n",
      "  Replied Words: foodstorage room <EOS>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [04:09<00:00,  5.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54,Average_loss 0.174003, Average Accucracy 0.636978\n",
      "  Inputs Words: ['where', 'are', 'you']\n",
      "  Replied Words: foodstorage room <EOS>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [04:10<00:00,  5.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55,Average_loss 0.174037, Average Accucracy 0.634521\n",
      "  Inputs Words: ['where', 'are', 'you']\n",
      "  Replied Words: foodstorage room <EOS>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [04:10<00:00,  5.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56,Average_loss 0.172690, Average Accucracy 0.635557\n",
      "  Inputs Words: ['where', 'are', 'you']\n",
      "  Replied Words: foodstorage room <EOS>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [04:10<00:00,  5.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57,Average_loss 0.172547, Average Accucracy 0.636009\n",
      "  Inputs Words: ['where', 'are', 'you']\n",
      "  Replied Words: foodstorage room <EOS>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [04:09<00:00,  5.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58,Average_loss 0.169897, Average Accucracy 0.636682\n",
      "  Inputs Words: ['where', 'are', 'you']\n",
      "  Replied Words: foodstorage room <EOS>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [04:10<00:00,  5.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59,Average_loss 0.169903, Average Accucracy 0.637385\n",
      "  Inputs Words: ['where', 'are', 'you']\n",
      "  Replied Words: foodstorage room <EOS>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [04:12<00:00,  5.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60,Average_loss 0.169365, Average Accucracy 0.636127\n",
      "  Inputs Words: ['where', 'are', 'you']\n",
      "  Replied Words: foodstorage room <EOS>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [04:13<00:00,  5.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61,Average_loss 0.170015, Average Accucracy 0.636556\n",
      "  Inputs Words: ['where', 'are', 'you']\n",
      "  Replied Words: foodstorage room <EOS>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [04:14<00:00,  5.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62,Average_loss 0.168317, Average Accucracy 0.635217\n",
      "  Inputs Words: ['where', 'are', 'you']\n",
      "  Replied Words: foodstorage room <EOS>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [04:15<00:00,  5.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63,Average_loss 0.169033, Average Accucracy 0.636105\n",
      "  Inputs Words: ['where', 'are', 'you']\n",
      "  Replied Words: foodstorage room <EOS>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [04:14<00:00,  5.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64,Average_loss 0.166682, Average Accucracy 0.636867\n",
      "  Inputs Words: ['where', 'are', 'you']\n",
      "  Replied Words: foodstorage room <EOS>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [04:12<00:00,  5.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65,Average_loss 0.166812, Average Accucracy 0.638124\n",
      "  Inputs Words: ['where', 'are', 'you']\n",
      "  Replied Words: foodstorage room <EOS>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [04:05<00:00,  5.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66,Average_loss 0.165787, Average Accucracy 0.637451\n",
      "  Inputs Words: ['where', 'are', 'you']\n",
      "  Replied Words: foodstorage room <EOS>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [04:05<00:00,  5.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67,Average_loss 0.165129, Average Accucracy 0.636401\n",
      "  Inputs Words: ['where', 'are', 'you']\n",
      "  Replied Words: foodstorage room <EOS>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [04:04<00:00,  5.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68,Average_loss 0.160648, Average Accucracy 0.636933\n",
      "  Inputs Words: ['where', 'are', 'you']\n",
      "  Replied Words: <UNK> holiness <EOS>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [04:04<00:00,  5.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69,Average_loss 0.162570, Average Accucracy 0.637281\n",
      "  Inputs Words: ['where', 'are', 'you']\n",
      "  Replied Words: foodstorage room <EOS>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [04:04<00:00,  5.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70,Average_loss 0.164260, Average Accucracy 0.638694\n",
      "  Inputs Words: ['where', 'are', 'you']\n",
      "  Replied Words: foodstorage room <EOS>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [04:03<00:00,  5.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71,Average_loss 0.163949, Average Accucracy 0.637518\n",
      "  Inputs Words: ['where', 'are', 'you']\n",
      "  Replied Words: foodstorage room <EOS>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [04:04<00:00,  5.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72,Average_loss 0.162319, Average Accucracy 0.638391\n",
      "  Inputs Words: ['where', 'are', 'you']\n",
      "  Replied Words: foodstorage room <EOS>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [04:03<00:00,  5.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73,Average_loss 0.162019, Average Accucracy 0.637607\n",
      "  Inputs Words: ['where', 'are', 'you']\n",
      "  Replied Words: foodstorage room <EOS>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [04:00<00:00,  5.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74,Average_loss 0.162474, Average Accucracy 0.637888\n",
      "  Inputs Words: ['where', 'are', 'you']\n",
      "  Replied Words: foodstorage room <EOS>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [04:01<00:00,  5.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75,Average_loss 0.158191, Average Accucracy 0.638931\n",
      "  Inputs Words: ['where', 'are', 'you']\n",
      "  Replied Words: foodstorage room <EOS>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [04:01<00:00,  5.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76,Average_loss 0.159902, Average Accucracy 0.638620\n",
      "  Inputs Words: ['where', 'are', 'you']\n",
      "  Replied Words: foodstorage room <EOS>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [03:58<00:00,  5.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77,Average_loss 0.161107, Average Accucracy 0.636460\n",
      "  Inputs Words: ['where', 'are', 'you']\n",
      "  Replied Words: in here <EOS>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [03:56<00:00,  5.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78,Average_loss 0.161215, Average Accucracy 0.636386\n",
      "  Inputs Words: ['where', 'are', 'you']\n",
      "  Replied Words: foodstorage room <EOS>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [03:54<00:00,  5.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79,Average_loss 0.163130, Average Accucracy 0.636830\n",
      "  Inputs Words: ['where', 'are', 'you']\n",
      "  Replied Words: foodstorage room <EOS>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [03:54<00:00,  5.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80,Average_loss 0.160907, Average Accucracy 0.635861\n",
      "  Inputs Words: ['where', 'are', 'you']\n",
      "  Replied Words: foodstorage room <EOS>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "save_path = '/content/drive/My Drive/ML Projects/Global IA/Seq2Seq-Chatbot/Notebook/model_weights/model_weights'\n",
    "acc_plt = []\n",
    "loss_plt = []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for epoch in range(epochs):\n",
    "        #_, summaries_str = sess.run([train_op, summaries_op])\n",
    "        #fw.add_summary(summaries_str, global_step=i)\n",
    "        total_accuracy = 0.0\n",
    "        total_loss = 0.0\n",
    "        for bs in tqdm(range(0,round_no  ,batch_size)):\n",
    "          index = min(bs+batch_size, round_no )\n",
    "          #print(bs,index)\n",
    "      \n",
    "          #padding done seperately for each batch in training and testing data\n",
    "          batch_x,len_x = pad_sentence(train_data[bs:index],pad_int)\n",
    "          batch_y,len_y = pad_sentence(test_data[bs:index],pad_int)\n",
    "          batch_x = np.array(batch_x)\n",
    "          batch_y = np.array(batch_y)\n",
    "        \n",
    "          pred,loss_f,opt = sess.run([inference_logits,cost,train_op], \n",
    "                                      feed_dict={input_data:batch_x,\n",
    "                                                target_data:batch_y,\n",
    "                                                input_data_len:len_x,\n",
    "                                                target_data_len:len_y,\n",
    "                                                lr_rate:learning_rate,\n",
    "                                                keep_prob:0.75})\n",
    "\n",
    "          train_acc = get_accuracy(batch_y, pred)\n",
    "          total_loss += loss_f \n",
    "          total_accuracy+=train_acc\n",
    "    \n",
    "        total_accuracy /= (round_no // batch_size)\n",
    "    \n",
    "        total_loss /=  (round_no//batch_size)\n",
    "        acc_plt.append(total_accuracy)\n",
    "        loss_plt.append(total_loss)\n",
    "        prediction_logits = sess.run(inference_logits, {input_data: [question_sentence]*batch_size,\n",
    "                                         input_data_len: [len(question_sentence)]*batch_size,\n",
    "                                         target_data_len: [len(question_sentence)]*batch_size,              \n",
    "                                         keep_prob: 0.75,\n",
    "                                         })[0]\n",
    "        print('Epoch %d,Average_loss %f, Average Accucracy %f'%(epoch+1,total_loss,total_accuracy))\n",
    "        print('  Inputs Words: {}'.format([index_to_vocabs[i] for i in question_sentence]))\n",
    "        print('  Replied Words: {}'.format(\" \".join([index_to_vocabs[i] for i in prediction_logits])))\n",
    "        print('\\n')\n",
    "        saver = tf.train.Saver() \n",
    "        saver.save(sess, save_path)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 683
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2225,
     "status": "ok",
     "timestamp": 1589904163287,
     "user": {
      "displayName": "Abonia Sojasingarayar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiGI2S6plDhEjXinzvOnzVjhgSjbT_2_mUe0Ud1xA=s64",
      "userId": "02695506849043029320"
     },
     "user_tz": -120
    },
    "id": "t4hq0kHz6V1H",
    "outputId": "67ca3e32-46d3-45ba-dfaf-ccd7862f1ba9"
   },
   "outputs": [],
   "source": [
    "%tensorboard --logdir /content/drive/My Drive/ML Projects/Global IA/Seq2Seq-Chatbot/Notebook/model_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1589904163288,
     "user": {
      "displayName": "Abonia Sojasingarayar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiGI2S6plDhEjXinzvOnzVjhgSjbT_2_mUe0Ud1xA=s64",
      "userId": "02695506849043029320"
     },
     "user_tz": -120
    },
    "id": "WkzXCp_swsP9",
    "outputId": "e5b69cca-4983-4f5b-b8c7-c5616a41e8e9"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Accuracy vs Epochs\n",
    "plt.plot(range(epochs),acc_plt)\n",
    "plt.title(\"Change in Accuracy\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 601,
     "status": "ok",
     "timestamp": 1589904163880,
     "user": {
      "displayName": "Abonia Sojasingarayar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiGI2S6plDhEjXinzvOnzVjhgSjbT_2_mUe0Ud1xA=s64",
      "userId": "02695506849043029320"
     },
     "user_tz": -120
    },
    "id": "HcbTo1j0y9my",
    "outputId": "e311f6fd-2e96-4cda-8aba-cd8242a7db41"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#loss vs Epochs\n",
    "plt.plot(range(epochs),loss_plt)\n",
    "plt.title(\"Change in loss\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Lost')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VwUlywN4Ajzl"
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "39MSfl6AAlTS"
   },
   "outputs": [],
   "source": [
    "pickle.dump(acc_plt,open('accuracy.p','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XuRLcdV-BJQF"
   },
   "outputs": [],
   "source": [
    "pickle.dump(loss_plt,open('loss.p','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vOc7_Qoy6V1X"
   },
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "seGAxQNe6V1X"
   },
   "source": [
    "### Get tokens:\n",
    "Get all the codes/tokens we additionaly added in the vocab dictionary\n",
    "\n",
    "    6283 '<PAD>'\n",
    "    6284 '<EOS>'\n",
    "    6285 '<UNK>'\n",
    "    6286 '<GO>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 60,
     "status": "ok",
     "timestamp": 1589904163888,
     "user": {
      "displayName": "Abonia Sojasingarayar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiGI2S6plDhEjXinzvOnzVjhgSjbT_2_mUe0Ud1xA=s64",
      "userId": "02695506849043029320"
     },
     "user_tz": -120
    },
    "id": "Z9tjyWtGtorR",
    "outputId": "0558ac04-27d9-4d4c-a32c-e7edde685f84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6283\n",
      "6284\n",
      "6285\n",
      "6286\n"
     ]
    }
   ],
   "source": [
    "#get all the codes/tokens we additionaly added in the vocab dictionary\n",
    "garbage = []\n",
    "for code in codes:\n",
    "  print(vocabs_to_index[code])\n",
    "  garbage.append(vocabs_to_index[code])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lAf20xE66V1a"
   },
   "source": [
    "### Prepare the questions,Answers, and predicted answers\n",
    "In order to prepare the questions and human answer  and bot answer we need to clean the sentence by removing the token we discussed in the previous step.\n",
    "    \n",
    "    if we get the token of <EOS> we break the loop \n",
    "    if the word is not the one of the additional token <PAD>,<UNK>,<GO> then we wont consider these words.we must return the data without these tokens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5kv4x-p94Rvk"
   },
   "outputs": [],
   "source": [
    "#prepare the question,answer and prediction data\n",
    "def print_data(i,batch_x,index_to_vocabs):\n",
    "  data = []\n",
    "  for n in batch_x[i]:\n",
    "    if n==garbage[1]:\n",
    "      break\n",
    "    else:\n",
    "      if n not in [6283,6285,6286]:\n",
    "        data.append(index_to_vocabs[n])\n",
    "  return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bC1ih2B396Bm"
   },
   "outputs": [],
   "source": [
    "ques = []\n",
    "real_answer = []\n",
    "pred_answer = []\n",
    "for i in range(len(val_batch_x)):\n",
    "  ques.append(print_data(i,batch_x,index_to_vocabs))\n",
    "  real_answer.append(print_data(i,batch_y,index_to_vocabs))\n",
    "  pred_answer.append(print_data(i,pred,index_to_vocabs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sFgLIfGK6V1h"
   },
   "source": [
    "### Printing Real and predicted Answers\n",
    "So from the below output we can comes to a conclusion how well our trained model works with the validation set(size of batch_size i.e 128 rows) that we have created earlier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1589904163890,
     "user": {
      "displayName": "Abonia Sojasingarayar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiGI2S6plDhEjXinzvOnzVjhgSjbT_2_mUe0Ud1xA=s64",
      "userId": "02695506849043029320"
     },
     "user_tz": -120
    },
    "id": "QvUS1zq3_zqL",
    "outputId": "e2fee2c0-6304-42e9-f47e-5f8b36c2c826"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 1\n",
      "QUESTION: where did you get that\n",
      "REAL ANSWER: at the on\n",
      "PREDICTED ANSWER: at the on \n",
      "\n",
      "row 2\n",
      "QUESTION: did she believe you\n",
      "REAL ANSWER: i have no idea\n",
      "PREDICTED ANSWER: i have no idea \n",
      "\n",
      "row 3\n",
      "QUESTION: where is boyd\n",
      "REAL ANSWER: downstairs in the closet\n",
      "PREDICTED ANSWER: downstairs in the closet \n",
      "\n",
      "row 4\n",
      "QUESTION: what song\n",
      "REAL ANSWER: you send me\n",
      "PREDICTED ANSWER: you send me \n",
      "\n",
      "row 5\n",
      "QUESTION: the stone age\n",
      "REAL ANSWER: the postvegas man\n",
      "PREDICTED ANSWER: the postvegas man \n",
      "\n",
      "row 6\n",
      "QUESTION: the postvegas man\n",
      "REAL ANSWER: a mutant species\n",
      "PREDICTED ANSWER: a mutant species \n",
      "\n",
      "row 7\n",
      "QUESTION: a mutant species\n",
      "REAL ANSWER: okay boys smile\n",
      "PREDICTED ANSWER: okay boys smile \n",
      "\n",
      "row 8\n",
      "QUESTION: good times\n",
      "REAL ANSWER: real times\n",
      "PREDICTED ANSWER: real times \n",
      "\n",
      "row 9\n",
      "QUESTION: she is dead\n",
      "REAL ANSWER: it was an accident\n",
      "PREDICTED ANSWER: she is dead \n",
      "\n",
      "row 10\n",
      "QUESTION: shut up micheal\n",
      "REAL ANSWER: i killed my brother\n",
      "PREDICTED ANSWER: i killed my brother \n",
      "\n",
      "row 11\n",
      "QUESTION: don\n",
      "REAL ANSWER: that is that\n",
      "PREDICTED ANSWER: my violin is \n",
      "\n",
      "row 12\n",
      "QUESTION: that is that\n",
      "REAL ANSWER: enedina and paco\n",
      "PREDICTED ANSWER: i guess \n",
      "\n",
      "row 13\n",
      "QUESTION: enedina and paco\n",
      "REAL ANSWER: what about them\n",
      "PREDICTED ANSWER: what about them \n",
      "\n",
      "row 14\n",
      "QUESTION: which couch\n",
      "REAL ANSWER: that one\n",
      "PREDICTED ANSWER: that one \n",
      "\n",
      "row 15\n",
      "QUESTION: come down here you\n",
      "REAL ANSWER: who is she\n",
      "PREDICTED ANSWER: who is she \n",
      "\n",
      "row 16\n",
      "QUESTION: leave us alone\n",
      "REAL ANSWER: do not go\n",
      "PREDICTED ANSWER: do not go \n",
      "\n",
      "row 17\n",
      "QUESTION: what will the lady say\n",
      "REAL ANSWER: she will not even know\n",
      "PREDICTED ANSWER: she will not even know \n",
      "\n",
      "row 18\n",
      "QUESTION: how much is that\n",
      "REAL ANSWER: fifteen yards\n",
      "PREDICTED ANSWER: thousand \n",
      "\n",
      "row 19\n",
      "QUESTION: fifteen yards\n",
      "REAL ANSWER: that is fifteen by seven\n",
      "PREDICTED ANSWER: that is fifteen by seven \n",
      "\n",
      "row 20\n",
      "QUESTION: that is fifteen by seven\n",
      "REAL ANSWER: that is it\n",
      "PREDICTED ANSWER: that is it \n",
      "\n",
      "row 21\n",
      "QUESTION: and in the vegetable\n",
      "REAL ANSWER: that is good land\n",
      "PREDICTED ANSWER: that is good land \n",
      "\n",
      "row 22\n",
      "QUESTION: he was asking for it\n",
      "REAL ANSWER: but why why\n",
      "PREDICTED ANSWER: but why why \n",
      "\n",
      "row 23\n",
      "QUESTION: miss\n",
      "REAL ANSWER: are you jorge\n",
      "PREDICTED ANSWER: are you jorge \n",
      "\n",
      "row 24\n",
      "QUESTION: and your friend\n",
      "REAL ANSWER: she is left\n",
      "PREDICTED ANSWER: she is left \n",
      "\n",
      "row 25\n",
      "QUESTION: she is left\n",
      "REAL ANSWER: is she coming back\n",
      "PREDICTED ANSWER: is she coming back \n",
      "\n",
      "row 26\n",
      "QUESTION: you cannot leave\n",
      "REAL ANSWER: why not\n",
      "PREDICTED ANSWER: why not \n",
      "\n",
      "row 27\n",
      "QUESTION: why not\n",
      "REAL ANSWER: there's been an accident\n",
      "PREDICTED ANSWER: i do not know \n",
      "\n",
      "row 28\n",
      "QUESTION: why are you crying\n",
      "REAL ANSWER: i am afraid\n",
      "PREDICTED ANSWER: i am afraid \n",
      "\n",
      "row 29\n",
      "QUESTION: a black bull came\n",
      "REAL ANSWER: a black bull\n",
      "PREDICTED ANSWER: a black bull \n",
      "\n",
      "row 30\n",
      "QUESTION: very very\n",
      "REAL ANSWER: yes very very big\n",
      "PREDICTED ANSWER: yes very very big \n",
      "\n",
      "row 31\n",
      "QUESTION: when you are miss\n",
      "REAL ANSWER: good then let's go\n",
      "PREDICTED ANSWER: good then let's go \n",
      "\n",
      "row 32\n",
      "QUESTION: how do you feel\n",
      "REAL ANSWER: i have a headache\n",
      "PREDICTED ANSWER: i have a headache \n",
      "\n",
      "row 33\n",
      "QUESTION: how did you see me\n",
      "REAL ANSWER: from the\n",
      "PREDICTED ANSWER: from the \n",
      "\n",
      "row 34\n",
      "QUESTION: jesus you kill it\n",
      "REAL ANSWER: if you can catch him\n",
      "PREDICTED ANSWER: if you can catch him \n",
      "\n",
      "row 35\n",
      "QUESTION: their weapons missing\n",
      "REAL ANSWER: sid 67 is now armed\n",
      "PREDICTED ANSWER: sid 67 is now armed \n",
      "\n",
      "row 36\n",
      "QUESTION: sid 67 is now armed\n",
      "REAL ANSWER: where is my gun\n",
      "PREDICTED ANSWER: where is my gun \n",
      "\n",
      "row 37\n",
      "QUESTION: think you can do it\n",
      "REAL ANSWER: not from in here\n",
      "PREDICTED ANSWER: not from in here \n",
      "\n",
      "row 38\n",
      "QUESTION: by net\n",
      "REAL ANSWER: it feels so real\n",
      "PREDICTED ANSWER: it feels so real \n",
      "\n",
      "row 39\n",
      "QUESTION: that is wrong with parker\n",
      "REAL ANSWER: how should i know\n",
      "PREDICTED ANSWER: how should i know \n",
      "\n",
      "row 40\n",
      "QUESTION: i wonder how that\n",
      "REAL ANSWER: turn it down\n",
      "PREDICTED ANSWER: turn it down \n",
      "\n",
      "row 41\n",
      "QUESTION: she is beautiful you know\n",
      "REAL ANSWER: name is\n",
      "PREDICTED ANSWER: name is \n",
      "\n",
      "row 42\n",
      "QUESTION: enjoying yourself\n",
      "REAL ANSWER: you know i am\n",
      "PREDICTED ANSWER: you know i am \n",
      "\n",
      "row 43\n",
      "QUESTION: sid 67 is not\n",
      "REAL ANSWER: part of him is\n",
      "PREDICTED ANSWER: part of him is \n",
      "\n",
      "row 44\n",
      "QUESTION: you okay\n",
      "REAL ANSWER: i think soyou\n",
      "PREDICTED ANSWER: i am cool \n",
      "\n",
      "row 45\n",
      "QUESTION: i think soyou\n",
      "REAL ANSWER: more or less\n",
      "PREDICTED ANSWER: more or less \n",
      "\n",
      "row 46\n",
      "QUESTION: how is your pulse\n",
      "REAL ANSWER: i could not tell you\n",
      "PREDICTED ANSWER: i could not tell you \n",
      "\n",
      "row 47\n",
      "QUESTION: i could not tell you\n",
      "REAL ANSWER: then shoot him already\n",
      "PREDICTED ANSWER: then shoot him already \n",
      "\n",
      "row 48\n",
      "QUESTION: him\n",
      "REAL ANSWER: what are you saying\n",
      "PREDICTED ANSWER: he will turn around \n",
      "\n",
      "row 49\n",
      "QUESTION: on the way in\n",
      "REAL ANSWER: when youwhati am busy\n",
      "PREDICTED ANSWER: when youwhati am busy \n",
      "\n",
      "row 50\n",
      "QUESTION: when youwhati am busy\n",
      "REAL ANSWER: it is the white house\n",
      "PREDICTED ANSWER: it is the white house \n",
      "\n",
      "row 51\n",
      "QUESTION: what about it\n",
      "REAL ANSWER: for\n",
      "PREDICTED ANSWER: for \n",
      "\n",
      "row 52\n",
      "QUESTION: it is\n",
      "REAL ANSWER: no this is great\n",
      "PREDICTED ANSWER: that is it feel well \n",
      "\n",
      "row 53\n",
      "QUESTION: \n",
      "REAL ANSWER: bomb\n",
      "PREDICTED ANSWER: that is that \n",
      "\n",
      "row 54\n",
      "QUESTION: this is a song\n",
      "REAL ANSWER: what would ya think\n",
      "PREDICTED ANSWER: what would ya think \n",
      "\n",
      "row 55\n",
      "QUESTION: izzat the thing\n",
      "REAL ANSWER: indeed it is\n",
      "PREDICTED ANSWER: indeed it is \n",
      "\n",
      "row 56\n",
      "QUESTION: uit destroyed the\n",
      "REAL ANSWER: come on\n",
      "PREDICTED ANSWER: come on \n",
      "\n",
      "row 57\n",
      "QUESTION: what\n",
      "REAL ANSWER: the\n",
      "PREDICTED ANSWER: the \n",
      "\n",
      "row 58\n",
      "QUESTION: udou it\n",
      "REAL ANSWER: and you\n",
      "PREDICTED ANSWER: let's see \n",
      "\n",
      "row 59\n",
      "QUESTION: tell tell tell me again\n",
      "REAL ANSWER: we landing\n",
      "PREDICTED ANSWER: we landing \n",
      "\n",
      "row 60\n",
      "QUESTION: we landing\n",
      "REAL ANSWER: tell me again\n",
      "PREDICTED ANSWER: tell me again \n",
      "\n",
      "row 61\n",
      "QUESTION: they sound what\n",
      "REAL ANSWER: knows anything em\n",
      "PREDICTED ANSWER: knows anything em \n",
      "\n",
      "row 62\n",
      "QUESTION: can we see the kitten\n",
      "REAL ANSWER: uhellou yeswe will be back\n",
      "PREDICTED ANSWER: uhellou yeswe will be back \n",
      "\n",
      "row 63\n",
      "QUESTION: uhellou yeswe will be back\n",
      "REAL ANSWER: we will be back tonight\n",
      "PREDICTED ANSWER: we will be back tonight \n",
      "\n",
      "row 64\n",
      "QUESTION: take a long view\n",
      "REAL ANSWER: that is the long view\n",
      "PREDICTED ANSWER: that is the long view \n",
      "\n",
      "row 65\n",
      "QUESTION: anything at the airport\n",
      "REAL ANSWER: press thought no whaddaya think\n",
      "PREDICTED ANSWER: press thought no whaddaya think \n",
      "\n",
      "row 66\n",
      "QUESTION: this is magnificent\n",
      "REAL ANSWER: stanley moss\n",
      "PREDICTED ANSWER: thank you \n",
      "\n",
      "row 67\n",
      "QUESTION: war's over pal\n",
      "REAL ANSWER: gloria sell the house\n",
      "PREDICTED ANSWER: gloria sell the house \n",
      "\n",
      "row 68\n",
      "QUESTION: not we udou this\n",
      "REAL ANSWER: never quit a winner\n",
      "PREDICTED ANSWER: never a winner \n",
      "\n",
      "row 69\n",
      "QUESTION: oh\n",
      "REAL ANSWER: guess who uiu am\n",
      "PREDICTED ANSWER: oh angela my own angela \n",
      "\n",
      "row 70\n",
      "QUESTION: where is my\n",
      "REAL ANSWER: the group watching television\n",
      "PREDICTED ANSWER: the group watching television \n",
      "\n",
      "row 71\n",
      "QUESTION: where is he\n",
      "REAL ANSWER: out in oklahoma\n",
      "PREDICTED ANSWER: i do not know \n",
      "\n",
      "row 72\n",
      "QUESTION: wanna up\n",
      "REAL ANSWER: heavy weather east of here\n",
      "PREDICTED ANSWER: heavy weather east of here \n",
      "\n",
      "row 73\n",
      "QUESTION: heavy weather east of here\n",
      "REAL ANSWER: whaddaya think\n",
      "PREDICTED ANSWER: whaddaya think \n",
      "\n",
      "row 74\n",
      "QUESTION: my name is ronald\n",
      "REAL ANSWER: who are you working for\n",
      "PREDICTED ANSWER: who are you working for \n",
      "\n",
      "row 75\n",
      "QUESTION: whengs he coming back\n",
      "REAL ANSWER: andrews fourteen hundred today\n",
      "PREDICTED ANSWER: andrews fourteen hundred today \n",
      "\n",
      "row 76\n",
      "QUESTION: and tyler too\n",
      "REAL ANSWER: uh no that is\n",
      "PREDICTED ANSWER: uh no that is \n",
      "\n",
      "row 77\n",
      "QUESTION: why\n",
      "REAL ANSWER: why not\n",
      "PREDICTED ANSWER: why not \n",
      "\n",
      "row 78\n",
      "QUESTION: that is what it is\n",
      "REAL ANSWER: the country is at war\n",
      "PREDICTED ANSWER: the country is at war \n",
      "\n",
      "row 79\n",
      "QUESTION: who is this guy\n",
      "REAL ANSWER: act then act two\n",
      "PREDICTED ANSWER: act then act two \n",
      "\n",
      "row 80\n",
      "QUESTION: what is it\n",
      "REAL ANSWER: speech\n",
      "PREDICTED ANSWER: open up \n",
      "\n",
      "row 81\n",
      "QUESTION: the war ai not over\n",
      "REAL ANSWER: i saw it on tv\n",
      "PREDICTED ANSWER: i saw it on tv \n",
      "\n",
      "row 82\n",
      "QUESTION: i think it is fine\n",
      "REAL ANSWER: it is not too\n",
      "PREDICTED ANSWER: it is not too \n",
      "\n",
      "row 83\n",
      "QUESTION: hey business\n",
      "REAL ANSWER: ai not uthatu the truth\n",
      "PREDICTED ANSWER: ai not uthatu the truth \n",
      "\n",
      "row 84\n",
      "QUESTION: and ribbon\n",
      "REAL ANSWER: of what\n",
      "PREDICTED ANSWER: of what \n",
      "\n",
      "row 85\n",
      "QUESTION: of what\n",
      "REAL ANSWER: the campaign\n",
      "PREDICTED ANSWER: that on \n",
      "\n",
      "row 86\n",
      "QUESTION: a\n",
      "REAL ANSWER: what they\n",
      "PREDICTED ANSWER: no like that \n",
      "\n",
      "row 87\n",
      "QUESTION: wake up\n",
      "REAL ANSWER: is he dead\n",
      "PREDICTED ANSWER: is he dead \n",
      "\n",
      "row 88\n",
      "QUESTION: get on your feet boy\n",
      "REAL ANSWER: uh\n",
      "PREDICTED ANSWER: uh \n",
      "\n",
      "row 89\n",
      "QUESTION: you cannot tell this story\n",
      "REAL ANSWER: why not\n",
      "PREDICTED ANSWER: why not \n",
      "\n",
      "row 90\n",
      "QUESTION: why not\n",
      "REAL ANSWER: will have you killed\n",
      "PREDICTED ANSWER: i do not know \n",
      "\n",
      "row 91\n",
      "QUESTION: noyou are right\n",
      "REAL ANSWER: show must go on\n",
      "PREDICTED ANSWER: show must go on \n",
      "\n",
      "row 92\n",
      "QUESTION: show must go on\n",
      "REAL ANSWER: a proud tradition\n",
      "PREDICTED ANSWER: a proud tradition \n",
      "\n",
      "row 93\n",
      "QUESTION: keep talking\n",
      "REAL ANSWER: what us against canada\n",
      "PREDICTED ANSWER: what us against canada \n",
      "\n",
      "row 94\n",
      "QUESTION: can we a\n",
      "REAL ANSWER: no the\n",
      "PREDICTED ANSWER: no the \n",
      "\n",
      "row 95\n",
      "QUESTION: it is tough to\n",
      "REAL ANSWER: i believe in you\n",
      "PREDICTED ANSWER: i believe in you \n",
      "\n",
      "row 96\n",
      "QUESTION: john belushi belushi\n",
      "REAL ANSWER: jim belushi\n",
      "PREDICTED ANSWER: jim belushi \n",
      "\n",
      "row 97\n",
      "QUESTION: jim belushi\n",
      "REAL ANSWER: thing you know\n",
      "PREDICTED ANSWER: thing you know \n",
      "\n",
      "row 98\n",
      "QUESTION: the\n",
      "REAL ANSWER: a beret\n",
      "PREDICTED ANSWER: the hudswinger \n",
      "\n",
      "row 99\n",
      "QUESTION: a beret\n",
      "REAL ANSWER: why a beret\n",
      "PREDICTED ANSWER: why a beret \n",
      "\n",
      "row 100\n",
      "QUESTION: with their berets\n",
      "REAL ANSWER: their skin berets\n",
      "PREDICTED ANSWER: their skin berets \n",
      "\n",
      "row 101\n",
      "QUESTION: a option of what\n",
      "REAL ANSWER: of\n",
      "PREDICTED ANSWER: of \n",
      "\n",
      "row 102\n",
      "QUESTION: where is my\n",
      "REAL ANSWER: show some compassion\n",
      "PREDICTED ANSWER: show some compassion \n",
      "\n",
      "row 103\n",
      "QUESTION: oh hell\n",
      "REAL ANSWER: susiesusieare you alrightususieu\n",
      "PREDICTED ANSWER: susiesusieare you alrightususieu \n",
      "\n",
      "row 104\n",
      "QUESTION: susiesusieare you alrightususieu\n",
      "REAL ANSWER: lemme talk to himwillshoe\n",
      "PREDICTED ANSWER: lemme talk to himwillshoe \n",
      "\n",
      "row 105\n",
      "QUESTION: lemme talk to himwillshoe\n",
      "REAL ANSWER: you alright\n",
      "PREDICTED ANSWER: you alright \n",
      "\n",
      "row 106\n",
      "QUESTION: no i think\n",
      "REAL ANSWER: a or\n",
      "PREDICTED ANSWER: a or \n",
      "\n",
      "row 107\n",
      "QUESTION: what the hell\n",
      "REAL ANSWER: steel buy it\n",
      "PREDICTED ANSWER: what about the \n",
      "\n",
      "row 108\n",
      "QUESTION: the stock's going to\n",
      "REAL ANSWER: start\n",
      "PREDICTED ANSWER: start \n",
      "\n",
      "row 109\n",
      "QUESTION: about what\n",
      "REAL ANSWER: the announcement\n",
      "PREDICTED ANSWER: about what about \n",
      "\n",
      "row 110\n",
      "QUESTION: do not start alright\n",
      "REAL ANSWER: alright why so pissed\n",
      "PREDICTED ANSWER: alright why so pissed \n",
      "\n",
      "row 111\n",
      "QUESTION: your words not mine\n",
      "REAL ANSWER: you speak for me son\n",
      "PREDICTED ANSWER: you speak for me son \n",
      "\n",
      "row 112\n",
      "QUESTION: sorry mr\n",
      "REAL ANSWER: wait here\n",
      "PREDICTED ANSWER: wait here \n",
      "\n",
      "row 113\n",
      "QUESTION: i cannot make it tonight\n",
      "REAL ANSWER: are you with me buddy\n",
      "PREDICTED ANSWER: are you with me buddy \n",
      "\n",
      "row 114\n",
      "QUESTION: where is it\n",
      "REAL ANSWER: upper west side\n",
      "PREDICTED ANSWER: argongs private lab \n",
      "\n",
      "row 115\n",
      "QUESTION: well why stop at that\n",
      "REAL ANSWER: i do not\n",
      "PREDICTED ANSWER: i do not \n",
      "\n",
      "row 116\n",
      "QUESTION: it is over you gordon\n",
      "REAL ANSWER: you told him about us\n",
      "PREDICTED ANSWER: you told him about us \n",
      "\n",
      "row 117\n",
      "QUESTION: with mark\n",
      "REAL ANSWER: he still likes you\n",
      "PREDICTED ANSWER: he still likes you \n",
      "\n",
      "row 118\n",
      "QUESTION: your books master\n",
      "REAL ANSWER: thank you\n",
      "PREDICTED ANSWER: thank you \n",
      "\n",
      "row 119\n",
      "QUESTION: thank you\n",
      "REAL ANSWER: and uh your nicotine sir\n",
      "PREDICTED ANSWER: that is perfectly all right \n",
      "\n",
      "row 120\n",
      "QUESTION: and uh your nicotine sir\n",
      "REAL ANSWER: thank you\n",
      "PREDICTED ANSWER: thank you \n",
      "\n",
      "row 121\n",
      "QUESTION: thank you\n",
      "REAL ANSWER: allow me sir\n",
      "PREDICTED ANSWER: want another one \n",
      "\n",
      "row 122\n",
      "QUESTION: hello mrs china there\n",
      "REAL ANSWER: no jonathan\n",
      "PREDICTED ANSWER: no jonathan \n",
      "\n",
      "row 123\n",
      "QUESTION: to ve\n",
      "REAL ANSWER: uh wrong picture tony\n",
      "PREDICTED ANSWER: uh wrong picture tony \n",
      "\n",
      "row 124\n",
      "QUESTION: they seemed closing by much\n",
      "REAL ANSWER: tony and china\n",
      "PREDICTED ANSWER: tony and china \n",
      "\n",
      "row 125\n",
      "QUESTION: and china together\n",
      "REAL ANSWER: its ugly head\n",
      "PREDICTED ANSWER: its ugly head \n",
      "\n",
      "row 126\n",
      "QUESTION: sarah listen to me\n",
      "REAL ANSWER: go away\n",
      "PREDICTED ANSWER: go away \n",
      "\n",
      "row 127\n",
      "QUESTION: anyone else not coming\n",
      "REAL ANSWER: right behind you\n",
      "PREDICTED ANSWER: right behind you \n",
      "\n",
      "row 128\n",
      "QUESTION: well into three\n",
      "REAL ANSWER: six six and six\n",
      "PREDICTED ANSWER: six six and six \n",
      "\n",
      "row 129\n",
      "QUESTION: besides dad would have\n",
      "REAL ANSWER: no he would not\n",
      "PREDICTED ANSWER: no he would not \n",
      "\n",
      "row 130\n",
      "QUESTION: i miss you\n",
      "REAL ANSWER: so much\n",
      "PREDICTED ANSWER: so much \n",
      "\n",
      "row 131\n",
      "QUESTION: what do you mean\n",
      "REAL ANSWER: i started seeing things\n",
      "PREDICTED ANSWER: i started seeing things \n",
      "\n",
      "row 132\n",
      "QUESTION: i started seeing things\n",
      "REAL ANSWER: a ghost\n",
      "PREDICTED ANSWER: a ghost \n",
      "\n",
      "row 133\n",
      "QUESTION: did you\n",
      "REAL ANSWER: nobut once i heard\n",
      "PREDICTED ANSWER: stop it smelled me \n",
      "\n",
      "row 134\n",
      "QUESTION: who's idea was it\n",
      "REAL ANSWER: \n",
      "PREDICTED ANSWER:  \n",
      "\n",
      "row 135\n",
      "QUESTION: what does she look like\n",
      "REAL ANSWER: is a blond\n",
      "PREDICTED ANSWER: is a blond \n",
      "\n",
      "row 136\n",
      "QUESTION: yes but\n",
      "REAL ANSWER: your friend saw them\n",
      "PREDICTED ANSWER: then shut up \n",
      "\n",
      "row 137\n",
      "QUESTION: at the party\n",
      "REAL ANSWER: toward the remember\n",
      "PREDICTED ANSWER: toward the remember \n",
      "\n",
      "row 138\n",
      "QUESTION: who's that\n",
      "REAL ANSWER: the\n",
      "PREDICTED ANSWER: santa claus \n",
      "\n",
      "row 139\n",
      "QUESTION: well maybe your wife\n",
      "REAL ANSWER: she is not here\n",
      "PREDICTED ANSWER: she is not here \n",
      "\n",
      "row 140\n",
      "QUESTION: she is not here\n",
      "REAL ANSWER: whenwhen will she be back\n",
      "PREDICTED ANSWER: whenwhen will she be back \n",
      "\n",
      "row 141\n",
      "QUESTION: whenwhen will she be back\n",
      "REAL ANSWER: i do not know\n",
      "PREDICTED ANSWER: i do not know \n",
      "\n",
      "row 142\n",
      "QUESTION: i wanted to apologize\n",
      "REAL ANSWER: you do\n",
      "PREDICTED ANSWER: you do \n",
      "\n",
      "row 143\n",
      "QUESTION: your house is so beautiful\n",
      "REAL ANSWER: thank you\n",
      "PREDICTED ANSWER: thank you \n",
      "\n",
      "row 144\n",
      "QUESTION: you know where she is\n",
      "REAL ANSWER: no i do not\n",
      "PREDICTED ANSWER: no i do not \n",
      "\n",
      "row 145\n",
      "QUESTION: no i do not\n",
      "REAL ANSWER: please leave me alone\n",
      "PREDICTED ANSWER: you tricked me damn you \n",
      "\n",
      "row 146\n",
      "QUESTION: why are you here\n",
      "REAL ANSWER: i do not know\n",
      "PREDICTED ANSWER: i do not know \n",
      "\n",
      "row 147\n",
      "QUESTION: this is\n",
      "REAL ANSWER: we know each other\n",
      "PREDICTED ANSWER: we know each other \n",
      "\n",
      "row 148\n",
      "QUESTION: how you holding up\n",
      "REAL ANSWER: goodi am good\n",
      "PREDICTED ANSWER: goodi am good \n",
      "\n",
      "row 149\n",
      "QUESTION: goodi am good\n",
      "REAL ANSWER: you are\n",
      "PREDICTED ANSWER: you are \n",
      "\n",
      "row 150\n",
      "QUESTION: what is it\n",
      "REAL ANSWER: tea\n",
      "PREDICTED ANSWER: we in \n",
      "\n",
      "row 151\n",
      "QUESTION: jody no\n",
      "REAL ANSWER: telling you\n",
      "PREDICTED ANSWER: telling you \n",
      "\n",
      "row 152\n",
      "QUESTION: in the at work\n",
      "REAL ANSWER: i do not\n",
      "PREDICTED ANSWER: i do not \n",
      "\n",
      "row 153\n",
      "QUESTION: i have to go\n",
      "REAL ANSWER: jody wait\n",
      "PREDICTED ANSWER: a \n",
      "\n",
      "row 154\n",
      "QUESTION: are you okay\n",
      "REAL ANSWER: i think so\n",
      "PREDICTED ANSWER: i am fine \n",
      "\n",
      "row 155\n",
      "QUESTION: does norman know\n",
      "REAL ANSWER: jody she is alive\n",
      "PREDICTED ANSWER: jody she is alive \n",
      "\n",
      "row 156\n",
      "QUESTION: something was thereyou saw it\n",
      "REAL ANSWER: did i\n",
      "PREDICTED ANSWER: did i \n",
      "\n",
      "row 157\n",
      "QUESTION: oh godyou knew\n",
      "REAL ANSWER: i was down in\n",
      "PREDICTED ANSWER: i was down in \n",
      "\n",
      "row 158\n",
      "QUESTION: i do not know\n",
      "REAL ANSWER: if she was dangerous before\n",
      "PREDICTED ANSWER: you do not know \n",
      "\n",
      "row 159\n",
      "QUESTION: did he say that\n",
      "REAL ANSWER: jody he was lying\n",
      "PREDICTED ANSWER: jody he was lying \n",
      "\n",
      "row 160\n",
      "QUESTION: i think three\n",
      "REAL ANSWER: three weeks\n",
      "PREDICTED ANSWER: three weeks \n",
      "\n",
      "row 161\n",
      "QUESTION: whengs she out of here\n",
      "REAL ANSWER: norman\n",
      "PREDICTED ANSWER: norman \n",
      "\n",
      "row 162\n",
      "QUESTION: if you have to work\n",
      "REAL ANSWER: no noi am just\n",
      "PREDICTED ANSWER: no noi am not \n",
      "\n",
      "row 163\n",
      "QUESTION: not the focus\n",
      "REAL ANSWER: you know what i mean\n",
      "PREDICTED ANSWER: you know what i mean \n",
      "\n",
      "row 164\n",
      "QUESTION: it is just us now\n",
      "REAL ANSWER: i know\n",
      "PREDICTED ANSWER: i know \n",
      "\n",
      "row 165\n",
      "QUESTION: after that\n",
      "REAL ANSWER: i will be there\n",
      "PREDICTED ANSWER: i will be there \n",
      "\n",
      "row 166\n",
      "QUESTION: of what\n",
      "REAL ANSWER: of him i think\n",
      "PREDICTED ANSWER: they are watching you neo \n",
      "\n",
      "row 167\n",
      "QUESTION: of him i think\n",
      "REAL ANSWER: did she say that\n",
      "PREDICTED ANSWER: did she say that \n",
      "\n",
      "row 168\n",
      "QUESTION: did she say that\n",
      "REAL ANSWER: more or less\n",
      "PREDICTED ANSWER: more or less \n",
      "\n",
      "row 169\n",
      "QUESTION: in the was scared\n",
      "REAL ANSWER: did you call the police\n",
      "PREDICTED ANSWER: did you call the police \n",
      "\n",
      "row 170\n",
      "QUESTION: what kind of\n",
      "REAL ANSWER: i do not\n",
      "PREDICTED ANSWER: i do not \n",
      "\n",
      "row 171\n",
      "QUESTION: i think\n",
      "REAL ANSWER: you are so brilliant\n",
      "PREDICTED ANSWER: you are so brilliant \n",
      "\n",
      "row 172\n",
      "QUESTION: well that is nice\n",
      "REAL ANSWER: especially spencer's theorem\n",
      "PREDICTED ANSWER: especially spencer's theorem \n",
      "\n",
      "row 173\n",
      "QUESTION: especially spencer's theorem\n",
      "REAL ANSWER: oh no\n",
      "PREDICTED ANSWER: oh no \n",
      "\n",
      "row 174\n",
      "QUESTION: that is\n",
      "REAL ANSWER: for my father\n",
      "PREDICTED ANSWER: is gone berserk \n",
      "\n",
      "row 175\n",
      "QUESTION: for my father\n",
      "REAL ANSWER: i am so sorry\n",
      "PREDICTED ANSWER: i am so sorry \n",
      "\n",
      "row 176\n",
      "QUESTION: get will see\n",
      "REAL ANSWER: that is going on claire\n",
      "PREDICTED ANSWER: that is going on claire \n",
      "\n",
      "row 177\n",
      "QUESTION: our house\n",
      "REAL ANSWER: the window\n",
      "PREDICTED ANSWER: the window \n",
      "\n",
      "row 178\n",
      "QUESTION: it is a flare\n",
      "REAL ANSWER: a flare\n",
      "PREDICTED ANSWER: a flare \n",
      "\n",
      "row 179\n",
      "QUESTION: what am i looking at\n",
      "REAL ANSWER: i did not do that\n",
      "PREDICTED ANSWER: i did not do that \n",
      "\n",
      "row 180\n",
      "QUESTION: i did not do that\n",
      "REAL ANSWER: who didmrs feur\n",
      "PREDICTED ANSWER: who didmrs feur \n",
      "\n",
      "row 181\n",
      "QUESTION: who didmrs feur\n",
      "REAL ANSWER: me\n",
      "PREDICTED ANSWER: me \n",
      "\n",
      "row 182\n",
      "QUESTION: do not get all\n",
      "REAL ANSWER: like it never even happened\n",
      "PREDICTED ANSWER: like it never even happened \n",
      "\n",
      "row 183\n",
      "QUESTION: there we go\n",
      "REAL ANSWER: well that is a relief\n",
      "PREDICTED ANSWER: well that is a relief \n",
      "\n",
      "row 184\n",
      "QUESTION: how do you know this\n",
      "REAL ANSWER: we had a seance\n",
      "PREDICTED ANSWER: we had a seance \n",
      "\n",
      "row 185\n",
      "QUESTION: we had a seance\n",
      "REAL ANSWER: who did\n",
      "PREDICTED ANSWER: who did \n",
      "\n",
      "row 186\n",
      "QUESTION: keep your voice down\n",
      "REAL ANSWER: i will not\n",
      "PREDICTED ANSWER: i will not \n",
      "\n",
      "row 187\n",
      "QUESTION: i am sorry\n",
      "REAL ANSWER: then where is she\n",
      "PREDICTED ANSWER: i am sorry let's go \n",
      "\n",
      "row 188\n",
      "QUESTION: i felt through me\n",
      "REAL ANSWER: we walked all night\n",
      "PREDICTED ANSWER: we walked all night \n",
      "\n",
      "row 189\n",
      "QUESTION: i am positive this time\n",
      "REAL ANSWER: please stop\n",
      "PREDICTED ANSWER: please stop \n",
      "\n",
      "row 190\n",
      "QUESTION: please stop\n",
      "REAL ANSWER: it is madison fra\n",
      "PREDICTED ANSWER: it is madison fra \n",
      "\n",
      "row 191\n",
      "QUESTION: it is madison fra\n",
      "REAL ANSWER: stop it\n",
      "PREDICTED ANSWER: stop it \n",
      "\n",
      "row 192\n",
      "QUESTION: that is the matter\n",
      "REAL ANSWER: it is too rough\n",
      "PREDICTED ANSWER: i must be going \n",
      "\n",
      "row 193\n",
      "QUESTION: it is too rough\n",
      "REAL ANSWER: since when\n",
      "PREDICTED ANSWER: since when \n",
      "\n",
      "row 194\n",
      "QUESTION: your wife\n",
      "REAL ANSWER: stop it\n",
      "PREDICTED ANSWER: stop it \n",
      "\n",
      "row 195\n",
      "QUESTION: look for antiques\n",
      "REAL ANSWER: some great places\n",
      "PREDICTED ANSWER: some great places \n",
      "\n",
      "row 196\n",
      "QUESTION: do you know it\n",
      "REAL ANSWER: do not think so\n",
      "PREDICTED ANSWER: do not think so \n",
      "\n",
      "row 197\n",
      "QUESTION: i know\n",
      "REAL ANSWER: finei will do the shopping\n",
      "PREDICTED ANSWER: when do we talk \n",
      "\n",
      "row 198\n",
      "QUESTION: would you stop it\n",
      "REAL ANSWER: well they are\n",
      "PREDICTED ANSWER: well they are \n",
      "\n",
      "row 199\n",
      "QUESTION: there are two\n",
      "REAL ANSWER: two what\n",
      "PREDICTED ANSWER: two what \n",
      "\n",
      "row 200\n",
      "QUESTION: two what\n",
      "REAL ANSWER: two\n",
      "PREDICTED ANSWER: two \n",
      "\n",
      "row 201\n",
      "QUESTION: nothing was ever more false\n",
      "REAL ANSWER: then tell it\n",
      "PREDICTED ANSWER: then tell it \n",
      "\n",
      "row 202\n",
      "QUESTION: is this\n",
      "REAL ANSWER: who is this\n",
      "PREDICTED ANSWER: who is this \n",
      "\n",
      "row 203\n",
      "QUESTION: who is this\n",
      "REAL ANSWER: rowan calling\n",
      "PREDICTED ANSWER: you know who \n",
      "\n",
      "row 204\n",
      "QUESTION: i beg your\n",
      "REAL ANSWER: when did she die\n",
      "PREDICTED ANSWER: when did she die \n",
      "\n",
      "row 205\n",
      "QUESTION: when did she die\n",
      "REAL ANSWER: who is this\n",
      "PREDICTED ANSWER: who is this \n",
      "\n",
      "row 206\n",
      "QUESTION: i had you sent away\n",
      "REAL ANSWER: who the\n",
      "PREDICTED ANSWER: who the \n",
      "\n",
      "row 207\n",
      "QUESTION: what is it\n",
      "REAL ANSWER: the is all\n",
      "PREDICTED ANSWER: i have a letter ma'am \n",
      "\n",
      "row 208\n",
      "QUESTION: she did not feel them\n",
      "REAL ANSWER: you are a monster\n",
      "PREDICTED ANSWER: you are a monster \n",
      "\n",
      "row 209\n",
      "QUESTION: go back michael go back\n",
      "REAL ANSWER: the door michaelfind the key\n",
      "PREDICTED ANSWER: the door michaelfind the key \n",
      "\n",
      "row 210\n",
      "QUESTION: the door michaelfind the key\n",
      "REAL ANSWER: help what you can\n",
      "PREDICTED ANSWER: help what you can \n",
      "\n",
      "row 211\n",
      "QUESTION: what you can\n",
      "REAL ANSWER: door\n",
      "PREDICTED ANSWER: door \n",
      "\n",
      "row 212\n",
      "QUESTION: parents say he uh fell\n",
      "REAL ANSWER: anybody got a yet\n",
      "PREDICTED ANSWER: anybody got a yet \n",
      "\n",
      "row 213\n",
      "QUESTION: yes\n",
      "REAL ANSWER: like this\n",
      "PREDICTED ANSWER: hey he \n",
      "\n",
      "row 214\n",
      "QUESTION: explain this to me\n",
      "REAL ANSWER: you bastard\n",
      "PREDICTED ANSWER: you bastard \n",
      "\n",
      "row 215\n",
      "QUESTION: made it\n",
      "REAL ANSWER: it is from love\n",
      "PREDICTED ANSWER: it is from love \n",
      "\n",
      "row 216\n",
      "QUESTION: i love him\n",
      "REAL ANSWER: do not tell me that\n",
      "PREDICTED ANSWER: do not tell me that \n",
      "\n",
      "row 217\n",
      "QUESTION: do not tell me that\n",
      "REAL ANSWER: i love\n",
      "PREDICTED ANSWER: i love \n",
      "\n",
      "row 218\n",
      "QUESTION: go on on\n",
      "REAL ANSWER: leave me alone\n",
      "PREDICTED ANSWER: leave me alone \n",
      "\n",
      "row 219\n",
      "QUESTION: what is wrong\n",
      "REAL ANSWER: wrongscience is not magic\n",
      "PREDICTED ANSWER: wrongscience is not magic \n",
      "\n",
      "row 220\n",
      "QUESTION: wrongscience is not magic\n",
      "REAL ANSWER: i do not understand\n",
      "PREDICTED ANSWER: i do not understand \n",
      "\n",
      "row 221\n",
      "QUESTION: what do you see\n",
      "REAL ANSWER: nothing\n",
      "PREDICTED ANSWER: nothing \n",
      "\n",
      "row 222\n",
      "QUESTION: doctor's orders\n",
      "REAL ANSWER: orders\n",
      "PREDICTED ANSWER: orders \n",
      "\n",
      "row 223\n",
      "QUESTION: do you love me michael\n",
      "REAL ANSWER: yesi love much\n",
      "PREDICTED ANSWER: yesi love much \n",
      "\n",
      "row 224\n",
      "QUESTION: wanna\n",
      "REAL ANSWER: a little wine\n",
      "PREDICTED ANSWER: a little wine \n",
      "\n",
      "row 225\n",
      "QUESTION: hey you are bleeding\n",
      "REAL ANSWER: dropped it\n",
      "PREDICTED ANSWER: dropped it \n",
      "\n",
      "row 226\n",
      "QUESTION: on which planet\n",
      "REAL ANSWER: you cannot just\n",
      "PREDICTED ANSWER: you cannot just \n",
      "\n",
      "row 227\n",
      "QUESTION: you cannot just\n",
      "REAL ANSWER: go away goddamnit\n",
      "PREDICTED ANSWER: go away goddamnit \n",
      "\n",
      "row 228\n",
      "QUESTION: i am getting left behind\n",
      "REAL ANSWER: left about rowan\n",
      "PREDICTED ANSWER: left about rowan \n",
      "\n",
      "row 229\n",
      "QUESTION: rowan\n",
      "REAL ANSWER: me\n",
      "PREDICTED ANSWER: me \n",
      "\n",
      "row 230\n",
      "QUESTION: you really love this guy\n",
      "REAL ANSWER: he is got great hands\n",
      "PREDICTED ANSWER: he is got great hands \n",
      "\n",
      "row 231\n",
      "QUESTION: that is right\n",
      "REAL ANSWER: and it cannot be forged\n",
      "PREDICTED ANSWER: oh will not do \n",
      "\n",
      "row 232\n",
      "QUESTION: i lost the touch\n",
      "REAL ANSWER: the touch\n",
      "PREDICTED ANSWER: the touch \n",
      "\n",
      "row 233\n",
      "QUESTION: what are you doing\n",
      "REAL ANSWER: i am sorry\n",
      "PREDICTED ANSWER: feeding my fish \n",
      "\n",
      "row 234\n",
      "QUESTION: my names is not angela\n",
      "REAL ANSWER: yes i am sorry ellen\n",
      "PREDICTED ANSWER: yes i am sorry ellen \n",
      "\n",
      "row 235\n",
      "QUESTION: so what do you do\n",
      "REAL ANSWER: i am a dentist\n",
      "PREDICTED ANSWER: i am a dentist \n",
      "\n",
      "row 236\n",
      "QUESTION: i do not know\n",
      "REAL ANSWER: you do not know\n",
      "PREDICTED ANSWER: you do not know \n",
      "\n",
      "row 237\n",
      "QUESTION: did not debbie deserve anymore\n",
      "REAL ANSWER: no she did not\n",
      "PREDICTED ANSWER: no she did not \n",
      "\n",
      "row 238\n",
      "QUESTION: tell me how it happened\n",
      "REAL ANSWER: why should i\n",
      "PREDICTED ANSWER: why should i \n",
      "\n",
      "row 239\n",
      "QUESTION: my sister my adopted sister\n",
      "REAL ANSWER: did stephanie kill your mother\n",
      "PREDICTED ANSWER: did stephanie kill your mother \n",
      "\n",
      "row 240\n",
      "QUESTION: that is wrong\n",
      "REAL ANSWER: nothing could be better\n",
      "PREDICTED ANSWER: do you want ice \n",
      "\n",
      "row 241\n",
      "QUESTION: what is it\n",
      "REAL ANSWER: open it\n",
      "PREDICTED ANSWER: power line \n",
      "\n",
      "row 242\n",
      "QUESTION: that good enough\n",
      "REAL ANSWER: yes i suppose so\n",
      "PREDICTED ANSWER: yes i suppose so \n",
      "\n",
      "row 243\n",
      "QUESTION: first finish your tea\n",
      "REAL ANSWER: he does not need to\n",
      "PREDICTED ANSWER: he does not need to \n",
      "\n",
      "row 244\n",
      "QUESTION: surgery are you a doctor\n",
      "REAL ANSWER: no a dentist\n",
      "PREDICTED ANSWER: no a dentist \n",
      "\n",
      "row 245\n",
      "QUESTION: a are you serious\n",
      "REAL ANSWER: maybe he got\n",
      "PREDICTED ANSWER: maybe he got \n",
      "\n",
      "row 246\n",
      "QUESTION: oh well maybe not yet\n",
      "REAL ANSWER: not ever never\n",
      "PREDICTED ANSWER: not ever never \n",
      "\n",
      "row 247\n",
      "QUESTION: so far away in\n",
      "REAL ANSWER: yeah whatever\n",
      "PREDICTED ANSWER: yeah whatever \n",
      "\n",
      "row 248\n",
      "QUESTION: check this\n",
      "REAL ANSWER: i better go dad\n",
      "PREDICTED ANSWER: i better go dad \n",
      "\n",
      "row 249\n",
      "QUESTION: what is it now\n",
      "REAL ANSWER: check it out\n",
      "PREDICTED ANSWER: do not ask \n",
      "\n",
      "row 250\n",
      "QUESTION: oh how inappropriate is that\n",
      "REAL ANSWER: take a of heaven\n",
      "PREDICTED ANSWER: take a of heaven \n",
      "\n",
      "row 251\n",
      "QUESTION: never say never\n",
      "REAL ANSWER: oh godlook look\n",
      "PREDICTED ANSWER: oh godlook look \n",
      "\n",
      "row 252\n",
      "QUESTION: what gives don corleone\n",
      "REAL ANSWER: we ourselves\n",
      "PREDICTED ANSWER: we ourselves \n",
      "\n",
      "row 253\n",
      "QUESTION: you go first\n",
      "REAL ANSWER: ladies firsti insist\n",
      "PREDICTED ANSWER: naw you go \n",
      "\n",
      "row 254\n",
      "QUESTION: ladies firsti insist\n",
      "REAL ANSWER: well the coming up\n",
      "PREDICTED ANSWER: well the coming up \n",
      "\n",
      "row 255\n",
      "QUESTION: great jacket teddy bear\n",
      "REAL ANSWER: yeah you like\n",
      "PREDICTED ANSWER: yeah you like \n",
      "\n",
      "row 256\n",
      "QUESTION: do it\n",
      "REAL ANSWER: you the pictures\n",
      "PREDICTED ANSWER: cannot handle it thing \n",
      "\n",
      "row 257\n",
      "QUESTION: you guys are my parents\n",
      "REAL ANSWER: of course we are\n",
      "PREDICTED ANSWER: of course we are \n",
      "\n",
      "row 258\n",
      "QUESTION: the one with the horses\n",
      "REAL ANSWER: that is me\n",
      "PREDICTED ANSWER: that is me \n",
      "\n",
      "row 259\n",
      "QUESTION: my new bike\n",
      "REAL ANSWER: very funny\n",
      "PREDICTED ANSWER: very funny \n",
      "\n",
      "row 260\n",
      "QUESTION: you want it in writing\n",
      "REAL ANSWER: just a formality\n",
      "PREDICTED ANSWER: just a formality \n",
      "\n",
      "row 261\n",
      "QUESTION: he was my grandfather too\n",
      "REAL ANSWER: i meant\n",
      "PREDICTED ANSWER: i meant \n",
      "\n",
      "row 262\n",
      "QUESTION: i have absolutely no\n",
      "REAL ANSWER: do it i you\n",
      "PREDICTED ANSWER: do it i you \n",
      "\n",
      "row 263\n",
      "QUESTION: your article sucked\n",
      "REAL ANSWER: in what sense\n",
      "PREDICTED ANSWER: in what sense \n",
      "\n",
      "row 264\n",
      "QUESTION: she said you\n",
      "REAL ANSWER: you never know around here\n",
      "PREDICTED ANSWER: you never know around here \n",
      "\n",
      "row 265\n",
      "QUESTION: he phoned it in\n",
      "REAL ANSWER: i see\n",
      "PREDICTED ANSWER: i see \n",
      "\n",
      "row 266\n",
      "QUESTION: i see\n",
      "REAL ANSWER: i doubt it\n",
      "PREDICTED ANSWER: what does that mean \n",
      "\n",
      "row 267\n",
      "QUESTION: your dad taught you everything\n",
      "REAL ANSWER: i mean my father\n",
      "PREDICTED ANSWER: i mean my father \n",
      "\n",
      "row 268\n",
      "QUESTION: it is all so complicated\n",
      "REAL ANSWER: it is incredibly simple\n",
      "PREDICTED ANSWER: it is incredibly simple \n",
      "\n",
      "row 269\n",
      "QUESTION: eventually you will let go\n",
      "REAL ANSWER: and then what\n",
      "PREDICTED ANSWER: and then what \n",
      "\n",
      "row 270\n",
      "QUESTION: you are amazing\n",
      "REAL ANSWER: i know\n",
      "PREDICTED ANSWER: i know \n",
      "\n",
      "row 271\n",
      "QUESTION: that is\n",
      "REAL ANSWER: what about you\n",
      "PREDICTED ANSWER: tried him once \n",
      "\n",
      "row 272\n",
      "QUESTION: what about you\n",
      "REAL ANSWER: i am very aural\n",
      "PREDICTED ANSWER: i am going after dad \n",
      "\n",
      "row 273\n",
      "QUESTION: i am very aural\n",
      "REAL ANSWER: tell me more\n",
      "PREDICTED ANSWER: tell me more \n",
      "\n",
      "row 274\n",
      "QUESTION: do you trust me julie\n",
      "REAL ANSWER: not a chance\n",
      "PREDICTED ANSWER: not a chance \n",
      "\n",
      "row 275\n",
      "QUESTION: not a chance\n",
      "REAL ANSWER: come on\n",
      "PREDICTED ANSWER: come again \n",
      "\n",
      "row 276\n",
      "QUESTION: that is hard to believe\n",
      "REAL ANSWER: but absolutely true\n",
      "PREDICTED ANSWER: but absolutely never \n",
      "\n",
      "row 277\n",
      "QUESTION: uh sure uncle billy\n",
      "REAL ANSWER: i have only one concern\n",
      "PREDICTED ANSWER: i have only one concern \n",
      "\n",
      "row 278\n",
      "QUESTION: as much as possible\n",
      "REAL ANSWER: you are sure\n",
      "PREDICTED ANSWER: you are sure \n",
      "\n",
      "row 279\n",
      "QUESTION: me the king of\n",
      "REAL ANSWER: the supreme of\n",
      "PREDICTED ANSWER: the supreme of \n",
      "\n",
      "row 280\n",
      "QUESTION: what are you doing\n",
      "REAL ANSWER: my job back off\n",
      "PREDICTED ANSWER: i do not know \n",
      "\n",
      "row 281\n",
      "QUESTION: talk to me artie\n",
      "REAL ANSWER: kelly van ryan\n",
      "PREDICTED ANSWER: kelly van ryan \n",
      "\n",
      "row 282\n",
      "QUESTION: how you doing artie\n",
      "REAL ANSWER: i you know i\n",
      "PREDICTED ANSWER: i you know i \n",
      "\n",
      "row 283\n",
      "QUESTION: and where might that be\n",
      "REAL ANSWER: i was thinking maybe\n",
      "PREDICTED ANSWER: i was thinking maybe \n",
      "\n",
      "row 284\n",
      "QUESTION: \n",
      "REAL ANSWER: the teeth doing any talking\n",
      "PREDICTED ANSWER: this is a little different \n",
      "\n",
      "row 285\n",
      "QUESTION: you okay\n",
      "REAL ANSWER: i am tv\n",
      "PREDICTED ANSWER: yeah just a nick \n",
      "\n",
      "row 286\n",
      "QUESTION: maybe she used another name\n",
      "REAL ANSWER: ray thinks she was murdered\n",
      "PREDICTED ANSWER: ray thinks she was murdered \n",
      "\n",
      "row 287\n",
      "QUESTION: you saw the news today\n",
      "REAL ANSWER: settlement\n",
      "PREDICTED ANSWER: settlement \n",
      "\n",
      "row 288\n",
      "QUESTION: if you want company\n",
      "REAL ANSWER: just check out the car\n",
      "PREDICTED ANSWER: just check out the car \n",
      "\n",
      "row 289\n",
      "QUESTION: those are teeth\n",
      "REAL ANSWER: where is the body\n",
      "PREDICTED ANSWER: where is the body \n",
      "\n",
      "row 290\n",
      "QUESTION: that bothers you\n",
      "REAL ANSWER: yeah maybe a little\n",
      "PREDICTED ANSWER: he was innocent \n",
      "\n",
      "row 291\n",
      "QUESTION: yeah maybe a little\n",
      "REAL ANSWER: why is that\n",
      "PREDICTED ANSWER: why is that \n",
      "\n",
      "row 292\n",
      "QUESTION: about a year ago\n",
      "REAL ANSWER: he dropped jimmy off first\n",
      "PREDICTED ANSWER: he dropped jimmy off first \n",
      "\n",
      "row 293\n",
      "QUESTION: he did say something\n",
      "REAL ANSWER: what was that\n",
      "PREDICTED ANSWER: what was that \n",
      "\n",
      "row 294\n",
      "QUESTION: ms\n",
      "REAL ANSWER: i said he did\n",
      "PREDICTED ANSWER: i said he did \n",
      "\n",
      "row 295\n",
      "QUESTION: this was not my idea\n",
      "REAL ANSWER: i am sorry\n",
      "PREDICTED ANSWER: i am sorry \n",
      "\n",
      "row 296\n",
      "QUESTION: a want one\n",
      "REAL ANSWER: yeahbut i got my bike\n",
      "PREDICTED ANSWER: yeahbut i got my bike \n",
      "\n",
      "row 297\n",
      "QUESTION: oh for christ's sake\n",
      "REAL ANSWER: you are\n",
      "PREDICTED ANSWER: you are \n",
      "\n",
      "row 298\n",
      "QUESTION: is that sam lombardo\n",
      "REAL ANSWER: hi mon\n",
      "PREDICTED ANSWER: hi mon \n",
      "\n",
      "row 299\n",
      "QUESTION: okay that is the matter\n",
      "REAL ANSWER: you notice my new jumper\n",
      "PREDICTED ANSWER: you notice my new jumper \n",
      "\n",
      "row 300\n",
      "QUESTION: kellywhat is it\n",
      "REAL ANSWER: i miss dad\n",
      "PREDICTED ANSWER: i miss dad \n",
      "\n",
      "row 301\n",
      "QUESTION: i miss dad\n",
      "REAL ANSWER: jesuswell i do too sometimes\n",
      "PREDICTED ANSWER: jesuswell i do too sometimes \n",
      "\n",
      "row 302\n",
      "QUESTION: jesuswell i do too sometimes\n",
      "REAL ANSWER: no you do not\n",
      "PREDICTED ANSWER: no you do not \n",
      "\n",
      "row 303\n",
      "QUESTION: he sam lombardo\n",
      "REAL ANSWER: mom\n",
      "PREDICTED ANSWER: mom \n",
      "\n",
      "row 304\n",
      "QUESTION: jeez that thing cannot you\n",
      "REAL ANSWER: rules are rules mr lombardo\n",
      "PREDICTED ANSWER: rules are rules mr lombardo \n",
      "\n",
      "row 305\n",
      "QUESTION: that is not your line\n",
      "REAL ANSWER: say you love me\n",
      "PREDICTED ANSWER: say you love me \n",
      "\n",
      "row 306\n",
      "QUESTION: i am running away\n",
      "REAL ANSWER: you think that is wise\n",
      "PREDICTED ANSWER: you think that is wise \n",
      "\n",
      "row 307\n",
      "QUESTION: meet my partner gloria\n",
      "REAL ANSWER: i blue balls\n",
      "PREDICTED ANSWER: i blue balls \n",
      "\n",
      "row 308\n",
      "QUESTION: but she ran away\n",
      "REAL ANSWER: that is right\n",
      "PREDICTED ANSWER: that is right \n",
      "\n",
      "row 309\n",
      "QUESTION: that is wrong\n",
      "REAL ANSWER: fuck the wanna drive\n",
      "PREDICTED ANSWER: nothing it is nothing \n",
      "\n",
      "row 310\n",
      "QUESTION: j s\n",
      "REAL ANSWER: jim west\n",
      "PREDICTED ANSWER: jim west \n",
      "\n",
      "row 311\n",
      "QUESTION: you need that real often\n",
      "REAL ANSWER: always this\n",
      "PREDICTED ANSWER: always this \n",
      "\n",
      "row 312\n",
      "QUESTION: yes screw\n",
      "REAL ANSWER: is this leading somewhere\n",
      "PREDICTED ANSWER: is this leading somewhere \n",
      "\n",
      "row 313\n",
      "QUESTION: prepare what\n",
      "REAL ANSWER: my here\n",
      "PREDICTED ANSWER: my here \n",
      "\n",
      "row 314\n",
      "QUESTION: all what\n",
      "REAL ANSWER: all that jumping and kicking\n",
      "PREDICTED ANSWER: all that jumping and kicking \n",
      "\n",
      "row 315\n",
      "QUESTION: at least i tried something\n",
      "REAL ANSWER: hey i tried the board\n",
      "PREDICTED ANSWER: hey i tried the board \n",
      "\n",
      "row 316\n",
      "QUESTION: know what this is\n",
      "REAL ANSWER: sureit is a windup thing\n",
      "PREDICTED ANSWER: sureit is a windup thing \n",
      "\n",
      "row 317\n",
      "QUESTION: sureit is a windup thing\n",
      "REAL ANSWER: a own design\n",
      "PREDICTED ANSWER: a own design \n",
      "\n",
      "row 318\n",
      "QUESTION: this is good\n",
      "REAL ANSWER: us something\n",
      "PREDICTED ANSWER: us something \n",
      "\n",
      "row 319\n",
      "QUESTION: oh is it\n",
      "REAL ANSWER: it is better than nothing\n",
      "PREDICTED ANSWER: it is better than nothing \n",
      "\n",
      "row 320\n",
      "QUESTION: it is better than nothing\n",
      "REAL ANSWER: it is\n",
      "PREDICTED ANSWER: it is \n",
      "\n",
      "row 321\n",
      "QUESTION: it is not a guy\n",
      "REAL ANSWER: it is a town\n",
      "PREDICTED ANSWER: it is a town \n",
      "\n",
      "row 322\n",
      "QUESTION: not again\n",
      "REAL ANSWER: i it\n",
      "PREDICTED ANSWER: i it \n",
      "\n",
      "row 323\n",
      "QUESTION: oh thank you\n",
      "REAL ANSWER: my pleasure\n",
      "PREDICTED ANSWER: magnificent magnificent \n",
      "\n",
      "row 324\n",
      "QUESTION: grant is\n",
      "REAL ANSWER: i knowi know\n",
      "PREDICTED ANSWER: i knowi know \n",
      "\n",
      "row 325\n",
      "QUESTION: my godhe is so\n",
      "REAL ANSWER: where have you been\n",
      "PREDICTED ANSWER: where have you been \n",
      "\n",
      "row 326\n",
      "QUESTION: yes me\n",
      "REAL ANSWER: course how novel\n",
      "PREDICTED ANSWER: course how novel \n",
      "\n",
      "row 327\n",
      "QUESTION: a new friend\n",
      "REAL ANSWER: we will see\n",
      "PREDICTED ANSWER: we will see \n",
      "\n",
      "row 328\n",
      "QUESTION: would that me\n",
      "REAL ANSWER: oh i would hope not\n",
      "PREDICTED ANSWER: oh i would hope not \n",
      "\n",
      "row 329\n",
      "QUESTION: you have done this before\n",
      "REAL ANSWER: i have had some practice\n",
      "PREDICTED ANSWER: i have had some practice \n",
      "\n",
      "row 330\n",
      "QUESTION: your private train sir\n",
      "REAL ANSWER: private train\n",
      "PREDICTED ANSWER: private train \n",
      "\n",
      "row 331\n",
      "QUESTION: good\n",
      "REAL ANSWER: this is colonel\n",
      "PREDICTED ANSWER: good night day \n",
      "\n",
      "row 332\n",
      "QUESTION: no sir just a\n",
      "REAL ANSWER: be a dangerous business\n",
      "PREDICTED ANSWER: be a dangerous business \n",
      "\n",
      "row 333\n",
      "QUESTION: emperor\n",
      "REAL ANSWER: the first\n",
      "PREDICTED ANSWER: the first \n",
      "\n",
      "row 334\n",
      "QUESTION: this is something\n",
      "REAL ANSWER: it is a\n",
      "PREDICTED ANSWER: it is a \n",
      "\n",
      "row 335\n",
      "QUESTION: now it is a bomb\n",
      "REAL ANSWER: it is\n",
      "PREDICTED ANSWER: it is \n",
      "\n",
      "row 336\n",
      "QUESTION: they are coming\n",
      "REAL ANSWER: when are they coming\n",
      "PREDICTED ANSWER: when are they coming \n",
      "\n",
      "row 337\n",
      "QUESTION: you are chasing a dream\n",
      "REAL ANSWER: just get me some horses\n",
      "PREDICTED ANSWER: just get me some horses \n",
      "\n",
      "row 338\n",
      "QUESTION: thank you friend\n",
      "REAL ANSWER: let's go\n",
      "PREDICTED ANSWER: let's go \n",
      "\n",
      "row 339\n",
      "QUESTION: i cannot\n",
      "REAL ANSWER: let me see it\n",
      "PREDICTED ANSWER: are you invoking attorneyclient privilege \n",
      "\n",
      "row 340\n",
      "QUESTION: i cannot\n",
      "REAL ANSWER: why not\n",
      "PREDICTED ANSWER: yes you \n",
      "\n",
      "row 341\n",
      "QUESTION: why not\n",
      "REAL ANSWER: why not\n",
      "PREDICTED ANSWER: why not \n",
      "\n",
      "row 342\n",
      "QUESTION: \n",
      "REAL ANSWER: you are not a woman\n",
      "PREDICTED ANSWER: that is it \n",
      "\n",
      "row 343\n",
      "QUESTION: why did you say that\n",
      "REAL ANSWER: say what\n",
      "PREDICTED ANSWER: say what \n",
      "\n",
      "row 344\n",
      "QUESTION: say what\n",
      "REAL ANSWER: i love you\n",
      "PREDICTED ANSWER: how do you do \n",
      "\n",
      "row 345\n",
      "QUESTION: because it is true\n",
      "REAL ANSWER: i do not believe you\n",
      "PREDICTED ANSWER: i do not believe you \n",
      "\n",
      "row 346\n",
      "QUESTION: who is that girl anyway\n",
      "REAL ANSWER: queen daughter\n",
      "PREDICTED ANSWER: queen daughter \n",
      "\n",
      "row 347\n",
      "QUESTION: coming\n",
      "REAL ANSWER: the fire\n",
      "PREDICTED ANSWER: the fire \n",
      "\n",
      "row 348\n",
      "QUESTION: thanks for your help\n",
      "REAL ANSWER: are you okay\n",
      "PREDICTED ANSWER: are you okay \n",
      "\n",
      "row 349\n",
      "QUESTION: you all right\n",
      "REAL ANSWER: these\n",
      "PREDICTED ANSWER: yeah i think so \n",
      "\n",
      "row 350\n",
      "QUESTION: smells like a battle\n",
      "REAL ANSWER: are you a warrior\n",
      "PREDICTED ANSWER: are you a warrior \n",
      "\n",
      "row 351\n",
      "QUESTION: that is thati hear something\n",
      "REAL ANSWER: you hear trouble\n",
      "PREDICTED ANSWER: you hear trouble \n",
      "\n",
      "row 352\n",
      "QUESTION: you hear trouble\n",
      "REAL ANSWER: what is it\n",
      "PREDICTED ANSWER: what is it \n",
      "\n",
      "row 353\n",
      "QUESTION: whatcha thinking about willow\n",
      "REAL ANSWER: i hate this\n",
      "PREDICTED ANSWER: i hate this \n",
      "\n",
      "row 354\n",
      "QUESTION: i will\n",
      "REAL ANSWER: fresh milk\n",
      "PREDICTED ANSWER: do you better \n",
      "\n",
      "row 355\n",
      "QUESTION: time to change her\n",
      "REAL ANSWER: time to leave\n",
      "PREDICTED ANSWER: time to leave \n",
      "\n",
      "row 356\n",
      "QUESTION: because she is sick\n",
      "REAL ANSWER: because she is sick\n",
      "PREDICTED ANSWER: because she is sick \n",
      "\n",
      "row 357\n",
      "QUESTION: where is the baby\n",
      "REAL ANSWER: i thought you had her\n",
      "PREDICTED ANSWER: i thought you had her \n",
      "\n",
      "row 358\n",
      "QUESTION: saved her life\n",
      "REAL ANSWER: i did\n",
      "PREDICTED ANSWER: i did \n",
      "\n",
      "row 359\n",
      "QUESTION: i will help you\n",
      "REAL ANSWER: i will not\n",
      "PREDICTED ANSWER: i will not \n",
      "\n",
      "row 360\n",
      "QUESTION: she asked about you\n",
      "REAL ANSWER: well what did she say\n",
      "PREDICTED ANSWER: well what did she say \n",
      "\n",
      "row 361\n",
      "QUESTION: cannot we keep it\n",
      "REAL ANSWER: absolutely not\n",
      "PREDICTED ANSWER: absolutely not \n",
      "\n",
      "row 362\n",
      "QUESTION: that is the magiciangs weapon\n",
      "REAL ANSWER: the power of\n",
      "PREDICTED ANSWER: the power of \n",
      "\n",
      "row 363\n",
      "QUESTION: is the magiciangs weapon\n",
      "REAL ANSWER: his will\n",
      "PREDICTED ANSWER: his will \n",
      "\n",
      "row 364\n",
      "QUESTION: his will\n",
      "REAL ANSWER: now use it\n",
      "PREDICTED ANSWER: now use it \n",
      "\n",
      "row 365\n",
      "QUESTION: \n",
      "REAL ANSWER: there's nobody here\n",
      "PREDICTED ANSWER: nice girl \n",
      "\n",
      "row 366\n",
      "QUESTION: noi can still\n",
      "REAL ANSWER: she is too powerful\n",
      "PREDICTED ANSWER: she is too powerful \n",
      "\n",
      "row 367\n",
      "QUESTION: patience willow\n",
      "REAL ANSWER: willow\n",
      "PREDICTED ANSWER: willow \n",
      "\n",
      "row 368\n",
      "QUESTION: watch between the eyes\n",
      "REAL ANSWER: he never misses\n",
      "PREDICTED ANSWER: he never misses \n",
      "\n",
      "row 369\n",
      "QUESTION: get back here\n",
      "REAL ANSWER: go of me\n",
      "PREDICTED ANSWER: go of me \n",
      "\n",
      "row 370\n",
      "QUESTION: she needs to be changed\n",
      "REAL ANSWER: i changed her already\n",
      "PREDICTED ANSWER: i changed her already \n",
      "\n",
      "row 371\n",
      "QUESTION: cows you know cows\n",
      "REAL ANSWER: i have seen pictures\n",
      "PREDICTED ANSWER: i have seen pictures \n",
      "\n",
      "row 372\n",
      "QUESTION: i have seen pictures\n",
      "REAL ANSWER: good you start tomorrow\n",
      "PREDICTED ANSWER: good you start tomorrow \n",
      "\n",
      "row 373\n",
      "QUESTION: who are these anyway\n",
      "REAL ANSWER: they are amish\n",
      "PREDICTED ANSWER: they are amish \n",
      "\n",
      "row 374\n",
      "QUESTION: john why\n",
      "REAL ANSWER: just do it\n",
      "PREDICTED ANSWER: just do it \n",
      "\n",
      "row 375\n",
      "QUESTION: your hole is healed then\n",
      "REAL ANSWER: pretty much\n",
      "PREDICTED ANSWER: pretty much \n",
      "\n",
      "row 376\n",
      "QUESTION: it\n",
      "REAL ANSWER: yes sir\n",
      "PREDICTED ANSWER: oh that \n",
      "\n",
      "row 377\n",
      "QUESTION: everything is all right john\n",
      "REAL ANSWER: pick up the hat\n",
      "PREDICTED ANSWER: pick up the hat \n",
      "\n",
      "row 378\n",
      "QUESTION: i saw him\n",
      "REAL ANSWER: who would you see\n",
      "PREDICTED ANSWER: who would you see \n",
      "\n",
      "row 379\n",
      "QUESTION: he was like him\n",
      "REAL ANSWER: black i understand what\n",
      "PREDICTED ANSWER: black i understand what \n",
      "\n",
      "row 380\n",
      "QUESTION: how is this kid\n",
      "REAL ANSWER: oh he is good\n",
      "PREDICTED ANSWER: oh he is good \n",
      "\n",
      "row 381\n",
      "QUESTION: who else knows\n",
      "REAL ANSWER: just us\n",
      "PREDICTED ANSWER: just us \n",
      "\n",
      "row 382\n",
      "QUESTION: who else knows\n",
      "REAL ANSWER: just us\n",
      "PREDICTED ANSWER: just us \n",
      "\n",
      "row 383\n",
      "QUESTION: no no doctor\n",
      "REAL ANSWER: but why\n",
      "PREDICTED ANSWER: but why \n",
      "\n",
      "row 384\n",
      "QUESTION: only the\n",
      "REAL ANSWER: how long\n",
      "PREDICTED ANSWER: how long \n",
      "\n",
      "row 385\n",
      "QUESTION: something wrong with buttons\n",
      "REAL ANSWER: buttons are\n",
      "PREDICTED ANSWER: buttons are \n",
      "\n",
      "row 386\n",
      "QUESTION: i am going this morning\n",
      "REAL ANSWER: but stoltzfus said\n",
      "PREDICTED ANSWER: but stoltzfus said \n",
      "\n",
      "row 387\n",
      "QUESTION: but stoltzfus said\n",
      "REAL ANSWER: i know what he said\n",
      "PREDICTED ANSWER: i know what he said \n",
      "\n",
      "row 388\n",
      "QUESTION: the bullets\n",
      "REAL ANSWER: oh the bullets\n",
      "PREDICTED ANSWER: oh the bullets \n",
      "\n",
      "row 389\n",
      "QUESTION: when will you be going\n",
      "REAL ANSWER: not long a few days\n",
      "PREDICTED ANSWER: not long long time \n",
      "\n",
      "row 390\n",
      "QUESTION: i know\n",
      "REAL ANSWER: i was being foolish\n",
      "PREDICTED ANSWER: it is not your fault \n",
      "\n",
      "row 391\n",
      "QUESTION: where is my pants\n",
      "REAL ANSWER: here whenever you want them\n",
      "PREDICTED ANSWER: here whenever you want them \n",
      "\n",
      "row 392\n",
      "QUESTION: say again\n",
      "REAL ANSWER: make that\n",
      "PREDICTED ANSWER: you know a primer \n",
      "\n",
      "row 393\n",
      "QUESTION: did you find him\n",
      "REAL ANSWER: not yet\n",
      "PREDICTED ANSWER: not yet \n",
      "\n",
      "row 394\n",
      "QUESTION: everything okay\n",
      "REAL ANSWER: yes thank you very much\n",
      "PREDICTED ANSWER: yeah dad it is great \n",
      "\n",
      "row 395\n",
      "QUESTION: yes thank you very much\n",
      "REAL ANSWER: john said you are amish\n",
      "PREDICTED ANSWER: john said you are amish \n",
      "\n",
      "row 396\n",
      "QUESTION: good morning\n",
      "REAL ANSWER: you did not have to\n",
      "PREDICTED ANSWER: is it a good morning \n",
      "\n",
      "row 397\n",
      "QUESTION: who was that man\n",
      "REAL ANSWER: his name is john book\n",
      "PREDICTED ANSWER: his name is john book \n",
      "\n",
      "row 398\n",
      "QUESTION: i am not a child\n",
      "REAL ANSWER: you are acting like one\n",
      "PREDICTED ANSWER: you are acting like one \n",
      "\n",
      "row 399\n",
      "QUESTION: no rachel\n",
      "REAL ANSWER: i have to help him\n",
      "PREDICTED ANSWER: i have to help him \n",
      "\n",
      "row 400\n",
      "QUESTION: he will live\n",
      "REAL ANSWER: you might have killed him\n",
      "PREDICTED ANSWER: you might have killed him \n",
      "\n",
      "row 401\n",
      "QUESTION: get back in there\n",
      "REAL ANSWER: my son is out there\n",
      "PREDICTED ANSWER: my son is out there \n",
      "\n",
      "row 402\n",
      "QUESTION: aunt em\n",
      "REAL ANSWER: fiftyseven fiftyeight\n",
      "PREDICTED ANSWER: fiftyseven fiftyeight \n",
      "\n",
      "row 403\n",
      "QUESTION: are busy\n",
      "REAL ANSWER: oh all right\n",
      "PREDICTED ANSWER: oh all right \n",
      "\n",
      "row 404\n",
      "QUESTION: to see\n",
      "REAL ANSWER: if she\n",
      "PREDICTED ANSWER: if she \n",
      "\n",
      "row 405\n",
      "QUESTION: if she\n",
      "REAL ANSWER: if she\n",
      "PREDICTED ANSWER: is \n",
      "\n",
      "row 406\n",
      "QUESTION: if she\n",
      "REAL ANSWER: is\n",
      "PREDICTED ANSWER: if she \n",
      "\n",
      "row 407\n",
      "QUESTION: oz has spoken\n",
      "REAL ANSWER: who are you\n",
      "PREDICTED ANSWER: who are you \n",
      "\n",
      "row 408\n",
      "QUESTION: yes\n",
      "REAL ANSWER: i do not believe you\n",
      "PREDICTED ANSWER: i do not believe you \n",
      "\n",
      "row 409\n",
      "QUESTION: run toto run\n",
      "REAL ANSWER: catch him you fool\n",
      "PREDICTED ANSWER: catch him you fool \n",
      "\n",
      "row 410\n",
      "QUESTION: toto too\n",
      "REAL ANSWER: toto too\n",
      "PREDICTED ANSWER: oh now \n",
      "\n",
      "row 411\n",
      "QUESTION: toto too\n",
      "REAL ANSWER: oh now\n",
      "PREDICTED ANSWER: toto too \n",
      "\n",
      "row 412\n",
      "QUESTION: oh now\n",
      "REAL ANSWER: whenever you wish\n",
      "PREDICTED ANSWER: whenever you wish \n",
      "\n",
      "row 413\n",
      "QUESTION: are you ready now\n",
      "REAL ANSWER: goodbye toto\n",
      "PREDICTED ANSWER: goodbye toto \n",
      "\n",
      "row 414\n",
      "QUESTION: aw come come come\n",
      "REAL ANSWER: no they will not honestly\n",
      "PREDICTED ANSWER: no they will not honestly \n",
      "\n",
      "row 415\n",
      "QUESTION: that is our farm\n",
      "REAL ANSWER: oh yes\n",
      "PREDICTED ANSWER: oh yes \n",
      "\n",
      "row 416\n",
      "QUESTION: her face is\n",
      "REAL ANSWER: yesthat is aunt em\n",
      "PREDICTED ANSWER: yesthat is aunt em \n",
      "\n",
      "row 417\n",
      "QUESTION: yesthat is aunt em\n",
      "REAL ANSWER: her her name is emily\n",
      "PREDICTED ANSWER: her her name is emily \n",
      "\n",
      "row 418\n",
      "QUESTION: oil can\n",
      "REAL ANSWER: did you say something\n",
      "PREDICTED ANSWER: did you say something \n",
      "\n",
      "row 419\n",
      "QUESTION: did you say something\n",
      "REAL ANSWER: oil can\n",
      "PREDICTED ANSWER: oil can \n",
      "\n",
      "row 420\n",
      "QUESTION: oh i will get it\n",
      "REAL ANSWER: oh oh\n",
      "PREDICTED ANSWER: oh oh \n",
      "\n",
      "row 421\n",
      "QUESTION: only oh\n",
      "REAL ANSWER: ohoh tin man oh\n",
      "PREDICTED ANSWER: ohoh tin man oh \n",
      "\n",
      "row 422\n",
      "QUESTION: oh my\n",
      "REAL ANSWER: lions and tigers and bears\n",
      "PREDICTED ANSWER: what is it betty \n",
      "\n",
      "row 423\n",
      "QUESTION: lions and tigers and bears\n",
      "REAL ANSWER: oh my\n",
      "PREDICTED ANSWER: oh my \n",
      "\n",
      "row 424\n",
      "QUESTION: oh my\n",
      "REAL ANSWER: lions and tigers and bears\n",
      "PREDICTED ANSWER: what is it betty \n",
      "\n",
      "row 425\n",
      "QUESTION: lions and tigers and bears\n",
      "REAL ANSWER: oh my\n",
      "PREDICTED ANSWER: oh my \n",
      "\n",
      "row 426\n",
      "QUESTION: oh my\n",
      "REAL ANSWER: lions and tigers and bears\n",
      "PREDICTED ANSWER: lions and tigers and bears \n",
      "\n",
      "row 427\n",
      "QUESTION: lions and tigers and bears\n",
      "REAL ANSWER: oh my\n",
      "PREDICTED ANSWER: oh my \n",
      "\n",
      "row 428\n",
      "QUESTION: oh my\n",
      "REAL ANSWER: lions and tigers and bears\n",
      "PREDICTED ANSWER: lions and tigers and \n",
      "\n",
      "row 429\n",
      "QUESTION: lions and tigers and bears\n",
      "REAL ANSWER: oh my\n",
      "PREDICTED ANSWER: oh my \n",
      "\n",
      "row 430\n",
      "QUESTION: a home\n",
      "REAL ANSWER: the nerve\n",
      "PREDICTED ANSWER: the nerve \n",
      "\n",
      "row 431\n",
      "QUESTION: i would sooner wait outside\n",
      "REAL ANSWER: but whywhy\n",
      "PREDICTED ANSWER: but whywhy \n",
      "\n",
      "row 432\n",
      "QUESTION: but whywhy\n",
      "REAL ANSWER: because i am still scared\n",
      "PREDICTED ANSWER: because i am still scared \n",
      "\n",
      "row 433\n",
      "QUESTION: because i am still scared\n",
      "REAL ANSWER: oh come on\n",
      "PREDICTED ANSWER: oh come on \n",
      "\n",
      "row 434\n",
      "QUESTION: oh oh come on\n",
      "REAL ANSWER: huhwhat would he say\n",
      "PREDICTED ANSWER: huhwhat would he say \n",
      "\n",
      "row 435\n",
      "QUESTION: oh oh toto\n",
      "REAL ANSWER: did they\n",
      "PREDICTED ANSWER: did they \n",
      "\n",
      "row 436\n",
      "QUESTION: to oz\n",
      "REAL ANSWER: to oz\n",
      "PREDICTED ANSWER: to oz \n",
      "\n",
      "row 437\n",
      "QUESTION: he said his mouth\n",
      "REAL ANSWER: here here\n",
      "PREDICTED ANSWER: here here \n",
      "\n",
      "row 438\n",
      "QUESTION: here here\n",
      "REAL ANSWER: the other side\n",
      "PREDICTED ANSWER: the fuck is this \n",
      "\n",
      "row 439\n",
      "QUESTION: the other side\n",
      "REAL ANSWER: yes there\n",
      "PREDICTED ANSWER: yes there \n",
      "\n",
      "row 440\n",
      "QUESTION: the ruby slippers\n",
      "REAL ANSWER: the slippers yesthe slippers\n",
      "PREDICTED ANSWER: the slippers yesthe slippers \n",
      "\n",
      "row 441\n",
      "QUESTION: dorothy next\n",
      "REAL ANSWER: yes dorothy ah\n",
      "PREDICTED ANSWER: yes dorothy ah \n",
      "\n",
      "row 442\n",
      "QUESTION: who at\n",
      "REAL ANSWER: i do not know\n",
      "PREDICTED ANSWER: i do not know \n",
      "\n",
      "row 443\n",
      "QUESTION: what happened\n",
      "REAL ANSWER: somebody pulled my tail\n",
      "PREDICTED ANSWER: i am not sure \n",
      "\n",
      "row 444\n",
      "QUESTION: somebody pulled my tail\n",
      "REAL ANSWER: oh you did it yourself\n",
      "PREDICTED ANSWER: oh you did it yourself \n",
      "\n",
      "row 445\n",
      "QUESTION: oh you did it yourself\n",
      "REAL ANSWER: i oh\n",
      "PREDICTED ANSWER: i oh \n",
      "\n",
      "row 446\n",
      "QUESTION: i oh\n",
      "REAL ANSWER: here come on\n",
      "PREDICTED ANSWER: here come on \n",
      "\n",
      "row 447\n",
      "QUESTION: here come on\n",
      "REAL ANSWER: what was that\n",
      "PREDICTED ANSWER: what was that \n",
      "\n",
      "row 448\n",
      "QUESTION: yeah me\n",
      "REAL ANSWER: yes you\n",
      "PREDICTED ANSWER: yes you \n",
      "\n",
      "row 449\n",
      "QUESTION: it is a whatzis\n",
      "REAL ANSWER: it is a whatzis\n",
      "PREDICTED ANSWER: it is a whatzis \n",
      "\n",
      "row 450\n",
      "QUESTION: nonow wait a minute\n",
      "REAL ANSWER: you do not neither\n",
      "PREDICTED ANSWER: you do not neither \n",
      "\n",
      "row 451\n",
      "QUESTION: mr gale\n",
      "REAL ANSWER: howdy miss\n",
      "PREDICTED ANSWER: howdy miss \n",
      "\n",
      "row 452\n",
      "QUESTION: about dorothy\n",
      "REAL ANSWER: what has dorothy done\n",
      "PREDICTED ANSWER: what has dorothy done \n",
      "\n",
      "row 453\n",
      "QUESTION: you mean she bit you\n",
      "REAL ANSWER: no her dog\n",
      "PREDICTED ANSWER: no her dog \n",
      "\n",
      "row 454\n",
      "QUESTION: tin man\n",
      "REAL ANSWER: ohhhh it is me\n",
      "PREDICTED ANSWER: ohhhh it is me \n",
      "\n",
      "row 455\n",
      "QUESTION: no sir\n",
      "REAL ANSWER: no sir\n",
      "PREDICTED ANSWER: my change \n",
      "\n",
      "row 456\n",
      "QUESTION: that is right\n",
      "REAL ANSWER: we do\n",
      "PREDICTED ANSWER: beat it \n",
      "\n",
      "row 457\n",
      "QUESTION: we do\n",
      "REAL ANSWER: to oz\n",
      "PREDICTED ANSWER: where is \n",
      "\n",
      "row 458\n",
      "QUESTION: to oz\n",
      "REAL ANSWER: to oz\n",
      "PREDICTED ANSWER: to oz \n",
      "\n",
      "row 459\n",
      "QUESTION: come on come on\n",
      "REAL ANSWER: hurry hurry\n",
      "PREDICTED ANSWER: what happened \n",
      "\n",
      "row 460\n",
      "QUESTION: ha ha ha\n",
      "REAL ANSWER: ho ho ho\n",
      "PREDICTED ANSWER: ho ho ho \n",
      "\n",
      "row 461\n",
      "QUESTION: oh look out\n",
      "REAL ANSWER: you know something\n",
      "PREDICTED ANSWER: you know something \n",
      "\n",
      "row 462\n",
      "QUESTION: it is a whozis\n",
      "REAL ANSWER: it is a whozis\n",
      "PREDICTED ANSWER: it is a whozis \n",
      "\n",
      "row 463\n",
      "QUESTION: help help help help help\n",
      "REAL ANSWER: ohwell what happened to you\n",
      "PREDICTED ANSWER: ohwell what happened to you \n",
      "\n",
      "row 464\n",
      "QUESTION: now now do not\n",
      "REAL ANSWER: oh dear dear\n",
      "PREDICTED ANSWER: oh dear dear \n",
      "\n",
      "row 465\n",
      "QUESTION: oh dear dear\n",
      "REAL ANSWER: we will get you together\n",
      "PREDICTED ANSWER: we will get you together \n",
      "\n",
      "row 466\n",
      "QUESTION: no you do not\n",
      "REAL ANSWER: oh no\n",
      "PREDICTED ANSWER: oh no \n",
      "\n",
      "row 467\n",
      "QUESTION: oh upstairs quickly\n",
      "REAL ANSWER: go on\n",
      "PREDICTED ANSWER: go on \n",
      "\n",
      "row 468\n",
      "QUESTION: hey what about dorothy\n",
      "REAL ANSWER: yes how about dorothy\n",
      "PREDICTED ANSWER: yes how about dorothy \n",
      "\n",
      "row 469\n",
      "QUESTION: what about us\n",
      "REAL ANSWER: well i\n",
      "PREDICTED ANSWER: well i \n",
      "\n",
      "row 470\n",
      "QUESTION: you new\n",
      "REAL ANSWER: yes miss\n",
      "PREDICTED ANSWER: yes miss \n",
      "\n",
      "row 471\n",
      "QUESTION: what happened to\n",
      "REAL ANSWER: make it headache\n",
      "PREDICTED ANSWER: make it headache \n",
      "\n",
      "row 472\n",
      "QUESTION: whos she\n",
      "REAL ANSWER: elektra king\n",
      "PREDICTED ANSWER: elektra king \n",
      "\n",
      "row 473\n",
      "QUESTION: the king pipeline\n",
      "REAL ANSWER: elektra would control it all\n",
      "PREDICTED ANSWER: elektra would control it all \n",
      "\n",
      "row 474\n",
      "QUESTION: but what if\n",
      "REAL ANSWER: count to be there\n",
      "PREDICTED ANSWER: count to be there \n",
      "\n",
      "row 475\n",
      "QUESTION: got to get out\n",
      "REAL ANSWER: we cant\n",
      "PREDICTED ANSWER: we cant \n",
      "\n",
      "row 476\n",
      "QUESTION: its just a scratch\n",
      "REAL ANSWER: really be\n",
      "PREDICTED ANSWER: really be \n",
      "\n",
      "row 477\n",
      "QUESTION: not exactly my line\n",
      "REAL ANSWER: quite the opposite in fact\n",
      "PREDICTED ANSWER: quite the opposite in fact \n",
      "\n",
      "row 478\n",
      "QUESTION: the inside man\n",
      "REAL ANSWER: is inside woman\n",
      "PREDICTED ANSWER: is inside woman \n",
      "\n",
      "row 479\n",
      "QUESTION: he was my father\n",
      "REAL ANSWER: im sorry\n",
      "PREDICTED ANSWER: im sorry \n",
      "\n",
      "row 480\n",
      "QUESTION: oh my buried alive\n",
      "REAL ANSWER: were alright\n",
      "PREDICTED ANSWER: were alright \n",
      "\n",
      "row 481\n",
      "QUESTION: i cant stay here\n",
      "REAL ANSWER: youre not going to\n",
      "PREDICTED ANSWER: youre not going to \n",
      "\n",
      "row 482\n",
      "QUESTION: noit will cave in\n",
      "REAL ANSWER: its the only way out\n",
      "PREDICTED ANSWER: its the only way out \n",
      "\n",
      "row 483\n",
      "QUESTION: i cant stay\n",
      "REAL ANSWER: i know\n",
      "PREDICTED ANSWER: i know \n",
      "\n",
      "row 484\n",
      "QUESTION: what is it\n",
      "REAL ANSWER: you should rest\n",
      "PREDICTED ANSWER: a passionfruit smoothee \n",
      "\n",
      "row 485\n",
      "QUESTION: i have to go\n",
      "REAL ANSWER: then take me with you\n",
      "PREDICTED ANSWER: but you must come in \n",
      "\n",
      "row 486\n",
      "QUESTION: then take me with you\n",
      "REAL ANSWER: no youll be safe here\n",
      "PREDICTED ANSWER: no youll be safe here \n",
      "\n",
      "row 487\n",
      "QUESTION: vodka martini\n",
      "REAL ANSWER: two not\n",
      "PREDICTED ANSWER: two not \n",
      "\n",
      "row 488\n",
      "QUESTION: wheres m\n",
      "REAL ANSWER: soon shell be everywhere\n",
      "PREDICTED ANSWER: soon shell be everywhere \n",
      "\n",
      "row 489\n",
      "QUESTION: one last screw\n",
      "REAL ANSWER: oh james\n",
      "PREDICTED ANSWER: oh james \n",
      "\n",
      "row 490\n",
      "QUESTION: \n",
      "REAL ANSWER: what brings you here\n",
      "PREDICTED ANSWER: bomb \n",
      "\n",
      "row 491\n",
      "QUESTION: nowwhere were we\n",
      "REAL ANSWER: a rope\n",
      "PREDICTED ANSWER: a rope \n",
      "\n",
      "row 492\n",
      "QUESTION: wheres the sub going\n",
      "REAL ANSWER: me out\n",
      "PREDICTED ANSWER: me out \n",
      "\n",
      "row 493\n",
      "QUESTION: the tower\n",
      "REAL ANSWER: how appropriate\n",
      "PREDICTED ANSWER: how appropriate \n",
      "\n",
      "row 494\n",
      "QUESTION: ill send someone out\n",
      "REAL ANSWER: you come\n",
      "PREDICTED ANSWER: you come \n",
      "\n",
      "row 495\n",
      "QUESTION: someone will come\n",
      "REAL ANSWER: is dead\n",
      "PREDICTED ANSWER: is dead \n",
      "\n",
      "row 496\n",
      "QUESTION: he was lover\n",
      "REAL ANSWER: what do you think\n",
      "PREDICTED ANSWER: what do you think \n",
      "\n",
      "row 497\n",
      "QUESTION: any word from him\n",
      "REAL ANSWER: still no contact yet\n",
      "PREDICTED ANSWER: still no contact yet \n",
      "\n",
      "row 498\n",
      "QUESTION: hi jon\n",
      "REAL ANSWER: hello\n",
      "PREDICTED ANSWER: hello \n",
      "\n",
      "row 499\n",
      "QUESTION: what are you doing\n",
      "REAL ANSWER: do not understand\n",
      "PREDICTED ANSWER: do not understand \n",
      "\n",
      "row 500\n",
      "QUESTION: mm hmm\n",
      "REAL ANSWER: i could stay and go\n",
      "PREDICTED ANSWER: i could stay and go \n",
      "\n",
      "row 501\n",
      "QUESTION: what am i\n",
      "REAL ANSWER: cured yes\n",
      "PREDICTED ANSWER: cured yes \n",
      "\n",
      "row 502\n",
      "QUESTION: its very flowing backwards\n",
      "REAL ANSWER: jon what\n",
      "PREDICTED ANSWER: jon what \n",
      "\n",
      "row 503\n",
      "QUESTION: jon what\n",
      "REAL ANSWER: the south flowing backwards\n",
      "PREDICTED ANSWER: the south flowing backwards \n",
      "\n",
      "row 504\n",
      "QUESTION: jon where are we\n",
      "REAL ANSWER: complex\n",
      "PREDICTED ANSWER: complex \n",
      "\n",
      "row 505\n",
      "QUESTION: and what if youre wrong\n",
      "REAL ANSWER: im not\n",
      "PREDICTED ANSWER: im not \n",
      "\n",
      "row 506\n",
      "QUESTION: im not\n",
      "REAL ANSWER: what if youre wrong\n",
      "PREDICTED ANSWER: what if youre wrong \n",
      "\n",
      "row 507\n",
      "QUESTION: damn straight\n",
      "REAL ANSWER: damn were\n",
      "PREDICTED ANSWER: damn were \n",
      "\n",
      "row 508\n",
      "QUESTION: his what\n",
      "REAL ANSWER: his whatever\n",
      "PREDICTED ANSWER: his whatever \n",
      "\n",
      "row 509\n",
      "QUESTION: his whatever\n",
      "REAL ANSWER: i am not his\n",
      "PREDICTED ANSWER: i am not his \n",
      "\n",
      "row 510\n",
      "QUESTION: what are you up to\n",
      "REAL ANSWER: do not around\n",
      "PREDICTED ANSWER: do not around \n",
      "\n",
      "row 511\n",
      "QUESTION: they are following us\n",
      "REAL ANSWER: all accomplished\n",
      "PREDICTED ANSWER: all accomplished \n",
      "\n",
      "row 512\n",
      "QUESTION: those year is this\n",
      "REAL ANSWER: everything's changed\n",
      "PREDICTED ANSWER: everything's changed \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(val_batch_x)):\n",
    "    print('row %d'%(i+1))\n",
    "    print('QUESTION:',' '.join(ques[i]))\n",
    "    print('REAL ANSWER:',' '.join(real_answer[i]))\n",
    "    print('PREDICTED ANSWER:',' '.join(pred_answer[i]),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-qx-jwMh6V1k"
   },
   "source": [
    "# Load save model for given sample test\n",
    "As here i have assigned my sentence to the variable \n",
    "            \n",
    "            question_sentence_2\n",
    "Initialize tf.session with the graph and load the model meta graph from the saved path to use the model for prediction.\n",
    "as earlier describe the iput for session run.So as we used differeznt keep_prob (dropout for regularization).Earlier i used 0.5 and now its 1.0 in order to see the better performance but its also difficult to conclude this hyperparameter value using this single example.Its for the example purpose.\n",
    "\n",
    "As we dont know the target length for the moment i assign the maximum length\n",
    "\n",
    "Finally out put the word id from vocab dictionary with the corresponding sentence for question and answer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3005,
     "status": "ok",
     "timestamp": 1589904166881,
     "user": {
      "displayName": "Abonia Sojasingarayar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiGI2S6plDhEjXinzvOnzVjhgSjbT_2_mUe0Ud1xA=s64",
      "userId": "02695506849043029320"
     },
     "user_tz": -120
    },
    "id": "30qfB77zEMx8",
    "outputId": "648d8bcf-f96e-43d1-eb61-40a2929220cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from /content/drive/My Drive/ML Projects/Global IA/Seq2Seq-Chatbot/Notebook/model_weights/model_weights\n",
      "Input\n",
      "  Word Ids:      [0, 14, 12, 6285]\n",
      "  Question: ['what', 'are', 'you', '<UNK>']\n",
      "\n",
      "Prediction\n",
      "  Word Ids:      [23, 108, 585, 6284]\n",
      "  Answer: i am sorry <EOS>\n"
     ]
    }
   ],
   "source": [
    "question_sentence_2 = 'what are you doing?'\n",
    "question_sentence_2 = sentence_to_seq(question_sentence_2, vocabs_to_index)\n",
    "loaded_graph = tf.Graph()\n",
    "with tf.Session(graph=loaded_graph) as sess:\n",
    "    # Load saved model\n",
    "    loader = tf.train.import_meta_graph(save_path + '.meta')\n",
    "    loader.restore(sess, save_path)\n",
    "\n",
    "    input_data = loaded_graph.get_tensor_by_name('input:0')\n",
    "    logits = loaded_graph.get_tensor_by_name('predictions:0')\n",
    "    input_data_len = loaded_graph.get_tensor_by_name('input_len:0')\n",
    "    target_data_len = loaded_graph.get_tensor_by_name('target_len:0')\n",
    "    keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "\n",
    "    prediction_logits = sess.run(logits, {input_data: [question_sentence_2]*batch_size,\n",
    "                                         input_data_len: [len(question_sentence_2)]*batch_size,\n",
    "                                         target_data_len : [5]*batch_size,\n",
    "                                         keep_prob: 1.0})[0]\n",
    "\n",
    "print('Input')\n",
    "print('  Word Ids:      {}'.format([i for i in question_sentence_2]))\n",
    "print('  Question: {}'.format([index_to_vocabs[i] for i in question_sentence_2]))\n",
    "\n",
    "print('\\nPrediction')\n",
    "print('  Word Ids:      {}'.format([i for i in prediction_logits]))\n",
    "print('  Answer: {}'.format(\" \".join([index_to_vocabs[i] for i in prediction_logits])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lFdubxqd6V1m"
   },
   "source": [
    "### Even history to use with Tensorboard\n",
    "Save the graph event file for to visualize the graph computation in tensorboard\n",
    " use the command below within relative path in the tensorflow\n",
    " \n",
    "     env tensorboard --logdir=Notebook\\model_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ucvYKRjU6V1m"
   },
   "outputs": [],
   "source": [
    "file_writer = tf.summary.FileWriter('/content/drive/My Drive/ML Projects/Global IA/Seq2Seq-Chatbot/Notebook/model_weights/log', sess.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l3QYeMG26V1n"
   },
   "source": [
    "Retrieve the learned embeddings\n",
    "\n",
    "Next, let's retrieve the word embeddings learned during training. This will be a matrix of shape (vocab_size, embedding-dimension).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "We will now write the weights to disk. To use the Embedding Projector, we will upload two files in tab separated format: a file of vectors (containing the embedding), and a file of meta data (containing the words).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "boF6izBN6V1o"
   },
   "outputs": [],
   "source": [
    "e = model.layers[0]\n",
    "weights = e.get_weights()[0]\n",
    "print(weights.shape) # shape: (vocab_size, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uLEazZhB6V1p"
   },
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "encoder = info.features['text'].encoder\n",
    "\n",
    "out_v = io.open('vecs.tsv', 'w', encoding='utf-8')\n",
    "out_m = io.open('meta.tsv', 'w', encoding='utf-8')\n",
    "\n",
    "for num, word in enumerate(encoder.subwords):\n",
    "  vec = weights[num+1] # skip 0, it's padding.\n",
    "  out_m.write(word + \"\\n\")\n",
    "  out_v.write('\\t'.join([str(x) for x in vec]) + \"\\n\")\n",
    "out_v.close()\n",
    "out_m.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qFvhHRNw6V1q"
   },
   "source": [
    "# Conclusion\n",
    "\n",
    "The training data on Cornell Movie Subtitle corpus produced a result that needs further improvement \n",
    "and more attention and speculation on training parameters. Adding more quality data will further \n",
    "improve performance. Also, the training model should be trained with other hyper-parameters and \n",
    "different datasets for further experimentation. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YIqCopyM6V1r"
   },
   "source": [
    "# References\n",
    "[1] Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation:https://arxiv.org/abs/1406.1078\n",
    "\n",
    "[2] Sequence to Sequence Learning with Neural Networks:https://arxiv.org/abs/1409.3215\n",
    "\n",
    "[3] Neural Machine Translation by Jointly Learning to Align and Translate:https://arxiv.org/abs/1409.0473\n",
    "\n",
    "[4] A Neural Conversational Model:https://arxiv.org/abs/1506.05869\n",
    "\n",
    "[6] Sequence-to-Sequence learning and Neural Conversation model 2017/08/02 \n",
    "https://isaacchanghau.github.io/2017/08/02/Seq2Seq-Learning-andNeuralConversationalModel \n",
    "\n",
    "[7] A Formalization of a Simple Sequential Encoder-Decoder https://mc.ai/a-formalization-of-a-simple-sequential-encoder-decoder/ \n",
    "\n",
    "[8] Neural Machine Translation by Jointly Learning to Align and Translate Dzmitry Bahdanau, Kyunghyun Cho, Yoshua Bengio (Submitted on 1 Sep 2014 (v1), last revised 19 May 2016 (this version, v7)) \n",
    "\n",
    "[9] Dataset collect and information about Cornell movie dialog corpus dataset available at https://www.cs.cornell.edu/ cristian/CornellMovieDialogsCorpus.htm \n",
    "\n",
    "[10]  I. N. d. Silva, D. H. Spatti, R. A. Flauzino, L. H. B. Liboni, and S. F. d. R. Alves, Artificial Neural  \n",
    "Networks A Practical Course, Springer International Publishing, 2017.\n",
    "\n",
    "[11]  O. Davydova, \"7 Types of Artificial Neural Networks for Natural Language Processing,\" \n",
    "[Online].  \n",
    "Available: https://www.kdnuggets.com/2017/10/7-types-artificial-neural-networks-natural language-processing.html.  \n",
    "\n",
    "[12]  G. M and D. S. [Online]. Available:  https://www.sciencedirect.com/science/article/pii/S1352231097004470. \n",
    "\n",
    "[13]  T. Young, D. Hazarika, S. Poria, and E. Cambria, \"Recent Trends in Deep Learning-Based Natural  Language Processing\". \n",
    "\n",
    "[14]  R. Collobert and J. Weston, \"A unified architecture for natural language processing: deep neural networks with multitask learning,\" in Proceedings of the 25th international conference on machine learning, 2008. \n",
    "\n",
    "[15] J¨org Tiedemann. News from OPUS - A collection of multilingual parallel corpora with tools and interfaces. In N. Nicolov, K. Bontcheva, G. Angelova, and R. Mitkov, editors, Recent Advances in Natural Language Processing, volume V, pages 237–248. John Benjamins, Amsterdam/Philadelphia, Borovets, Bulgaria, 2009. \n",
    "\n",
    "[16] Ashish Vaswani, Noam Shazier, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. Attention is all you need. CoRR, abs/1706.03762, 2017. \n",
    "\n",
    "[17] Oriol Vinyals and Quoc V. Le. A neural conversational model. CoRR, abs/1506.05869, 2015. \n",
    "\n",
    "[18] Joseph Weizenbaum. Eliza: a computer program for the study of natural language communication between man and machine. Commun. ACM, 9(1):36–45, January 1966\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Seq2Seq Chatbot_80_512.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
